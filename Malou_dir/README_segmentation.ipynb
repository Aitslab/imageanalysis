{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Segmentation\n",
    "\n",
    "\t1.1 Load images\n",
    "    \n",
    "    1.2 Annotate images using cvat\n",
    "    \n",
    "    1.3 Preprocessing of images\n",
    "        - Convert images to png\n",
    "\t\t- Create training/validation/test fraction text files\n",
    "\t\t- Normalization\n",
    "\t\t- Creating border labels\n",
    "\t\t- Augmentation (affine transformation)\n",
    "        - Preprocessing of image-sets for Model 5\n",
    "        \n",
    "    1.4 Training\n",
    "    \n",
    "    1.5 Prediction\n",
    "    \n",
    "    1.6 Evaluation\n",
    "    \n",
    "    1.7 Scripts\n",
    "        - format_convertion.py\n",
    "        - config.py\n",
    "        - 00-load-and-reformat-dataset.py\n",
    "        - 01-Augmentation.py\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - Utils scripts\n",
    "            - augmentation.py \n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "        - Preprocessing of datasets for Model 5\n",
    "            - Preprocessing_and_merging_annotations_BBBC038.py\n",
    "            - Preprocessing_BBBC020.py\n",
    "            - Preprocessing_celltracking_images.py\n",
    "     1.8 Docs\n",
    "         - filelist_wrong_images.txt\n",
    "         - 1-2_training.txt\n",
    "         - 3_training.txt\n",
    "         - 4_training.txt\n",
    "         - 5_training_500.txt\n",
    "         - 6_training.txt\n",
    "         - 7_training.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have with help from the script by Broad Bioimage Benchmarc Collection (BBBC), found at https://github.com/carpenterlab/unet4nuclei,\n",
    "recreated their experiment with the use of images from Aits lab, and additional images from other open source datasets.\n",
    "\n",
    "In the BBBC repository, the full script can be found for their experiments, but for our purpose the script has been modified.\n",
    "\n",
    "Some modifications had to be done due to outdated versions of python packages, and some modifications because of different image-formats. \n",
    "In our experiment it was also of importance to include micronucleis in the modelprediction, so the scripts are modified to fit that purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up folders and scripts\n",
    "\n",
    "In the folder where the scripts will be stored, there should also be a script called config.py and a folder named utils containing scripts with functions. The filetree should look like this:\n",
    "\n",
    "\n",
    "**2_Final_Models**  \n",
    "- **1_Model1**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **2_Model2**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **3_Model3**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **4_Model4**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "- **5_Model5**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "- **6_Model6**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "- **7_Model7**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "- **8_Model8**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "- **9_Model9**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **data**\n",
    "    - **1_raw_annotations**\n",
    "    - **2_raw_images**\n",
    "    - **3_preprocessing_of_data**\n",
    "        - 00-load-and-reformat-dataset.py\n",
    "        - 01-Augmentation.py \n",
    "        - config.py \n",
    "    - **4_filelists**\n",
    "        - 1-2_training.txt\n",
    "        - 3_training.txt\n",
    "        - 4_training.txt\n",
    "        - 5_training.txt\n",
    "        - 6_training.txt\n",
    "        - 7_training.txt\n",
    "        - 8_training.txt\n",
    "        - TEST.txt\n",
    "        - VALIDATION.txt\n",
    "    \n",
    "\n",
    "The folder **2_Final_Models/data/1_raw_annotations** is where the annotations will be stored.\n",
    "\n",
    "The folder **2_Final_Models/data/1_raw_data** is where the images will be stored. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download bbbc images\n",
    "\n",
    "The images from the bbbc experiment can be found here:\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC039/images.zip\n",
    "\n",
    "The images are extracted and put in the folder **2_Final_Models/data/1_raw_data**\n",
    "\n",
    "\n",
    "And the annotations for the images:\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC039/masks.zip\n",
    "\n",
    "The mask images are extracted and put in the folder **2_Final_Models/data/2_raw_annotations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading image sets for Model 5\n",
    "\n",
    "GFP-GOWT1 mouse stem cells:\n",
    "\n",
    "http://data.celltrackingchallenge.net/training-datasets/Fluo-N2DH-GOWT1.zip\n",
    "\n",
    "HeLa cells stably expressing H2b-GFP:\n",
    "\n",
    "http://data.celltrackingchallenge.net/training-datasets/Fluo-N2DL-HeLa.zip\n",
    "\n",
    "Simulated nuclei of HL60 cells stained with Hoescht:\n",
    "\n",
    "http://data.celltrackingchallenge.net/training-datasets/Fluo-N2DH-SIM+.zip\n",
    "\n",
    "kaggle-dsbowl-2018-dataset:\n",
    "\n",
    "https://github.com/lopuhin/kaggle-dsbowl-2018-dataset-fixes/archive/master.zip\n",
    "\n",
    "BBBC Murine bone-marrow derived macrophages:\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC020/BBBC020_v1_images.zip\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC020/BBBC020_v1_outlines_nuclei.zip\n",
    "\n",
    "The zipfiles should be extracted to the following folderstructure:\n",
    "\n",
    "**3_data**\n",
    " - **2_additional_datasets**\n",
    "     - **1_celltracking_challenge_data**\n",
    "         - **Fluo-N2DL-HeLa**\n",
    "         - **Fluo-N2DH-SIM+**\n",
    "         - **Fluo-N2DH-GOWT1**\n",
    "     - **2_BBBC_image_sets**\n",
    "         - **kaggle-dsbowl-2018-dataset-fixes**\n",
    "         - **BBBC020_v1_images**\n",
    "         - **BBBC020_v1_outlines_nuclei**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aits lab images\n",
    "We have worked with 100 randomly selected images from the full data set consisting of approx. 6 million images, these images are of the format .C01 which is a microscopy format. The input images in the BBBC scripts are expected to be .tiff or .png, so all 100 images are first converted to png.\n",
    "\n",
    "For this I have created a script that will take a directory as input, and output the converted images to a new selected directory.\n",
    "\n",
    "The script is done with argparse, and can be used just by downloading the script and following these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and installing bftools:\n",
    "\n",
    "```bash\n",
    "cd ~/bin\n",
    "wget http://downloads.openmicroscopy.org/latest/bio-formats/artifacts/bftools.zip\n",
    "unzip bftools.zip\n",
    "rm bftools.zip\n",
    "export PATH=$PATH:~/bin/bftools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing required python packages:\n",
    "```bash\n",
    "pip install argparse\n",
    "pip install os\n",
    "pip install subprocess\n",
    "pip install tqdm\n",
    "pip install pathlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The program is run like:\n",
    "```bash\n",
    "python3 format_convertion.py -i INDIR -o OUTDIR -ift IN_FILETYPE -oft OUT_FILETYPE\n",
    "```\n",
    "\n",
    "The script **format_convertion.py** is found in section **1.7  Scripts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Annotate images using cvat\n",
    "\n",
    "\n",
    "We have annotated 50 images to use in the experiment, we have used the annotation program cvat. Information about the program and installation instructions are found on their github page, https://github.com/opencv/cvat.\n",
    "\n",
    "Only one label is used for annotation, nucleus, and each nucleus is drawn with the polygon tool.\n",
    "\n",
    "The work is saved using the option “DUMP ANNOTATION” -> “MASK ZIP 1.1”\n",
    "\n",
    "That will create and download a zip file with one folder of images only with the class (nucleus), showing all nucleus in the same color, and one folder with annotations of the objects, each image will be an RGB image, with all objects being different colors to distinguish between them.\n",
    "\n",
    "In the creation of our labels, the object images was used. These images are not of the same format as the bbbc institute’s, so the script had to be modified to fit these images.\n",
    "\n",
    "\n",
    "The images we have annotated can be found here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{insert link}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Preprocessing of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model set up\n",
    "\n",
    "When later training the model, the imageset is divided in to 3 categories; training-, validation-, and test- set.\n",
    "\n",
    "For our experiments we have done nine different models, with different training set.\n",
    "10 images is saved as a test set, 10 is used for validation, and for the different models we have different training sets.\n",
    "\n",
    "Model 1: 30 images from Aitslab\n",
    "\n",
    "Model 2: 30 images from Aitslab that has been augmented with elastic transformation so that a total of 300 images is used. Evaluation done with original images from the validation set, and with elastic transformation done on the validation set.\n",
    "\n",
    "Model 3: The same as Model 2 but with additional 100 images from the BBBC group.\n",
    "\n",
    "Model 4: The same as Model 2 but with additional 200 images from the BBBC group.\n",
    "\n",
    "Model 5: The same as Model 4 but with additional 500 images from the BBBC group\n",
    "\n",
    "Model 6: Training with 2 images from Aitslab\n",
    "\n",
    "Model 7: Training with 5 images from Aitslab\n",
    "\n",
    "Model 8: Training with 15 images from Aitslab\n",
    "\n",
    "Model 9: Model 1 trained for additional 15 epochs\n",
    "\n",
    "### Normalization and creation of boundary labels\n",
    "\n",
    "First the images are normalized to have pixel values between 0-1 instead of 0-255, and converted to png if that is not already done. \n",
    "\n",
    "Then boundary labels are created. \n",
    "Objects are found in the annotation image using the skimage module, both for finding distinguished objects, and for finding boundaries of the objects. The boundaries are created outside of the object.   \n",
    "\n",
    "These steps are done in the script **00-load-and-reformat-dataset.py**\n",
    "\n",
    "The annotations are expected to be one image with all annotations, where each object is of different pixelvalue.\n",
    "for the images downloaded for Model 5, some additional preprocessing was needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the images for Model 5\n",
    "\n",
    "#### kaggle-dsbowl-2018-dataset:\n",
    "\n",
    "This datasets consists of different images, many images that is not similar to our dataset, and not wanted in our model. It is no specific structure of the directories and where to find the similar images, but the images similar to ours are all grey scale, and can be distinguished in that way.\n",
    "\n",
    "Another difference with this dataset is that the annotations are separated per object, so that it exists one image per object instead of one image with all objects.\n",
    "\n",
    "To extract the images a script was created, it goes through the directories, it is one image per directory. The image is checked if it is grey scale or not. The image type is RGB-D even if it is grey scale, so to control if it is grey scale the pixel values are compared. If the image is grey scale, the first 3 values of each pixel are expected to be the same (the fourth value is the value of the image transparancy).\n",
    "\n",
    "If the image is gray scale then the masks are extracted and combined to form one image. Each mask image is black and white, the object is white. The mask images are combined, with each mask given a different pixel value.\n",
    "\n",
    "In the same script the normalization and boundarylabeling are done in the same way as the previous datasets.\n",
    "\n",
    "The script is named **Preprocessing_and_merging_annotations_BBBC038.py** and can be found under **1.7 - Scripts**\n",
    "\n",
    "After running the script and looking through the images, some images were not suited for our model, so they were removed. It was done by creating a list with all the images to be removed and the following bash command: \n",
    "\n",
    "Create a doc folder:\n",
    "\n",
    "```bash\n",
    "mkdir 3_data/2_additional_datasets/2_BBBC_image_sets/doc\n",
    "cd 3_data/2_additional_datasets/2_BBBC_image_sets/doc\n",
    "```\n",
    "the content of **filelist_wrong_images.txt** is found under **1.8 Docs**:\n",
    "\n",
    "\n",
    "Put the textfile in the created doc folder, and execute the following command:\n",
    "```bash\n",
    "cat filelist_wrong_images.txt | while read line; do rm ../BBBC038_*/$line; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BBBC Murine bone-marrow derived macrophages:\n",
    "\n",
    "In each in **3_data/2_additional_datasets/2_BBBC_image_sets/BBBC020_v1_images** consists of 3 images, one with the cells, one with the nucleus, and one with the combined images. We are only interested in the images of the nucleus, and need to extract those. These images are the ones with the ending _c5.TIF in their names.\n",
    "\n",
    "The images needs to be converted to grey images, and the mask images needs to be combined as in the BBBC038 dataset.\n",
    "\n",
    "This is all done with the script **Preprocessing_BBBC020.py** which is found under **1.7 - Scripts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Celltracking challenge images (GFP-GOWT1 mouse stem cells, HeLa cells stably expressing H2b-GFP and Simulated nuclei of HL60 cells stained with Hoescht)\n",
    "\n",
    "These images need no specific preprocessing. A script was created to extract, normalize and create boundary labels for all the images in one go. \n",
    "\n",
    "The script is named **Preprocessing_celltracking_images.py** and is found under **1.7 - Scripts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating 5_training.txt: \n",
    "\n",
    "For Model 5, all these images should be used in the training set, together with the images used in Model 4. The below bash commands will create the file **5_training.txt** with all the images, and place it in the folder **2_Final_Models/data/4_filelists**.\n",
    "\n",
    "```bash\n",
    "ls 3_data/2_additional_datasets/2_BBBC_image_sets/BBBC038_normalized_images/ > 2_Final_Models/data/4_filelists/5_training.txt && \n",
    "ls 3_data/2_additional_datasets/2_BBBC_image_sets/BBBC020_normalized_images/ >> 2_Final_Models/data/4_filelists/5_training.txt && \n",
    "ls 3_data/2_additional_datasets/1_celltracking_challenge_data/normalized_images/ >> 2_Final_Models/data/4_filelists/5_training.txt &&\n",
    "cat 2_Final_Models/data/4_filelists/4_training.txt >> 2_Final_Models/data/4_filelists/5_training.txt\n",
    "```\n",
    "For Model 5 we want 500 additional images, but we have 1368 images. To use only 500 images the file **5_training.txt** is randomly sorted and the 500 first lines are used and put in a new textfile using bashcommand:\n",
    "\n",
    "```bash\n",
    "sort -R 2_Final_Models/data/4_filelists/5_training.txt | head -n 500 > 2_Final_Models/data/4_filelists/5_training_500.txt\n",
    "```\n",
    "\n",
    "The list we got and used for this can be found under **1.8 - Docs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving all data to the same folder:\n",
    "\n",
    "After doing the above steps with the preprocessing, all images are ready to use in the model for training. The images should be moved to **2_Final_Models/data/boundary_labels** and **2_Final_Models/data/norm_images**. These folders are created during the preprocessing when running the script **00-load-and-reformat-dataset.py** \n",
    "\n",
    "Moving the files is done using bash command:\n",
    "\n",
    "```bash\n",
    "mv 3_data/2_additional_datasets/1_celltracking_challenge_data/boundary_labels/* 2_Final_Models/data/boundary_labels/\n",
    "\n",
    "mv 3_data/2_additional_datasets/1_celltracking_challenge_data/normalized_images/* 2_Final_Models/data/norm_images/\n",
    "\n",
    "mv 3_data/2_additional_datasets/2_BBBC_image_sets/BBBC020_boundary_labels/* 2_Final_Models/data/boundary_labels/\n",
    "\n",
    "mv 3_data/2_additional_datasets/2_BBBC_image_sets/BBBC020_normalized_images/* 2_Final_Models/data/norm_images/\n",
    "\n",
    "mv 3_data/2_additional_datasets/2_BBBC_image_sets/BBBC038_boundary_labels/* 2_Final_Models/data/boundary_labels/\n",
    "\n",
    "mv 3_data/2_additional_datasets/2_BBBC_image_sets/BBBC038_normalized_images/* 2_Final_Models/data/norm_images/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "\n",
    "For Model 1, the 30 images will be augmented with affine transformation, which is done using script **01-Augmentation.py**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Training\n",
    "\n",
    "The training script looks the same for each model except for the variable \"config_vars['path_files_training']\"\n",
    "and \"experiment_name\", and \"data_partitions\" which are modified as follows:\n",
    "\n",
    "for Model 1, the script is 02-training.py which is found in section 1.7,\n",
    "\n",
    "for Model 2:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "experiment_name = 'Model_2'\n",
    "```\n",
    "\n",
    "for Model 3:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/3_training.txt'\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "experiment_name = 'Model_3'\n",
    "```\n",
    "\n",
    "for Model 4:\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/4_training.txt'\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "experiment_name = 'Model_4'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Prediction\n",
    "\n",
    "As for the training scripts, the prediction scripts look the same for each model except for the variable \"config_vars['path_files_training']\"\n",
    "and \"experiment_name\", which are modified as follows:\n",
    "\n",
    "for Model 1, the script is 03-prediction.py which is found in section 1.7,\n",
    "\n",
    "for Model 2:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "\n",
    "experiment_name = 'Model_2'\n",
    "```\n",
    "\n",
    "for Model 3:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/3_training.txt'\n",
    "\n",
    "experiment_name = 'Model_3'\n",
    "```\n",
    "\n",
    "for Model 4:\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/4_training.txt'\n",
    "\n",
    "experiment_name = 'Model_4'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Evaluation\n",
    "\n",
    "The evaluation script looks the same for each model except for the variable \"config_vars['path_files_training']\"\n",
    "and \"experiment_name\", which are modified as follows:\n",
    "\n",
    "for Model 1, the script is 04-evaluation.py, which is found in section 1.7,\n",
    "\n",
    "for Model 2:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "\n",
    "experiment_name = 'Model_2'\n",
    "```\n",
    "\n",
    "for Model 3:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/3_training.txt'\n",
    "\n",
    "experiment_name = 'Model_3'\n",
    "```\n",
    "\n",
    "for Model 4:\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/4_training.txt'\n",
    "\n",
    "experiment_name = 'Model_4'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### format_convertion.py:\n",
    "\n",
    "```python\n",
    "import argparse\n",
    "import os\n",
    "import os.path\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "#################################### ARGPARSE ##################################\n",
    "usage = 'Enter the directory name where the files to convert are located, what format to convert the files to \\\n",
    "and name a directory where you want the converted files to end up.'\n",
    "parser = argparse.ArgumentParser(description=usage)\n",
    "parser.add_argument(\n",
    "    '-i',\n",
    "    dest = 'infile',\n",
    "    metavar = 'INDIR',\n",
    "    type = str,\n",
    "    help = 'set the directory where the input files are located',\n",
    "    required = True\n",
    "    )\n",
    "parser.add_argument(\n",
    "    '-o',\n",
    "    dest = 'outfile',\n",
    "    metavar = 'OUTDIR',\n",
    "    type = str,\n",
    "    help = 'set the directory to store the converted files',\n",
    "    required = True\n",
    "    )\n",
    "parser.add_argument(\n",
    "    '-ift',\n",
    "    dest = 'input_filetype',\n",
    "    metavar = 'IN_FILETYPE',\n",
    "    type = str,\n",
    "    help = 'Set what format the input files are, e.g C01 png',\n",
    "    required = True\n",
    "    )\n",
    "parser.add_argument(\n",
    "    '-oft',\n",
    "    dest = 'output_filetype',\n",
    "    metavar = 'OUT_FILETYPE',\n",
    "    type = str,\n",
    "    help = 'Chose format to convert to, e.g. tiff or png',\n",
    "    required = True\n",
    "    )\n",
    "args = parser.parse_args()\n",
    "################################################################################\n",
    "\n",
    "# Convert the input to the absolute path\n",
    "input_dir = os.path.abspath(args.infile)\n",
    "output_dir = os.path.abspath(args.outfile)\n",
    "\n",
    "\n",
    "out_filetype = '.{}'.format(args.output_filetype)\n",
    "in_filetype = args.input_filetype\n",
    "\n",
    "# If the output directory does not exist,\n",
    "# a directory will be created with that name.\n",
    "my_file = Path(output_dir)\n",
    "if not my_file.exists():\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# If the path provided is not a directory, raise error\n",
    "if not os.path.isdir(input_dir):\n",
    "    raise argparse.ArgumentTypeError('Input must be a directory')\n",
    "if not os.path.isdir(output_dir):\n",
    "    raise argparse.ArgumentTypeError('Output must be a directory')\n",
    "\n",
    "input_files = []\n",
    "converted_files = []\n",
    "os.chdir(input_dir)\n",
    "for i in os.listdir(input_dir):\n",
    "    if i.split('.')[-1] == in_filetype: # Checks that filename ends with format chosen\n",
    "        input_files.append(input_dir + '/' + i)\n",
    "        converted_files.append(output_dir + '/' + i.split('.')[0] + out_filetype)\n",
    "\n",
    "for i,j in tqdm(zip(input_files,converted_files), total = len(input_files)): # tqdm creates a progressbar to see the progress.\n",
    "    subprocess.run(['bfconvert', '-overwrite', '-nogroup',i,j],stdout = subprocess.PIPE, stderr = subprocess.DEVNULL) #Runs bftools which needs to be preinstalled, output to DEVNULL.\n",
    "    subprocess.run(['convert', i, '-auto-level', '-depth', '16', '-define', 'quantum:format=unsigned', '-type', 'grayscale', j],stdout = subprocess.PIPE, stderr = subprocess.DEVNULL) #Convert images to 16-bits tiff images.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import utils.dirtools\n",
    "\n",
    "config_vars = {}\n",
    "\n",
    "# ************ 01 ************ #\n",
    "# ****** PREPROCESSING ******* #\n",
    "# **************************** #\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.01 INPUT DIRECTORIES AND FILES\n",
    "\n",
    "config_vars[\"root_directory\"] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/'\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.02 DATA PARTITION INFO\n",
    "\n",
    "## Maximum number of training images (use 0 for all)\n",
    "config_vars[\"max_training_images\"] = 0\n",
    "\n",
    "## Generate partitions?\n",
    "## If False, load predefined partitions (training.txt, validation.txt and test.txt)\n",
    "config_vars[\"create_split_files\"] = False\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.03 IMAGE STORAGE OPTIONS\n",
    "\n",
    "## Transform gray scale TIF images to PNG\n",
    "config_vars[\"transform_images_to_PNG\"] = True\n",
    "config_vars[\"pixel_depth\"] = 8\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.04 PRE-PROCESSING OF ANNOTATIONS\n",
    "\n",
    "## Area of minimun object in pixels\n",
    "config_vars[\"min_nucleus_size\"] = 10\n",
    "\n",
    "## Pixels of the boundary (min 2 pixels)\n",
    "config_vars[\"boundary_size\"] = 2\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.05 DATA AUGMENTATION USING ELASTIC DEFORMATIONS\n",
    "\n",
    "## Elastic deformation takes a lot of times to compute. \n",
    "## It is computed only once in the preprocessing. \n",
    "config_vars[\"augment_images\"] =  False\n",
    "\n",
    "## Augmentation parameters. \n",
    "## Calibrate parameters using the 00-elastic-deformation.ipynb\n",
    "config_vars[\"elastic_points\"] = 16\n",
    "config_vars[\"elastic_distortion\"] = 5\n",
    "\n",
    "## Number of augmented images\n",
    "config_vars[\"elastic_augmentations\"] = 10\n",
    "\n",
    "\n",
    "# ************ 02 ************ #\n",
    "# ********* TRAINING ********* #\n",
    "# **************************** #\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 02.01 OPTIMIZATION\n",
    "\n",
    "config_vars[\"learning_rate\"] = 1e-4\n",
    "\n",
    "config_vars[\"epochs\"] = 15\n",
    "\n",
    "config_vars[\"steps_per_epoch\"] = 500\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 02.02 BATCHES\n",
    "\n",
    "config_vars[\"batch_size\"] = 10\n",
    "\n",
    "config_vars[\"val_batch_size\"] = 10\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 02.03 DATA NORMALIZATION\n",
    "\n",
    "config_vars[\"rescale_labels\"] = True\n",
    "\n",
    "config_vars[\"crop_size\"] = 256\n",
    "\n",
    "# ************ 03 ************ #\n",
    "# ******** PREDICTION ******** #\n",
    "# **************************** #\n",
    "\n",
    "config_vars[\"cell_min_size\"] = 30\n",
    "\n",
    "config_vars[\"boundary_boost_factor\"] = 1\n",
    "\n",
    "# ************ 04 ************ #\n",
    "# ******** EVALUATION ******** #\n",
    "# **************************** #\n",
    "\n",
    "config_vars[\"object_dilation\"] = 3\n",
    "\n",
    "# **************************** #\n",
    "# ******** FINAL SETUP ******* #\n",
    "# **************************** #\n",
    "\n",
    "config_vars = utils.dirtools.setup_working_directories(config_vars)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00-load-and-reformat-dataset.py\n",
    "\n",
    "```python\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import requests\n",
    "from config import config_vars\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "import utils.dirtools\n",
    "import utils.augmentation\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2lab\n",
    "\n",
    "# Create output directories for transformed data\n",
    "\n",
    "os.makedirs(config_vars[\"normalized_images_dir\"], exist_ok=True)\n",
    "os.makedirs(config_vars[\"boundary_labels_dir\"], exist_ok=True)\n",
    "\n",
    "config_vars[\"raw_images_dir\"]='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/2_raw_images/'\n",
    "config_vars[\"raw_annotations_dir\"]='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/1_raw_annotations/'\n",
    "\n",
    "# ## Normalize images\n",
    "\n",
    "if config_vars[\"transform_images_to_PNG\"]:\n",
    "    \n",
    "    filelist = sorted(os.listdir(config_vars[\"raw_images_dir\"]))\n",
    "\n",
    "    # run over all raw images\n",
    "    for filename in tqdm(filelist):\n",
    "\n",
    "        # load image and its annotation\n",
    "        orig_img = skimage.io.imread(config_vars[\"raw_images_dir\"] + filename)       \n",
    "\n",
    "        # IMAGE\n",
    "\n",
    "        # normalize to [0,1]\n",
    "        percentile = 99.9\n",
    "        high = np.percentile(orig_img, percentile)\n",
    "        low = np.percentile(orig_img, 100-percentile)\n",
    "\n",
    "        img = np.minimum(high, orig_img)\n",
    "        img = np.maximum(low, img)\n",
    "\n",
    "        img = (img - low) / (high - low) # gives float64, thus cast to 8 bit later\n",
    "        img = skimage.img_as_ubyte(img) \n",
    "\n",
    "        skimage.io.imsave(config_vars[\"normalized_images_dir\"] + filename[:-3] + 'png', img)    \n",
    "else:\n",
    "    config_vars[\"normalized_images_dir\"] = config_vars[\"raw_images_dir\"]\n",
    "\n",
    "# ## Create boundary labels\n",
    "\n",
    "filelist = sorted(os.listdir(config_vars[\"raw_annotations_dir\"]))\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2lab\n",
    "total_objects = 0\n",
    "\n",
    "# run over all raw images\n",
    "for filename in tqdm(filelist):\n",
    "    \n",
    "    # GET ANNOTATION\n",
    "    annot = skimage.io.imread(config_vars[\"raw_annotations_dir\"] + filename)\n",
    "\n",
    "    # strip the first channel\n",
    "    if annot.shape[2]!=3:\n",
    "        annot = annot[:,:,0]\n",
    "    else:\n",
    "        annot = rgb2lab(annot)\n",
    "        annot = annot[:,:,0]\n",
    "    # label the annotations nicely to prepare for future filtering operation\n",
    "    \n",
    "    annot = skimage.morphology.label(annot)\n",
    "    total_objects += len(np.unique(annot)) - 1\n",
    "      \n",
    "    # find boundaries\n",
    "    boundaries = skimage.segmentation.find_boundaries(annot, mode = 'outer')\n",
    "\n",
    "    # BINARY LABEL\n",
    "    \n",
    "    # prepare buffer for binary label\n",
    "    label_binary = np.zeros((annot.shape + (3,)))\n",
    "    \n",
    "    # write binary label\n",
    "    label_binary[(annot == 0) & (boundaries == 0), 0] = 1\n",
    "    label_binary[(annot != 0) & (boundaries == 0), 1] = 1\n",
    "    label_binary[boundaries == 1, 2] = 1\n",
    "    \n",
    "    label_binary = img_as_ubyte(label_binary)\n",
    "    # save it - converts image to range from 0 to 255\n",
    "    skimage.io.imsave(config_vars[\"boundary_labels_dir\"] + filename, label_binary)\n",
    "    \n",
    "print(\"Total objects: \",total_objects)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-Augmentation.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "from config import config_vars\n",
    "import utils.dirtools\n",
    "import utils.augmentation\n",
    "\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "\n",
    "# ## Augment (elastic transformation)\n",
    "\n",
    "config_vars[\"augment_images\"] = True\n",
    "def generate_augmented_examples(filelist, n_augmentations, n_points, distort, dir_boundary_labels, dir_images_normalized_8bit):\n",
    "    \n",
    "    updated_filelist = []\n",
    "    \n",
    "    # run over all raw images\n",
    "    for filename in tqdm(filelist):\n",
    "        print(\"Augmenting {}\".format(filename))\n",
    "            \n",
    "        # check if boundary labels were calculated \n",
    "        my_file = pathlib.Path(dir_boundary_labels + filename)\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            \n",
    "            # load image \n",
    "            x = skimage.io.imread(dir_images_normalized_8bit + filename)\n",
    "            \n",
    "            # load annotation \n",
    "            y = skimage.io.imread(dir_boundary_labels + filename)\n",
    "            \n",
    "            for n in range(1,n_augmentations):\n",
    "                # augment image and annotation \n",
    "                x_augmented, y_augmented = utils.augmentation.deform(x, y, points = n_points, distort = distort)\n",
    "                \n",
    "                # filename for augmented images\n",
    "                filename_augmented = os.path.splitext(filename)[0] + '_aug_{:03d}'.format(n) + os.path.splitext(filename)[1]\n",
    "                skimage.io.imsave(dir_images_normalized_8bit + filename_augmented, x_augmented)\n",
    "                skimage.io.imsave(dir_boundary_labels + filename_augmented, y_augmented)\n",
    "                updated_filelist.append(filename_augmented)\n",
    "                \n",
    "    return filelist + updated_filelist \n",
    "\n",
    "if config_vars[\"augment_images\"]:\n",
    "    \n",
    "    tmp_value = config_vars[\"max_training_images\"]\n",
    "    config_vars[\"max_training_images\"] = 0\n",
    "    tmp_partitions = utils.dirtools.read_data_partitions(config_vars, load_augmented=False)\n",
    "    \n",
    "    training_files = generate_augmented_examples(\n",
    "        tmp_partitions[\"training\"], \n",
    "        config_vars[\"elastic_augmentations\"], \n",
    "        config_vars[\"elastic_points\"], \n",
    "        config_vars[\"elastic_distortion\"], \n",
    "        config_vars[\"boundary_labels_dir\"], \n",
    "        config_vars[\"normalized_images_dir\"]\n",
    "    )\n",
    "    \n",
    "    config_vars[\"max_training_images\"] = tmp_value\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02-training.py\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend\n",
    "import keras.callbacks\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.optimizers\n",
    "\n",
    "import utils.model_builder\n",
    "import utils.data_provider\n",
    "import utils.metrics\n",
    "import utils.objectives\n",
    "import utils.dirtools\n",
    "\n",
    "from config import config_vars\n",
    "\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "experiment_name = 'Model_1'\n",
    "\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars, load_augmented = False)\n",
    "\n",
    "\n",
    "# build session running on GPU 1\n",
    "configuration = tf.compat.v1.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"1\"\n",
    "session = tf.compat.v1.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "train_gen = utils.data_provider.random_sample_generator(\n",
    "    config_vars[\"normalized_images_dir\"],\n",
    "    config_vars[\"boundary_labels_dir\"],\n",
    "    data_partitions[\"training\"],\n",
    "    config_vars[\"batch_size\"],\n",
    "    config_vars[\"pixel_depth\"],\n",
    "    config_vars[\"crop_size\"],\n",
    "    config_vars[\"crop_size\"],\n",
    "    config_vars[\"rescale_labels\"]\n",
    ")\n",
    "\n",
    "val_gen = utils.data_provider.single_data_from_images(\n",
    "     config_vars[\"normalized_images_dir\"],\n",
    "     config_vars[\"boundary_labels_dir\"],\n",
    "     data_partitions[\"validation\"],\n",
    "     config_vars[\"val_batch_size\"],\n",
    "     config_vars[\"pixel_depth\"],\n",
    "     config_vars[\"crop_size\"],\n",
    "     config_vars[\"crop_size\"],\n",
    "     config_vars[\"rescale_labels\"]\n",
    ")\n",
    "\n",
    "\n",
    "# build model\n",
    "model = utils.model_builder.get_model_3_class(config_vars[\"crop_size\"], config_vars[\"crop_size\"], activation=None)\n",
    "model.summary()\n",
    "\n",
    "#loss = \"categorical_crossentropy\"\n",
    "loss = utils.objectives.weighted_crossentropy\n",
    "\n",
    "metrics = [keras.metrics.categorical_accuracy, \n",
    "           utils.metrics.channel_recall(channel=0, name=\"background_recall\"), \n",
    "           utils.metrics.channel_precision(channel=0, name=\"background_precision\"),\n",
    "           utils.metrics.channel_recall(channel=1, name=\"interior_recall\"), \n",
    "           utils.metrics.channel_precision(channel=1, name=\"interior_precision\"),\n",
    "           utils.metrics.channel_recall(channel=2, name=\"boundary_recall\"), \n",
    "           utils.metrics.channel_precision(channel=2, name=\"boundary_precision\"),\n",
    "          ]\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=config_vars[\"learning_rate\"])\n",
    "\n",
    "model.compile(loss=loss, metrics=metrics, optimizer=optimizer)\n",
    "\n",
    "# Performance logging\n",
    "callback_csv = keras.callbacks.CSVLogger(filename=config_vars[\"csv_log_file\"])\n",
    "\n",
    "callbacks=[callback_csv]\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "statistics = model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    steps_per_epoch=config_vars[\"steps_per_epoch\"],\n",
    "    epochs=config_vars[\"epochs\"],\n",
    "#    epochs = 3,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=int(len(data_partitions[\"validation\"])/config_vars[\"val_batch_size\"]),\n",
    "    callbacks=callbacks,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "model.save_weights(config_vars[\"model_file\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-prediction.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import utils.metrics\n",
    "import utils.model_builder\n",
    "print(skimage.__version__)\n",
    "\n",
    "\n",
    "# # Configuration\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from config import config_vars\n",
    "\n",
    "# Partition of the data to make predictions (test or validation)\n",
    "\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "partition = \"validation\"\n",
    "\n",
    "experiment_name = 'Model_1'\n",
    "\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "\n",
    "# Configuration to run on GPU\n",
    "configuration = tf.compat.v1.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"0\"\n",
    "\n",
    "session = tf.compat.v1.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "\n",
    "# # Load images and run predictions\n",
    "\n",
    "image_names = [os.path.join(config_vars[\"normalized_images_dir\"], f) for f in data_partitions[partition]]\n",
    "\n",
    "imagebuffer = skimage.io.imread_collection(image_names)\n",
    "\n",
    "images = imagebuffer.concatenate()\n",
    "\n",
    "dim1 = images.shape[1]\n",
    "dim2 = images.shape[2]\n",
    "\n",
    "images = images.reshape((-1, dim1, dim2, 1))\n",
    "\n",
    "# preprocess (assuming images are encoded as 8-bits in the preprocessing step)\n",
    "images = images / 255\n",
    "\n",
    "# build model and load weights\n",
    "model = utils.model_builder.get_model_3_class(dim1, dim2)\n",
    "model.load_weights(config_vars[\"model_file\"])\n",
    "\n",
    "# Normal prediction time\n",
    "predictions = model.predict(images, batch_size=1)\n",
    "\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Code inspired by scikit-images source-code for skimage.morphology.remove_small_objects()\n",
    "def remove_large_objects(image, min_size):\n",
    "    out = np.copy(image)\n",
    "    \n",
    "    if out.dtype == bool:\n",
    "        selem = ndi.generate_binary_structure(image.ndim,1)\n",
    "        ccs = np.zeros_like(image, dtype=np.int32)\n",
    "        ndi.label(image, selem, output=ccs)\n",
    "    else:\n",
    "        ccs = out\n",
    "    component_sizes = np.bincount(ccs.ravel())\n",
    "    too_large = component_sizes > min_size\n",
    "    too_large_mask = too_large[ccs]\n",
    "    out[too_large_mask] = 0\n",
    "    return out\n",
    "\n",
    "def pred_to_label(pred, cell_min_size, cell_label=1):\n",
    "    # Only marks interior of cells (cell_label = 1 is interior, cell_label = 2 is boundary)\n",
    "    cell_orig = (pred == cell_label)\n",
    "    \n",
    "    cell_small = (pred == 1) + (pred == 2)\n",
    "    cell_small = remove_large_objects(cell_small,100) \n",
    "    \n",
    "    cell_concat = cell_orig + cell_small\n",
    "    \n",
    "    cell_orig = skimage.morphology.remove_small_holes(cell_concat, area_threshold=cell_min_size)\n",
    "    cell_orig = skimage.morphology.remove_small_objects(cell_concat, min_size=cell_min_size)\n",
    "    # label cells only\n",
    "    [label, num] = skimage.morphology.label(cell_orig, return_num=True)\n",
    "    return label\n",
    "\n",
    "\n",
    "# # Transform predictions to label matrices\n",
    "\n",
    "for i in range(len(images)):\n",
    "\n",
    "    filename = imagebuffer.files[i]\n",
    "    filename = os.path.basename(filename)\n",
    "    \n",
    "    probmap = predictions[i].squeeze()\n",
    "    \n",
    "    skimage.io.imsave(config_vars[\"probmap_out_dir\"] + filename, probmap)\n",
    "    \n",
    "    pred = np.argmax(probmap * [1, 1, 1], -1)\n",
    "    \n",
    "    label = pred_to_label(pred, config_vars[\"cell_min_size\"])\n",
    "    \n",
    "    skimage.io.imsave(config_vars[\"labels_out_dir\"] + filename, label)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-evaluation.ipynb\n",
    "\n",
    "```python\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "\n",
    "import utils.evaluation\n",
    "from config import config_vars\n",
    "\n",
    "\n",
    "# Partition of the data to make predictions (test or validation)\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "partition = \"validation\"\n",
    "\n",
    "experiment_name = 'Model_1'\n",
    "\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "\n",
    "# Display prediction along with segmentation to visualize errors\n",
    "\n",
    "def show(ground_truth, prediction, threshold=0.5, image_name=\"N\"):\n",
    "    \n",
    "    # Compute Intersection over Union\n",
    "    IOU = utils.evaluation.intersection_over_union(ground_truth, prediction)\n",
    "    \n",
    "    # Create diff map\n",
    "    diff = np.zeros(ground_truth.shape + (3,))\n",
    "    A = ground_truth.copy()\n",
    "    B = prediction.copy()\n",
    "    A[A > 0] = 1\n",
    "    B[B > 0] = 1\n",
    "    D = A - B\n",
    "    #diff[D > 0,:2] = 1\n",
    "    #diff[D < 0,1:] = 1\n",
    "    \n",
    "    # Object-level errors\n",
    "    C = IOU.copy()\n",
    "    C[C>=threshold] = 1\n",
    "    C[C<threshold] = 0\n",
    "    missed = np.where(np.sum(C,axis=1) == 0)[0]\n",
    "    extra = np.where(np.sum(C,axis=0) == 0)[0]\n",
    "\n",
    "    for m in missed:\n",
    "        diff[ground_truth == m+1, 0] = 1\n",
    "    for e in extra:\n",
    "        diff[prediction == e+1, 2] = 1\n",
    "    \n",
    "    # Display figures\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18,6))\n",
    "    ax[0].imshow(ground_truth)\n",
    "    ax[0].set_title(\"True objects:\"+str(len(np.unique(ground_truth))))\n",
    "    ax[1].imshow(diff)\n",
    "    ax[1].set_title(\"Segmentation errors:\"+str(len(missed)))\n",
    "    ax[2].imshow(prediction)\n",
    "    ax[2].set_title(\"Predicted objects:\"+str(len(np.unique(prediction))))\n",
    "    ax[3].imshow(IOU)\n",
    "    ax[3].set_title(image_name)\n",
    "\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Code inspired by scikit-images source-code for skimage.morphology.remove_small_objects()\n",
    "def remove_large_objects(image, min_size):\n",
    "    out = np.copy(image)\n",
    "    \n",
    "    if out.dtype == bool:\n",
    "        selem = ndi.generate_binary_structure(image.ndim,1)\n",
    "        ccs = np.zeros_like(image, dtype=np.int32)\n",
    "        ndi.label(image, selem, output=ccs)\n",
    "    else:\n",
    "        ccs = out\n",
    "    component_sizes = np.bincount(ccs.ravel())\n",
    "    too_large = component_sizes > min_size\n",
    "    too_large_mask = too_large[ccs]\n",
    "    out[too_large_mask] = 0\n",
    "    return out\n",
    "\n",
    "def pred_to_label(pred, cell_min_size, cell_label=1):\n",
    "    # Only marks interior of cells (cell_label = 1 is interior, cell_label = 2 is boundary)\n",
    "    cell_orig = (pred == cell_label)\n",
    "    \n",
    "    cell_small = (pred == 1) + (pred == 2)\n",
    "    cell_small = remove_large_objects(cell_small,100) \n",
    "    \n",
    "    cell_concat = cell_orig + cell_small\n",
    "    \n",
    "    cell_orig = skimage.morphology.remove_small_holes(cell_concat, area_threshold=cell_min_size)\n",
    "    cell_orig = skimage.morphology.remove_small_objects(cell_concat, min_size=cell_min_size)\n",
    "    # label cells only\n",
    "    [label, num] = skimage.morphology.label(cell_concat, return_num=True)\n",
    "    return label\n",
    "\n",
    "\n",
    "# Run the evaluation\n",
    "\n",
    "l_images = data_partitions[partition]\n",
    "from skimage.color import rgb2gray,rgb2lab\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Image\", \"Threshold\", \"F1\", \"Jaccard\", \"TP\", \"FP\", \"FN\"])\n",
    "false_negatives = pd.DataFrame(columns=[\"False_Negative\", \"Area\"])\n",
    "splits_merges = pd.DataFrame(columns=[\"Image_Name\", \"Merges\", \"Splits\"])\n",
    "\n",
    "for image_name in all_images:\n",
    "    # Load ground truth data\n",
    "    img_filename = os.path.join(config_vars[\"boundary_labels_dir\"], image_name)\n",
    "    ground_truth = skimage.io.imread(img_filename)\n",
    "    ground_truth = ground_truth.squeeze()\n",
    "    #if len(ground_truth.shape) == 3:\n",
    "    #    ground_truth = rgb2lab(ground_truth)\n",
    "    #    ground_truth = ground_truth[:,:,0]\n",
    "    \n",
    "    ground_truth = np.argmax(ground_truth * [1, 1, 1], -1)\n",
    "    \n",
    "    ground_truth = pred_to_label(ground_truth, config_vars[\"cell_min_size\"])\n",
    "    # Transform to label matrix\n",
    "    #ground_truth = skimage.morphology.label(ground_truth)\n",
    "    \n",
    "    # Load predictions\n",
    "    pred_filename = os.path.join(config_vars[\"labels_out_dir\"], image_name)\n",
    "    prediction = skimage.io.imread(pred_filename)\n",
    "    \n",
    "    # Apply object dilation\n",
    "    if config_vars[\"object_dilation\"] > 0:\n",
    "        struct = skimage.morphology.square(config_vars[\"object_dilation\"])\n",
    "        prediction = skimage.morphology.dilation(prediction, struct)\n",
    "    elif config_vars[\"object_dilation\"] < 0:\n",
    "        struct = skimage.morphology.square(-config_vars[\"object_dilation\"])\n",
    "        prediction = skimage.morphology.erosion(prediction, struct)\n",
    "        \n",
    "    # Relabel objects (cut margin of 30 pixels to make a fair comparison with DeepCell)\n",
    "    ground_truth = skimage.segmentation.relabel_sequential(ground_truth)[0] #[30:-30,30:-30])[0]\n",
    "    prediction = skimage.segmentation.relabel_sequential(prediction)[0] #[30:-30,30:-30])[0]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    results = utils.evaluation.compute_af1_results(\n",
    "        ground_truth, \n",
    "        prediction, \n",
    "        results, \n",
    "        image_name\n",
    "    )\n",
    "    \n",
    "    false_negatives = utils.evaluation.get_false_negatives(\n",
    "        ground_truth, \n",
    "        prediction, \n",
    "        false_negatives, \n",
    "        image_name\n",
    "    )\n",
    "    \n",
    "    splits_merges = utils.evaluation.get_splits_and_merges(\n",
    "        ground_truth, \n",
    "        prediction, \n",
    "        splits_merges, \n",
    "        image_name\n",
    "    )\n",
    "    \n",
    "    # Display an example image\n",
    "    #if image_name == all_images[0]:\n",
    "    show(ground_truth, prediction, image_name=image_name)\n",
    "\n",
    "\n",
    "# Display accuracy results\n",
    "\n",
    "average_performance = results.groupby(\"Threshold\").mean().reset_index()\n",
    "\n",
    "R = results.groupby(\"Image\").mean().reset_index()\n",
    "g = sb.jointplot(data=R[R[\"F1\"] > 0.4], x=\"Jaccard\", y=\"F1\")\n",
    "\n",
    "average_performance\n",
    "R.sort_values(by=\"F1\",ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# Plot accuracy results\n",
    "\n",
    "sb.regplot(data=average_performance, x=\"Threshold\", y=\"F1\", order=3, ci=None)\n",
    "average_performance\n",
    "\n",
    "\n",
    "\n",
    "# Compute and print Average F1\n",
    "\n",
    "average_F1_score = average_performance[\"F1\"].mean()\n",
    "jaccard_index = average_performance[\"Jaccard\"].mean()\n",
    "print(\"Average F1 score:\", average_F1_score)\n",
    "print(\"Jaccard index:\", jaccard_index)\n",
    "\n",
    "# Summarize False Negatives by area\n",
    "\n",
    "false_negatives = false_negatives[false_negatives[\"False_Negative\"] == 1]\n",
    "\n",
    "false_negatives.groupby(\n",
    "    pd.cut(\n",
    "        false_negatives[\"Area\"], \n",
    "        [0,250,625,900,10000], # Area intervals\n",
    "        labels=[\"Tiny nuclei\",\"Small nuclei\",\"Normal nuclei\",\"Large nuclei\"],\n",
    "    )\n",
    ")[\"False_Negative\"].sum()\n",
    "\n",
    "\n",
    "# Summarize splits and merges\n",
    "\n",
    "print(\"Splits:\",np.sum(splits_merges[\"Splits\"]))\n",
    "print(\"Merges:\",np.sum(splits_merges[\"Merges\"]))\n",
    "\n",
    "# Report false positives\n",
    "\n",
    "print(\"Extra objects (false postives):\",results[results[\"Threshold\"].round(3) == 0.7].sum()[\"FP\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentation.py\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "from skimage.util import img_as_ubyte\n",
    "# Based on example code from:\n",
    "# http://scikit-image.org/docs/dev/auto_examples/transform/plot_piecewise_affine.html\n",
    "\n",
    "def deform(image1, image2, points=10, distort=5.0):\n",
    "    \n",
    "    # create deformation grid \n",
    "    rows, cols = image1.shape[0], image1.shape[1]\n",
    "    src_cols = np.linspace(0, cols, points)\n",
    "    src_rows = np.linspace(0, rows, points)\n",
    "    src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "    src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    # add distortion to coordinates\n",
    "    s = src[:, 1].shape\n",
    "    dst_rows = src[:, 1] + np.random.normal(size=s)*np.random.uniform(0.0, distort, size=s)\n",
    "    dst_cols = src[:, 0] + np.random.normal(size=s)*np.random.uniform(0.0, distort, size=s)\n",
    "    \n",
    "    dst = np.vstack([dst_cols, dst_rows]).T\n",
    "\n",
    "    tform = skimage.transform.PiecewiseAffineTransform()\n",
    "    tform.estimate(src, dst)\n",
    "\n",
    "    out_rows = rows \n",
    "    out_cols = cols\n",
    "    out1 = skimage.transform.warp(image1, tform, output_shape=(out_rows, out_cols), mode=\"symmetric\")\n",
    "    out2 = skimage.transform.warp(image2, tform, output_shape=(out_rows, out_cols), mode=\"symmetric\")\n",
    "    \n",
    "    return img_as_ubyte(out1), img_as_ubyte(out2)\n",
    "\n",
    "\n",
    "def resize(x, y):\n",
    "    wf = 1 + np.random.uniform(-0.25, 0.25)\n",
    "    hf = 1 + np.random.uniform(-0.25, 0.25)\n",
    "\n",
    "    w,h = x.shape[0:2]\n",
    "\n",
    "    wt, ht = int(wf*w), int(hf*h)\n",
    "\n",
    "    new_x = skimage.transform.resize(x, (wt,ht))\n",
    "    new_y = skimage.transform.resize(y, (wt,ht))\n",
    "\n",
    "    return new_x, new_y\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_provider.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io\n",
    "import keras.preprocessing.image\n",
    "\n",
    "import utils.augmentation\n",
    "\n",
    "\n",
    "def setup_working_directories(config_vars):\n",
    "\n",
    "    ## Expected raw data directories:\n",
    "    config_vars[\"raw_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_images/')\n",
    "    config_vars[\"raw_annotations_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_annotations/')\n",
    "\n",
    "    ## Split files\n",
    "    config_vars[\"path_files_training\"] = os.path.join(config_vars[\"root_directory\"], 'training.txt')\n",
    "    config_vars[\"path_files_validation\"] = os.path.join(config_vars[\"root_directory\"], 'validation.txt')\n",
    "    config_vars[\"path_files_test\"] = os.path.join(config_vars[\"root_directory\"], 'test.txt')\n",
    "\n",
    "    ## Transformed data directories:\n",
    "    config_vars[\"normalized_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'norm_images/')\n",
    "    config_vars[\"boundary_labels_dir\"] = os.path.join(config_vars[\"root_directory\"], 'boundary_labels/')\n",
    "\n",
    "    return config_vars\n",
    "\n",
    "def single_data_from_images(x_dir, y_dir, image_names, batch_size, bit_depth, dim1, dim2, rescale_labels):\n",
    "\n",
    "    ## Prepare image names\n",
    "    x_image_names = [os.path.join(x_dir, f) for f in image_names]\n",
    "    y_image_names = [os.path.join(y_dir, f) for f in image_names]\n",
    "\n",
    "    ## Load all images in memory\n",
    "    x = skimage.io.imread_collection(x_image_names).concatenate()\n",
    "    y = skimage.io.imread_collection(y_image_names).concatenate()\n",
    "\n",
    "    ## Crop the desired size\n",
    "    x = x[:, 0:dim1, 0:dim2]\n",
    "    x = x.reshape(-1, dim1, dim2, 1)\n",
    "    y = y[:, 0:dim1, 0:dim2, :]\n",
    "\n",
    "    ## Setup Keras Generators\n",
    "    rescale_factor = 1./(2**bit_depth - 1)\n",
    "    \n",
    "    if(rescale_labels):\n",
    "        rescale_factor_labels = rescale_factor\n",
    "    else:\n",
    "        rescale_factor_labels = 1\n",
    "\n",
    "    gen_x = keras.preprocessing.image.ImageDataGenerator(rescale=rescale_factor)\n",
    "    gen_y = keras.preprocessing.image.ImageDataGenerator(rescale=rescale_factor_labels)\n",
    "    \n",
    "    seed = 42\n",
    "\n",
    "    stream_x = gen_x.flow(\n",
    "        x,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    stream_y = gen_y.flow(\n",
    "        y,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    flow = zip(stream_x, stream_y)\n",
    "    \n",
    "    return flow\n",
    "\n",
    "\n",
    "def random_sample_generator(x_dir, y_dir, image_names, batch_size, bit_depth, dim1, dim2, rescale_labels):\n",
    "\n",
    "    do_augmentation = True\n",
    "    \n",
    "    # get image names\n",
    "    print('Training with',len(image_names), 'images.')\n",
    "\n",
    "    # get dimensions right -- understand data set\n",
    "    n_images = len(image_names)\n",
    "    ref_img = skimage.io.imread(os.path.join(y_dir, image_names[0]))\n",
    "\n",
    "    if(len(ref_img.shape) == 2):\n",
    "        gray = True\n",
    "    else:\n",
    "        gray = False\n",
    "    \n",
    "    # rescale images\n",
    "    rescale_factor = 1./(2**bit_depth - 1)\n",
    "    if(rescale_labels):\n",
    "        rescale_factor_labels = rescale_factor\n",
    "    else:\n",
    "        rescale_factor_labels = 1\n",
    "        \n",
    "    while(True):\n",
    "        \n",
    "        if(gray):\n",
    "            y_channels = 1\n",
    "        else:\n",
    "            y_channels = 3\n",
    "            \n",
    "        # buffers for a batch of data\n",
    "        x = np.zeros((batch_size, dim1, dim2, 1))\n",
    "        y = np.zeros((batch_size, dim1, dim2, y_channels))\n",
    "        \n",
    "        # get one image at a time\n",
    "        for i in range(batch_size):\n",
    "                       \n",
    "            # get random image\n",
    "            img_index = np.random.randint(low=0, high=n_images)\n",
    "            \n",
    "            # open images\n",
    "            x_big = skimage.io.imread(os.path.join(x_dir, image_names[img_index])) * rescale_factor\n",
    "            y_big = skimage.io.imread(os.path.join(y_dir, image_names[img_index])) * rescale_factor_labels\n",
    "\n",
    "            # resizing\n",
    "            #x_big, y_big = utils.augmentation.resize(patch_x, patch_y)\n",
    "\n",
    "\n",
    "            # get random crop\n",
    "            start_dim1 = np.random.randint(low=0, high=x_big.shape[0] - dim1)\n",
    "            start_dim2 = np.random.randint(low=0, high=x_big.shape[1] - dim2)\n",
    "\n",
    "            patch_x = x_big[start_dim1:start_dim1 + dim1, start_dim2:start_dim2 + dim2] #* rescale_factor\n",
    "            patch_y = y_big[start_dim1:start_dim1 + dim1, start_dim2:start_dim2 + dim2] #* rescale_factor_labels\n",
    "\n",
    "            if(do_augmentation):\n",
    "                \n",
    "                rand_flip = np.random.randint(low=0, high=2)\n",
    "                rand_rotate = np.random.randint(low=0, high=4)\n",
    "                \n",
    "                # flip\n",
    "                if(rand_flip == 0):\n",
    "                    patch_x = np.flip(patch_x, 0)\n",
    "                    patch_y = np.flip(patch_y, 0)\n",
    "                \n",
    "                # rotate\n",
    "                for rotate_index in range(rand_rotate):\n",
    "                    patch_x = np.rot90(patch_x)\n",
    "                    patch_y = np.rot90(patch_y)\n",
    "\n",
    "                # illumination\n",
    "                ifactor = 1 + np.random.uniform(-0.75, 0.75)\n",
    "                patch_x *= ifactor\n",
    "                    \n",
    "            # save image to buffer\n",
    "            x[i, :, :, 0] = patch_x\n",
    "            \n",
    "            if(gray):\n",
    "                y[i, :, :, 0] = patch_y\n",
    "            else:\n",
    "                y[i, :, :, 0:y_channels] = patch_y\n",
    "            \n",
    "        # return the buffer\n",
    "        yield(x, y)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dirtools.py \n",
    "\n",
    "```python\n",
    "import os\n",
    "import glob\n",
    "import random \n",
    "\n",
    "def create_image_lists(dir_raw_images, fraction_train = 0.5, fraction_validation = 0.25):\n",
    "    file_list = os.listdir(dir_raw_images)\n",
    "\n",
    "    if (fraction_train + fraction_validation >= 1):\n",
    "        print(\"fraction_train + fraction_validation is > 1!\")\n",
    "        print(\"setting fraction_train = 0.5, fraction_validation = 0.25\")\n",
    "        fraction_train = 0.5\n",
    "        fraction_validation = 0.25\n",
    "        \n",
    "    fraction_test = 1 - fraction_train - fraction_validation\n",
    "\n",
    "    image_list = [x for x in file_list if x.endswith(\"png\") ]\n",
    "\n",
    "    random.shuffle(image_list)\n",
    "\n",
    "    index_train_end = int( len(image_list) * fraction_train)\n",
    "    index_validation_end = index_train_end + int(len(image_list) * fraction_validation)\n",
    "\n",
    "    # split into two parts for training and testing \n",
    "    image_list_train = image_list[0:index_train_end]\n",
    "    image_list_test = image_list[index_train_end:(index_validation_end)]\n",
    "    image_list_validation = image_list[index_validation_end:]\n",
    "    return(image_list_train, image_list_test, image_list_validation)\n",
    "\n",
    "\n",
    "def write_path_files(file_path, list):\n",
    "    with open(file_path, 'w') as myfile:\n",
    "        for line in  list: myfile.write(line + '\\n')\n",
    "\n",
    "\n",
    "def setup_working_directories(config_vars):\n",
    "\n",
    "    ## Expected raw data directories:\n",
    "    config_vars[\"raw_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_images/')\n",
    "    config_vars[\"raw_annotations_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_annotations/')\n",
    "\n",
    "    ## Split files\n",
    "    config_vars[\"path_files_training\"] = os.path.join(config_vars[\"root_directory\"], 'training.txt')\n",
    "    config_vars[\"path_files_validation\"] = os.path.join(config_vars[\"root_directory\"], 'validation.txt')\n",
    "    config_vars[\"path_files_test\"] = os.path.join(config_vars[\"root_directory\"], 'test.txt')\n",
    "\n",
    "    ## Transformed data directories:\n",
    "    config_vars[\"normalized_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'norm_images/')\n",
    "    config_vars[\"boundary_labels_dir\"] = os.path.join(config_vars[\"root_directory\"], 'boundary_labels/')\n",
    "\n",
    "    return config_vars\n",
    "\n",
    "\n",
    "def read_data_partitions(config_vars, load_augmented=True):\n",
    "    with open(config_vars[\"path_files_training\"]) as f:\n",
    "        training_files = f.read().splitlines()\n",
    "        if config_vars[\"max_training_images\"] > 0:\n",
    "            random.shuffle(training_files)\n",
    "            training_files = training_files[0:config_vars[\"max_training_images\"]]\n",
    "        \n",
    "    with open(config_vars[\"path_files_validation\"]) as f:\n",
    "        validation_files = f.read().splitlines()\n",
    "    \n",
    "    with open(config_vars[\"path_files_test\"]) as f:\n",
    "        test_files = f.read().splitlines()\n",
    "\n",
    "    # Add augmented images to the training list\n",
    "    if load_augmented:\n",
    "        files = glob.glob(config_vars[\"root_directory\"] + \"norm_images/*_aug_*.png\")\n",
    "        files = [f.split(\"/\")[-1] for f in files]\n",
    "        augmentedtraining = []\n",
    "        augmentedvalidation = []\n",
    "        for trf in training_files:\n",
    "            augmentedtraining += [f for f in files if f.startswith(trf.split(\".\")[0])]\n",
    "        training_files += augmentedtraining\n",
    "        #for vlf in validation_files:\n",
    "        #    augmentedvalidation += [f for f in files if f.startswith(vlf.split(\".\")[0])]\n",
    "        #validation_files += augmentedvalidation\n",
    "        #else:\n",
    "         #   training_files += files\n",
    "\n",
    "    partitions = {\n",
    "        \"training\": training_files,\n",
    "        \"validation\": validation_files,\n",
    "        \"test\": test_files\n",
    "    }\n",
    "\n",
    "    return partitions\n",
    "\n",
    "def setup_experiment(config_vars, tag):\n",
    "\n",
    "    # Output dirs\n",
    "    config_vars[\"experiment_dir\"] = os.path.join(config_vars[\"root_directory\"], \"experiments/\" + tag + \"/out/\")\n",
    "    config_vars[\"probmap_out_dir\"] = os.path.join(config_vars[\"experiment_dir\"], \"prob/\")\n",
    "    config_vars[\"labels_out_dir\"] = os.path.join(config_vars[\"experiment_dir\"], \"segm/\")\n",
    "\n",
    "    # Files\n",
    "    config_vars[\"model_file\"] = config_vars[\"root_directory\"] + \"experiments/\" + tag + \"/model.hdf5\"\n",
    "    config_vars[\"csv_log_file\"] = config_vars[\"root_directory\"] + \"experiments/\" + tag + \"/log.csv\"\n",
    "\n",
    "    # Make output directories\n",
    "    os.makedirs(config_vars[\"experiment_dir\"], exist_ok=True)\n",
    "    os.makedirs(config_vars[\"probmap_out_dir\"], exist_ok=True)\n",
    "    os.makedirs(config_vars[\"labels_out_dir\"], exist_ok=True)\n",
    "\n",
    "    return config_vars\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation.py\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def intersection_over_union(ground_truth, prediction):\n",
    "    \n",
    "    # Count objects\n",
    "    true_objects = len(np.unique(ground_truth))\n",
    "    pred_objects = len(np.unique(prediction))\n",
    "    \n",
    "    # Compute intersection\n",
    "    h = np.histogram2d(ground_truth.flatten(), prediction.flatten(), bins=(true_objects,pred_objects))\n",
    "    intersection = h[0]\n",
    "    \n",
    "    # Area of objects\n",
    "    area_true = np.histogram(ground_truth, bins=true_objects)[0]\n",
    "    area_pred = np.histogram(prediction, bins=pred_objects)[0]\n",
    "    \n",
    "    # Calculate union\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "    union = area_true + area_pred - intersection\n",
    "    \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    \n",
    "    # Compute Intersection over Union\n",
    "    union[union == 0] = 1e-9\n",
    "    IOU = intersection/union\n",
    "    \n",
    "    return IOU\n",
    "    \n",
    "\n",
    "\n",
    "def measures_at(threshold, IOU):\n",
    "    \n",
    "    matches = IOU > threshold\n",
    "    \n",
    "    true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Extra objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Missed objects\n",
    "    \n",
    "    assert np.all(np.less_equal(true_positives, 1))\n",
    "    assert np.all(np.less_equal(false_positives, 1))\n",
    "    assert np.all(np.less_equal(false_negatives, 1))\n",
    "    \n",
    "    TP, FP, FN = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "    \n",
    "    f1 = 2*TP / (2*TP + FP + FN + 1e-9)\n",
    "    \n",
    "    return f1, TP, FP, FN\n",
    "\n",
    "# Compute Average Precision for all IoU thresholds\n",
    "\n",
    "def compute_af1_results(ground_truth, prediction, results, image_name):\n",
    "\n",
    "    # Compute IoU\n",
    "    IOU = intersection_over_union(ground_truth, prediction)\n",
    "    if IOU.shape[0] > 0:\n",
    "        jaccard = np.max(IOU, axis=0).mean()\n",
    "    else:\n",
    "        jaccard = 0.0\n",
    "    \n",
    "    # Calculate F1 score at all thresholds\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        f1, tp, fp, fn = measures_at(t, IOU)\n",
    "        res = {\"Image\": image_name, \"Threshold\": t, \"F1\": f1, \"Jaccard\": jaccard, \"TP\": tp, \"FP\": fp, \"FN\": fn}\n",
    "        row = len(results)\n",
    "        results.loc[row] = res\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Count number of False Negatives at 0.7 IoU\n",
    "\n",
    "def get_false_negatives(ground_truth, prediction, results, image_name, threshold=0.7):\n",
    "\n",
    "    # Compute IoU\n",
    "    IOU = intersection_over_union(ground_truth, prediction)\n",
    "    \n",
    "    true_objects = len(np.unique(ground_truth))\n",
    "    if true_objects <= 1:\n",
    "        return results\n",
    "        \n",
    "    area_true = np.histogram(ground_truth, bins=true_objects)[0][1:]\n",
    "    true_objects -= 1\n",
    "    \n",
    "    # Identify False Negatives\n",
    "    matches = IOU > threshold\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Missed objects\n",
    "\n",
    "    data = np.asarray([ \n",
    "        area_true.copy(), \n",
    "        np.array(false_negatives, dtype=np.int32)\n",
    "    ])\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame(data=data.T, columns=[\"Area\", \"False_Negative\"])])\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Count the number of splits and merges\n",
    "\n",
    "def get_splits_and_merges(ground_truth, prediction, results, image_name):\n",
    "\n",
    "    # Compute IoU\n",
    "    IOU = intersection_over_union(ground_truth, prediction)\n",
    "    \n",
    "    matches = IOU > 0.1\n",
    "    merges = np.sum(matches, axis=0) > 1\n",
    "    splits = np.sum(matches, axis=1) > 1\n",
    "    r = {\"Image_Name\":image_name, \"Merges\":np.sum(merges), \"Splits\":np.sum(splits)}\n",
    "    results.loc[len(results)+1] = r\n",
    "    return results\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment.py\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "import tensorflow as tf\n",
    "    \n",
    "import keras.backend\n",
    "import keras.callbacks\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.optimizers\n",
    "    \n",
    "import utils.model_builder\n",
    "import utils.data_provider\n",
    "import utils.metrics\n",
    "import utils.objectives\n",
    "import utils.dirtools\n",
    "import utils.evaluation\n",
    "    \n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "\n",
    "\n",
    "def run(config_vars, data_partitions, experiment_name, partition, GPU=\"2\"):\n",
    "\n",
    "    # Device configuration\n",
    "    configuration = tf.ConfigProto()\n",
    "    configuration.gpu_options.allow_growth = True\n",
    "    configuration.gpu_options.visible_device_list = GPU\n",
    "    session = tf.Session(config = configuration)\n",
    "    \n",
    "    # apply session\n",
    "    keras.backend.set_session(session)\n",
    "\n",
    "    # # Step 02\n",
    "    # # Training a U-Net model    \n",
    "    \n",
    "    train_gen = utils.data_provider.random_sample_generator(\n",
    "        config_vars[\"normalized_images_dir\"],\n",
    "        config_vars[\"boundary_labels_dir\"],\n",
    "        data_partitions[\"training\"],\n",
    "        config_vars[\"batch_size\"],\n",
    "        config_vars[\"pixel_depth\"],\n",
    "        config_vars[\"crop_size\"],\n",
    "        config_vars[\"crop_size\"],\n",
    "        config_vars[\"rescale_labels\"]\n",
    "    )\n",
    "    \n",
    "    val_gen = utils.data_provider.single_data_from_images(\n",
    "         config_vars[\"normalized_images_dir\"],\n",
    "         config_vars[\"boundary_labels_dir\"],\n",
    "         data_partitions[\"validation\"],\n",
    "         config_vars[\"val_batch_size\"],\n",
    "         config_vars[\"pixel_depth\"],\n",
    "         config_vars[\"crop_size\"],\n",
    "         config_vars[\"crop_size\"],\n",
    "         config_vars[\"rescale_labels\"]\n",
    "    )\n",
    "    \n",
    "    model = utils.model_builder.get_model_3_class(config_vars[\"crop_size\"], config_vars[\"crop_size\"], activation=None)\n",
    "    \n",
    "    loss = utils.objectives.weighted_crossentropy\n",
    "    \n",
    "    metrics = [keras.metrics.categorical_accuracy, \n",
    "               utils.metrics.channel_recall(channel=0, name=\"background_recall\"), \n",
    "               utils.metrics.channel_precision(channel=0, name=\"background_precision\"),\n",
    "               utils.metrics.channel_recall(channel=1, name=\"interior_recall\"), \n",
    "               utils.metrics.channel_precision(channel=1, name=\"interior_precision\"),\n",
    "               utils.metrics.channel_recall(channel=2, name=\"boundary_recall\"), \n",
    "               utils.metrics.channel_precision(channel=2, name=\"boundary_precision\"),\n",
    "              ]\n",
    "    \n",
    "    optimizer = keras.optimizers.RMSprop(lr=config_vars[\"learning_rate\"])\n",
    "    \n",
    "    model.compile(loss=loss, metrics=metrics, optimizer=optimizer)\n",
    "    \n",
    "    callback_csv = keras.callbacks.CSVLogger(filename=config_vars[\"csv_log_file\"])\n",
    "    \n",
    "    callbacks=[callback_csv]\n",
    "    \n",
    "    # TRAIN\n",
    "    statistics = model.fit_generator(\n",
    "        generator=train_gen,\n",
    "        steps_per_epoch=config_vars[\"steps_per_epoch\"],\n",
    "        epochs=config_vars[\"epochs\"],\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=int(len(data_partitions[\"validation\"])/config_vars[\"val_batch_size\"]),\n",
    "        callbacks=callbacks,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    model.save_weights(config_vars[\"model_file\"])\n",
    "    \n",
    "    print('Training Done! :)')\n",
    "    \n",
    "    \n",
    "    # # Step 03\n",
    "    # # Predict segmentations\n",
    "        \n",
    "    image_names = [f for f in data_partitions[partition] if f.startswith(\"IXM\")]\n",
    "    image_names = [os.path.join(config_vars[\"normalized_images_dir\"], f) for f in image_names]#data_partitions[partition]]\n",
    "    \n",
    "    imagebuffer = skimage.io.imread_collection(image_names)\n",
    "    \n",
    "    images = imagebuffer.concatenate()\n",
    "    \n",
    "    dim1 = images.shape[1]\n",
    "    dim2 = images.shape[2]\n",
    "    \n",
    "    images = images.reshape((-1, dim1, dim2, 1))\n",
    "    \n",
    "    images = images / 255\n",
    "    \n",
    "    model = utils.model_builder.get_model_3_class(dim1, dim2)\n",
    "    model.load_weights(config_vars[\"model_file\"])\n",
    "    \n",
    "    predictions = model.predict(images, batch_size=1)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "    \n",
    "        filename = imagebuffer.files[i]\n",
    "        filename = os.path.basename(filename)\n",
    "        \n",
    "        probmap = predictions[i].squeeze()\n",
    "        \n",
    "        skimage.io.imsave(config_vars[\"probmap_out_dir\"] + filename, probmap)\n",
    "        \n",
    "        pred = utils.metrics.probmap_to_pred(probmap, config_vars[\"boundary_boost_factor\"])\n",
    "    \n",
    "        label = utils.metrics.pred_to_label(pred, config_vars[\"cell_min_size\"])\n",
    "        \n",
    "        skimage.io.imsave(config_vars[\"labels_out_dir\"] + filename, label)\n",
    "    \n",
    "    \n",
    "    # # Step 04\n",
    "    # # Evaluation of performance\n",
    "    \n",
    "    all_images = data_partitions[partition]\n",
    "    #all_images = [f for f in data_partitions[partition] if f.startswith(\"IXM\")]\n",
    "    \n",
    "    \n",
    "    results = pd.DataFrame(columns=[\"Image\", \"Threshold\", \"Precision\"])\n",
    "    false_negatives = pd.DataFrame(columns=[\"False_Negative\", \"Area\"])\n",
    "    splits_merges = pd.DataFrame(columns=[\"Image_Name\", \"Merges\",\"Splits\"])\n",
    "    \n",
    "    for image_name in all_images:\n",
    "        img_filename = os.path.join(config_vars[\"raw_annotations_dir\"], image_name)\n",
    "        ground_truth = skimage.io.imread(img_filename)\n",
    "        if len(ground_truth.shape) == 3:\n",
    "            ground_truth = ground_truth[:,:,0]\n",
    "        \n",
    "        ground_truth = skimage.morphology.label(ground_truth)\n",
    "        \n",
    "        pred_filename = os.path.join(config_vars[\"labels_out_dir\"], image_name)\n",
    "        prediction = skimage.io.imread(pred_filename) #.replace(\".png\",\".tiff\"))\n",
    "        \n",
    "        if config_vars[\"object_dilation\"] > 0:\n",
    "            struct = skimage.morphology.square(config_vars[\"object_dilation\"])\n",
    "            prediction = skimage.morphology.dilation(prediction, struct)\n",
    "        elif config_vars[\"object_dilation\"] < 0:\n",
    "            struct = skimage.morphology.square(-config_vars[\"object_dilation\"])\n",
    "            prediction = skimage.morphology.erosion(prediction, struct)\n",
    "            \n",
    "        ground_truth = skimage.segmentation.relabel_sequential(ground_truth[30:-30,30:-30])[0] # )[0] #\n",
    "        prediction = skimage.segmentation.relabel_sequential(prediction[30:-30,30:-30])[0] # )[0] #\n",
    "        \n",
    "        results = utils.evaluation.compute_ap_results(\n",
    "            ground_truth, \n",
    "            prediction, \n",
    "            results, \n",
    "            image_name\n",
    "        )\n",
    "        \n",
    "        false_negatives = utils.evaluation.get_false_negatives(\n",
    "            ground_truth, \n",
    "            prediction, \n",
    "            false_negatives, \n",
    "            image_name\n",
    "        )\n",
    "        \n",
    "        splits_merges = utils.evaluation.get_splits_and_merges(\n",
    "            ground_truth, \n",
    "            prediction, \n",
    "            splits_merges, \n",
    "            image_name\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # # Report of results\n",
    "    \n",
    "    output = {}\n",
    "\n",
    "    average_precision = results.groupby(\"Threshold\").mean().reset_index()\n",
    "    mean_average_precision = average_precision[\"Precision\"].mean()\n",
    "    output[\"MAP\"] = mean_average_precision\n",
    "    \n",
    "    false_negatives = false_negatives[false_negatives[\"False_Negative\"] == 1]\n",
    "    \n",
    "    missed = false_negatives.groupby(\n",
    "        pd.cut(\n",
    "            false_negatives[\"Area\"], \n",
    "            [0,250,625,900,10000], # Area intervals\n",
    "            labels=[\"Tiny nuclei\",\"Small nuclei\",\"Normal nuclei\",\"Large nuclei\"],\n",
    "        )\n",
    "    )[\"False_Negative\"].sum()\n",
    "    \n",
    "    output[\"Missed\"] = missed\n",
    "    output[\"Splits\"] = np.sum(splits_merges[\"Splits\"])\n",
    "    output[\"Merges\"] = np.sum(splits_merges[\"Merges\"])\n",
    "\n",
    "    return output\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics.py\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import skimage.segmentation\n",
    "import skimage.io\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "debug = False\n",
    "\n",
    "def channel_precision(channel, name):\n",
    "    def precision_func(y_true, y_pred):\n",
    "        y_pred_tmp = K.cast(tf.equal( K.argmax(y_pred, axis=-1), channel), \"float32\")\n",
    "        true_positives = K.sum(K.round(K.clip(y_true[:,:,:,channel] * y_pred_tmp, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred_tmp, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "        return precision\n",
    "    precision_func.__name__ = name\n",
    "    return precision_func\n",
    "\n",
    "\n",
    "def channel_recall(channel, name):\n",
    "    def recall_func(y_true, y_pred):\n",
    "        y_pred_tmp = K.cast(tf.equal( K.argmax(y_pred, axis=-1), channel), \"float32\")\n",
    "        true_positives = K.sum(K.round(K.clip(y_true[:,:,:,channel] * y_pred_tmp, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true[:,:,:,channel], 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "        return recall\n",
    "    recall_func.__name__ = name\n",
    "    return recall_func\n",
    "\n",
    "\n",
    "## PROBMAP TO CONTOURS TO LABEL\n",
    "\n",
    "def probmap_to_contour(probmap, threshold = 0.5):\n",
    "    # assume 2D input\n",
    "    outline = probmap >= threshold\n",
    "    \n",
    "    return outline\n",
    "\n",
    "def contour_to_label(outline, image):\n",
    "    # see notebook contours_to_labels for why we do what we do here\n",
    "    \n",
    "    # get connected components\n",
    "    labels = skimage.morphology.label(outline, background=1)\n",
    "    skimage.morphology.remove_small_objects(labels, min_size = 100, in_place = True)\n",
    "    \n",
    "    n_ccs = np.max(labels)\n",
    "\n",
    "    # buffer label image\n",
    "    filtered_labels = np.zeros_like(labels, dtype=np.uint16)\n",
    "\n",
    "    # relabel as we don't know what connected component the background has been given before\n",
    "    label_index = 1\n",
    "    \n",
    "    # start at 1 (0 is contours), end at number of connected components\n",
    "    for i in range(1, n_ccs + 1):\n",
    "\n",
    "        # get mask of connected compoenents\n",
    "        mask = labels == i\n",
    "\n",
    "        # get mean\n",
    "        mean = np.mean(np.take(image.flatten(),np.nonzero(mask.flatten())))\n",
    "\n",
    "        if(mean > 50/255):\n",
    "            filtered_labels[mask] = label_index\n",
    "            label_index = label_index + 1\n",
    "            \n",
    "    return filtered_labels\n",
    "\n",
    "\n",
    "## PROBMAP TO PRED TO LABEL\n",
    "\n",
    "def probmap_to_pred(probmap, boundary_boost_factor):\n",
    "    # we need to boost the boundary class to make it more visible\n",
    "    # this shrinks the cells a little bit but avoids undersegmentation\n",
    "    pred = np.argmax(probmap * [1, 1, boundary_boost_factor], -1)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def pred_to_label(pred, cell_min_size, cell_label=1):\n",
    "    # Only marks interior of cells (cell_label = 1 is interior, cell_label = 2 is boundary)\n",
    "    cell=(pred == cell_label)\n",
    "    # fix cells\n",
    "    cell = skimage.morphology.remove_small_holes(cell, area_threshold=cell_min_size)\n",
    "    cell = skimage.morphology.remove_small_objects(cell, min_size=cell_min_size)\n",
    "    \n",
    "    # label cells only\n",
    "    [label, num] = skimage.morphology.label(cell, return_num=True)\n",
    "    return label\n",
    "\n",
    "\n",
    "def compare_two_labels(label_model, label_gt, return_IoU_matrix):\n",
    "    \n",
    "    # get number of detected nuclei\n",
    "    nb_nuclei_gt = np.max(label_gt)\n",
    "    nb_nuclei_model = np.max(label_model)\n",
    "    \n",
    "    # catch the case of an empty picture in model and gt\n",
    "    if nb_nuclei_gt == 0 and nb_nuclei_model == 0:\n",
    "        if(return_IoU_matrix):\n",
    "            return [0, 0, 1, np.empty(0)]     \n",
    "        else:\n",
    "            return [0, 0, 1]\n",
    "    \n",
    "    # catch the case of empty picture in model\n",
    "    if nb_nuclei_model == 0:\n",
    "        if(return_IoU_matrix):\n",
    "            return [0, nb_nuclei_gt, 0, np.empty(0)]     \n",
    "        else:\n",
    "            return [0, nb_nuclei_gt, 0]\n",
    "    \n",
    "    # catch the case of empty picture in gt\n",
    "    if nb_nuclei_gt == 0:\n",
    "        if(return_IoU_matrix):\n",
    "            return [nb_nuclei_model, 0, 0, np.empty(0)]     \n",
    "        else:\n",
    "            return [nb_nuclei_model, 0, 0]\n",
    "    \n",
    "    # build IoU matrix\n",
    "    IoUs = np.full((nb_nuclei_gt, nb_nuclei_model), -1, dtype = np.float32)\n",
    "\n",
    "    # calculate IoU for each nucleus index_gt in GT and nucleus index_pred in prediction    \n",
    "    # TODO improve runtime of this algorithm\n",
    "    for index_gt in range(1,nb_nuclei_gt+1):\n",
    "\n",
    "        nucleus_gt = label_gt == index_gt\n",
    "        number_gt = np.sum(nucleus_gt)\n",
    "\n",
    "        for index_model in range(1,nb_nuclei_model+1):\n",
    "            \n",
    "            if debug:\n",
    "                print(index_gt, \"/\", index_model)\n",
    "            \n",
    "            nucleus_model = label_model == index_model \n",
    "            number_model = np.sum(nucleus_model)\n",
    "            \n",
    "            same_and_1 = np.sum((nucleus_gt == nucleus_model) * nucleus_gt)\n",
    "            \n",
    "            IoUs[index_gt-1,index_model-1] = same_and_1 / (number_gt + number_model - same_and_1)\n",
    "    \n",
    "    # get matches and errors\n",
    "    detection_map = (IoUs > 0.5)\n",
    "    nb_matches = np.sum(detection_map)\n",
    "\n",
    "    detection_rate = IoUs * detection_map\n",
    "    \n",
    "    nb_overdetection = nb_nuclei_model - nb_matches\n",
    "    nb_underdetection = nb_nuclei_gt - nb_matches\n",
    "    \n",
    "    mean_IoU = np.mean(np.sum(detection_rate, axis = 1))\n",
    "    \n",
    "    if(return_IoU_matrix):\n",
    "        result = [nb_overdetection, nb_underdetection, mean_IoU, IoUs]\n",
    "    else:\n",
    "        result = [nb_overdetection, nb_underdetection, mean_IoU]\n",
    "    return result\n",
    "\n",
    "def splits_and_merges_3_class(y_model_pred, y_gt_pred):\n",
    "    \n",
    "    # get segmentations\n",
    "    label_gt = pred_to_label(y_gt_pred, cell_min_size=2)\n",
    "    label_model = pred_to_label(y_model_pred, cell_min_size=2)\n",
    "    \n",
    "    # compare labels\n",
    "    result = compare_two_labels(label_model, label_gt, False)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def splits_and_merges_boundary(y_model_outline, y_gt_outline, image):\n",
    "    \n",
    "    # get segmentations\n",
    "    label_gt = contour_to_label(y_gt_outline, image)\n",
    "    label_model = contour_to_label(y_model_outline, image)\n",
    "    \n",
    "    # compare labels\n",
    "    result = compare_two_labels(label_model, label_gt, False)\n",
    "        \n",
    "    return result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_builder.py\n",
    "\n",
    "```python\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import tensorflow as tf\n",
    "\n",
    "CONST_DO_RATE = 0.5\n",
    "\n",
    "option_dict_conv = {\"activation\": \"relu\", \"border_mode\": \"same\"}\n",
    "option_dict_bn = {\"mode\": 0, \"momentum\" : 0.9}\n",
    "\n",
    "\n",
    "# returns a core model from gray input to 64 channels of the same size\n",
    "def get_core(dim1, dim2):\n",
    "    \n",
    "    x = keras.layers.Input(shape=(dim1, dim2, 1))\n",
    "\n",
    "    a = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(x)  \n",
    "    a = keras.layers.BatchNormalization(**option_dict_bn)(a)\n",
    "\n",
    "    a = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(a)\n",
    "    a = keras.layers.BatchNormalization(**option_dict_bn)(a)\n",
    "\n",
    "    \n",
    "    y = keras.layers.MaxPooling2D()(a)\n",
    "\n",
    "    b = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(y)\n",
    "    b = keras.layers.BatchNormalization(**option_dict_bn)(b)\n",
    "\n",
    "    b = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(b)\n",
    "    b = keras.layers.BatchNormalization(**option_dict_bn)(b)\n",
    "\n",
    "    \n",
    "    y = keras.layers.MaxPooling2D()(b)\n",
    "\n",
    "    c = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(y)\n",
    "    c = keras.layers.BatchNormalization(**option_dict_bn)(c)\n",
    "\n",
    "    c = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(c)\n",
    "    c = keras.layers.BatchNormalization(**option_dict_bn)(c)\n",
    "\n",
    "    \n",
    "    y = keras.layers.MaxPooling2D()(c)\n",
    "\n",
    "    d = keras.layers.Convolution2D(512, 3, 3, **option_dict_conv)(y)\n",
    "    d = keras.layers.BatchNormalization(**option_dict_bn)(d)\n",
    "\n",
    "    d = keras.layers.Convolution2D(512, 3, 3, **option_dict_conv)(d)\n",
    "    d = keras.layers.BatchNormalization(**option_dict_bn)(d)\n",
    "\n",
    "    \n",
    "    # UP\n",
    "\n",
    "    d = keras.layers.UpSampling2D()(d)\n",
    "\n",
    "    y = keras.layers.merge.concatenate([d, c], axis=3)\n",
    "\n",
    "    e = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(y)\n",
    "    e = keras.layers.BatchNormalization(**option_dict_bn)(e)\n",
    "\n",
    "    e = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(e)\n",
    "    e = keras.layers.BatchNormalization(**option_dict_bn)(e)\n",
    "\n",
    "    e = keras.layers.UpSampling2D()(e)\n",
    "\n",
    "    \n",
    "    y = keras.layers.merge.concatenate([e, b], axis=3)\n",
    "\n",
    "    f = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(y)\n",
    "    f = keras.layers.BatchNormalization(**option_dict_bn)(f)\n",
    "\n",
    "    f = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(f)\n",
    "    f = keras.layers.BatchNormalization(**option_dict_bn)(f)\n",
    "\n",
    "    f = keras.layers.UpSampling2D()(f)\n",
    "\n",
    "    \n",
    "    y = keras.layers.merge.concatenate([f, a], axis=3)\n",
    "\n",
    "    y = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(y)\n",
    "    y = keras.layers.BatchNormalization(**option_dict_bn)(y)\n",
    "\n",
    "    y = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(y)\n",
    "    y = keras.layers.BatchNormalization(**option_dict_bn)(y)\n",
    "\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "def get_model_3_class(dim1, dim2, activation=\"softmax\"):\n",
    "    \n",
    "    [x, y] = get_core(dim1, dim2)\n",
    "\n",
    "    y = keras.layers.Convolution2D(3, 1, 1, **option_dict_conv)(y)\n",
    "\n",
    "    if activation is not None:\n",
    "        y = keras.layers.Activation(activation)(y)\n",
    "\n",
    "    model = keras.models.Model(x, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## objectives.py\n",
    "\n",
    "```python\n",
    "import keras.metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def weighted_crossentropy(y_true, y_pred):\n",
    "\n",
    "    class_weights = tf.constant([[[[1., 1., 10.]]]])\n",
    "\n",
    "    unweighted_losses = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "\n",
    "    weights = tf.reduce_sum(class_weights * y_true, axis=-1)\n",
    "\n",
    "    weighted_losses = weights * unweighted_losses\n",
    "\n",
    "    loss = tf.reduce_mean(weighted_losses)\n",
    "\n",
    "    return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing_and_merging_annotations_BBBC038.py\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image,ImageChops\n",
    "import numpy as np\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2lab\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "filepath = '/home/maloua/Malou_Master/3_data/2_additional_datasets/2_BBBC_image_sets/kaggle-dsbowl-2018-dataset-fixes-master/stage1_train/'\n",
    "filelist = os.listdir(filepath)\n",
    "image_storage = '/home/maloua/Malou_Master/3_data/2_additional_datasets/2_BBBC_image_sets/BBBC038_normalized_images/'\n",
    "annotation_storage = '/home/maloua/Malou_Master/3_data/2_additional_datasets/2_BBBC_image_sets/BBBC038_boundary_labels/'\n",
    "\n",
    "os.makedirs(image_storage, exist_ok= True)\n",
    "os.makedirs(annotation_storage, exist_ok = True)\n",
    "\n",
    "def create_boundary_label(im):\n",
    "    \n",
    "    if len(im.shape)>2:\n",
    "        if im.shape[2]!=3:\n",
    "            annot = annot[:,:,0]\n",
    "        else:\n",
    "            im = rgb2lab(annot)\n",
    "            im = annot[:,:,0]\n",
    "    # label the annotations nicely to prepare for future filtering operation\n",
    "    \n",
    "    im = skimage.morphology.label(im)\n",
    "\n",
    "    boundaries = skimage.segmentation.find_boundaries(im, mode = 'outer')\n",
    "\n",
    "    \n",
    "    label_binary = np.zeros((im.shape + (3,)))\n",
    "    # write binary label\n",
    "    label_binary[(im == 0) & (boundaries == 0), 0] = 1\n",
    "    label_binary[(im != 0) & (boundaries == 0), 1] = 1\n",
    "    label_binary[boundaries == 1, 2] = 1\n",
    "    label_binary = img_as_ubyte(label_binary)\n",
    "    return(label_binary)\n",
    "\n",
    "for directory in tqdm(filelist):\n",
    "    imgindex = 0\n",
    "    imname = os.listdir(filepath + directory + '/images')\n",
    "    im = Image.open(filepath + directory + '/images/'+ imname[0])\n",
    "    pix_vals = list(im.getdata())\n",
    "    pix_vals = pix_vals[0:5]\n",
    "    grey = True\n",
    "    for pixels in pix_vals:\n",
    "        if pixels[0]==pixels[1]==pixels[2]:\n",
    "            grey = True\n",
    "        else:\n",
    "            grey = False\n",
    "    if grey == True:\n",
    "        im = skimage.io.imread(filepath + directory + '/images/'+ imname[0])\n",
    "        if len(im.shape)>= 3:\n",
    "            im = im[:,:,0]\n",
    "        skimage.io.imsave(image_storage + imname[0],im)\n",
    "        \n",
    "        masks_path = filepath + directory + '/masks/'\n",
    "        masks = os.listdir(masks_path)\n",
    "        \n",
    "        mask_list = []\n",
    "        index = 1\n",
    "        for mask in masks:\n",
    "            mask_im = skimage.io.imread(masks_path + mask)\n",
    "            mask_im[mask_im==255]=index\n",
    "            mask_list.append(mask_im)\n",
    "            index += 1\n",
    "        maskmerged = sum(mask_list)\n",
    "        label_mask = create_boundary_label(maskmerged)\n",
    "        skimage.io.imsave(annotation_storage + imname[0], label_mask)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing_BBBC020.py\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "import os\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image,ImageChops\n",
    "import numpy as np\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.color import rgb2grey\n",
    "\n",
    "\n",
    "def create_boundary_label(im):\n",
    "    \n",
    "    # strip the first channel\n",
    "    if len(im.shape)>2:\n",
    "        if im.shape[2]!=3:\n",
    "            annot = annot[:,:,0]\n",
    "        else:\n",
    "            im = rgb2lab(annot)\n",
    "            im = annot[:,:,0]\n",
    "    # label the annotations nicely to prepare for future filtering operation\n",
    "    \n",
    "    im = skimage.morphology.label(im)\n",
    "    #print(np.unique(im))\n",
    "    # find boundaries\n",
    "    boundaries = skimage.segmentation.find_boundaries(im, mode = 'outer')\n",
    "\n",
    "    \n",
    "    label_binary = np.zeros((im.shape + (3,)))\n",
    "    # write binary label\n",
    "    label_binary[(im == 0) & (boundaries == 0), 0] = 1\n",
    "    label_binary[(im != 0) & (boundaries == 0), 1] = 1\n",
    "    label_binary[boundaries == 1, 2] = 1\n",
    "    #print(np.unique(label_binary.reshape(-1, merged.shape[2]), axis=0))\n",
    "    label_binary = img_as_ubyte(label_binary)\n",
    "    return(label_binary)\n",
    "\n",
    "\n",
    "# Normalization script\n",
    "def normalize(orig_img):\n",
    "        # normalize to [0,1]\n",
    "        percentile = 99.9\n",
    "        high = np.percentile(orig_img, percentile)\n",
    "        low = np.percentile(orig_img, 100-percentile)\n",
    "\n",
    "        img = np.minimum(high, orig_img)\n",
    "        img = np.maximum(low, img)\n",
    "\n",
    "        img = (img - low) / (high - low) # gives float64, thus cast to 8 bit later\n",
    "        img = skimage.img_as_ubyte(img) \n",
    "\n",
    "        return(img)   \n",
    "\n",
    "\n",
    "dir_path = '/home/maloua/Malou_Master/3_data/2_additional_datasets/2_BBBC_image_sets/BBBC020_v1_images/'\n",
    "masks_path = '/home/maloua/Malou_Master/3_data/2_additional_datasets/2_BBBC_image_sets/BBC020_v1_outlines_nuclei/'\n",
    "\n",
    "\n",
    "\n",
    "norm_images = '/home/maloua/Malou_Master/3_data/2_additional_datasets/2_BBBC_image_sets/BBBC020_normalized_images/'\n",
    "boundary_labels = '/home/maloua/Malou_Master/3_data/2_additional_datasets/2_BBBC_image_sets/BBBC020_boundary_labels/'\n",
    "\n",
    "os.makedirs(norm_images, exist_ok = True)\n",
    "os.makedirs(boundary_labels, exist_ok = True)\n",
    "\n",
    "image_dirs = os.listdir(dir_path)\n",
    "masks_dir = os.listdir(masks_path)\n",
    "\n",
    "\n",
    "for dirs in image_dirs:\n",
    "    images = os.listdir(dir_path + dirs)\n",
    "    for image in images:\n",
    "        ending = image.split('_')[-1]\n",
    "        if ending == 'c5.TIF':\n",
    "            blueim = skimage.io.imread(dir_path + dirs + '/' + image)\n",
    "            grayim = rgb2grey(blueim)\n",
    "            imagename = image.split('.')[0]\n",
    "            mask_list = []\n",
    "            index = 1\n",
    "            for masks in masks_dir:\n",
    "                if masks.startswith(imagename):\n",
    "                    mask = skimage.io.imread(masks_path + masks)\n",
    "                    mask[mask==255]=index\n",
    "                    mask_list.append(mask)\n",
    "                    index += 1\n",
    "            maskmerged = sum(mask_list)\n",
    "            if isinstance(maskmerged,np.ndarray):\n",
    "                grayim = normalize(grayim)\n",
    "                skimage.io.imsave(norm_images + image[:-3] + 'png', grayim)\n",
    "                label_mask = create_boundary_label(maskmerged)\n",
    "                skimage.io.imsave(boundary_labels + image[:-3] + 'png', label_mask)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing_celltracking_images.py\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import requests\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2lab\n",
    "\n",
    "pathways_raw = ['Fluo-N2DL-HeLa/01/','Fluo-N2DL-HeLa/02/','Fluo-N2DH-SIM+/01/','Fluo-N2DH-SIM+/02/','Fluo-N2DH-GOWT1/01/','Fluo-N2DH-GOWT1/02/']\n",
    "pathways_annot =['Fluo-N2DL-HeLa/01_ST/SEG/','Fluo-N2DL-HeLa/02_ST/SEG/','Fluo-N2DH-SIM+/01_GT/SEG/','Fluo-N2DH-SIM+/02_GT/SEG/','Fluo-N2DH-GOWT1/01_ST/SEG/','Fluo-N2DH-GOWT1/02_ST/SEG/']\n",
    "\n",
    "norm_images = '/home/maloua/Malou_Master/3_data/2_additional_datasets/1_celltracking_challenge_data/normalized_images/'\n",
    "boundary_labels = '/home/maloua/Malou_Master/3_data/2_additional_datasets/1_celltracking_challenge_data/boundary_labels/'\n",
    "\n",
    "os.makedirs(norm_images, exist_ok = True)\n",
    "os.makedirs(boundary_labels, exist_ok = True)\n",
    "\n",
    "total_objects = 0\n",
    "index = 0\n",
    "for i in range(len(pathways_raw)):\n",
    "    raw_dir = '/home/maloua/Malou_Master/3_data/2_additional_datasets/1_celltracking_challenge_data/' + pathways_raw[i]\n",
    "    annot_dir = '/home/maloua/Malou_Master/3_data/2_additional_datasets/1_celltracking_challenge_data/' + pathways_annot[i]\n",
    "    filelist_raw = sorted(os.listdir(raw_dir))\n",
    "    filelist_annot = sorted(os.listdir(annot_dir))\n",
    "    # run over all raw images\n",
    "    for filename in tqdm(filelist_raw):\n",
    "        # load image and its annotation\n",
    "        orig_img = skimage.io.imread(raw_dir + filename)       \n",
    "\n",
    "        # IMAGE\n",
    "\n",
    "        # normalize to [0,1]\n",
    "        percentile = 99.9\n",
    "        high = np.percentile(orig_img, percentile)\n",
    "        low = np.percentile(orig_img, 100-percentile)\n",
    "\n",
    "        img = np.minimum(high, orig_img)\n",
    "        img = np.maximum(low, img)\n",
    "\n",
    "        img = (img - low) / (high - low) # gives float64, thus cast to 8 bit later\n",
    "        img = skimage.img_as_ubyte(img) \n",
    "\n",
    "        skimage.io.imsave(norm_images + '{}_'.format(index) + filename[:-3]  + 'png', img)  \n",
    "    \n",
    "    for filename in tqdm(filelist_annot):\n",
    "        # GET ANNOTATION\n",
    "        annot = skimage.io.imread(annot_dir + filename)\n",
    "\n",
    "        # strip the first channel\n",
    "        if len(annot.shape)>2:\n",
    "            if annot.shape[2]!=3:\n",
    "                annot = annot[:,:,0]\n",
    "            else:\n",
    "                annot = rgb2lab(annot)\n",
    "                annot = annot[:,:,0]\n",
    "        # label the annotations nicely to prepare for future filtering operation\n",
    "\n",
    "        annot = skimage.morphology.label(annot)\n",
    "        total_objects += len(np.unique(annot)) - 1\n",
    "\n",
    "        # find boundaries\n",
    "        boundaries = skimage.segmentation.find_boundaries(annot, mode = 'outer')\n",
    "\n",
    "        # BINARY LABEL\n",
    "\n",
    "        # prepare buffer for binary label\n",
    "        label_binary = np.zeros((annot.shape + (3,)))\n",
    "\n",
    "        # write binary label\n",
    "        label_binary[(annot == 0) & (boundaries == 0), 0] = 1\n",
    "        label_binary[(annot != 0) & (boundaries == 0), 1] = 1\n",
    "        label_binary[boundaries == 1, 2] = 1\n",
    "\n",
    "        label_binary = img_as_ubyte(label_binary)\n",
    "        # save it - converts image to range from 0 to 255\n",
    "        skimage.io.imsave(boundary_labels + '{}_'.format(index)+ 't' + filename[-7:-3] + 'png' , label_binary)\n",
    "    index += 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 - Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filelist_wrong_images.txt\n",
    "**1a11552569160f0b1ea10bedbd628ce6c14f29edec5092034c2309c556df833e.png\n",
    "1b44d22643830cd4f23c9deadb0bd499fb392fb2cd9526d81547d93077d983df.png\n",
    "2a1a294e21d76efd0399e4eb321b45f44f7510911acd92c988480195c5b4c812.png\n",
    "4e07a653352b30bb95b60ebc6c57afbc7215716224af731c51ff8d430788cd40.png\n",
    "5d58600efa0c2667ec85595bf456a54e2bd6e6e9a5c0dff42d807bc9fe2b822e.png\n",
    "5e263abff938acba1c0cff698261c7c00c23d7376e3ceacc3d5d4a655216b16d.png\n",
    "7f38885521586fc6011bef1314a9fb2aa1e4935bd581b2991e1d963395eab770.png\n",
    "8d05fb18ee0cda107d56735cafa6197a31884e0a5092dc6d41760fb92ae23ab4.png\n",
    "8f94a80b95a881d0efdec36affc915dca9609f4cba8134c4a91b219d418778aa.png\n",
    "20b20ab049372d184c705acebe7af026d3580f5fd5a72ed796e3622e1685af2f.png\n",
    "76a372bfd3fad3ea30cb163b560e52607a8281f5b042484c3a0fc6d0aa5a7450.png\n",
    "538b7673d507014d83af238876e03617396b70fe27f525f8205a4a96900fbb8e.png\n",
    "930f246a8e4ff273a72a6e4b3cf8e8caff94fca4eaf1dbe6f93ba37b8195c0a0.png\n",
    "4217e25defac94ff465157d53f5a24b8a14045b763d8606ec4a97d71d99ee381.png\n",
    "08275a5b1c2dfcd739e8c4888a5ee2d29f83eccfa75185404ced1dc0866ea992.png\n",
    "091944f1d2611c916b98c020bd066667e33f4639159b2a92407fe5a40788856d.png\n",
    "54793624413c7d0e048173f7aeee85de3277f7e8d47c82e0a854fe43e879cd12.png\n",
    "a102535b0e88374bea4a1cfd9ee7cb3822ff54f4ab2a9845d428ec22f9ee2288.png\n",
    "c395870ad9f5a3ae651b50efab9b20c3e6b9aea15d4c731eb34c0cf9e3800a72.png\n",
    "cb4df20a83b2f38b394c67f1d9d4aef29f9794d5345da3576318374ec3a11490.png\n",
    "f29fd9c52e04403cd2c7d43b6fe2479292e53b2f61969d25256d2d2aca7c6a81.png\n",
    "3594684b9ea0e16196f498815508f8d364d55fea2933a2e782122b6f00375d04.png**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5_training_500.txt\n",
    "\n",
    "0_t045.png\n",
    "2_t008.png\n",
    "5_t062.png\n",
    "5953af5080d981b554529971903d8bee9871457a4361b51f04ba04f43793dd8f.png\n",
    "64eeef16fdc4e26523d27bfa71a1d38d2cb2e4fa116c0d0ea56b1322f806f0b9.png\n",
    "IXMtest_K01_s5_w1A3DE001A-72D6-4321-8B25-4300AB0207AC.png\n",
    "0_t024.png\n",
    "MFGTMPcx7_170802000001_I12f01d0.png\n",
    "0_t032.png\n",
    "4_t062.png\n",
    "IXMtest_B20_s2_w159B9FE71-035A-4DED-B0CA-C76916C968BC.png\n",
    "2349e95ece2857c89db7e4a8be8c88af0b45f3c4262608120cb3bd6ef51fd241.png\n",
    "3_t053.png\n",
    "4d4ebfcae4374165ea6ae7c7e18fd0ba5014c3c860ee2489c59e25ddd45e7a32.png\n",
    "619429303c1af7540916509fe7900cf483eba4391b06aac87ff7f66ca1ab6483.png\n",
    "0ea221716cf13710214dcd331a61cea48308c3940df1d28cfc7fd817c83714e1.png\n",
    "5_t002.png\n",
    "1_t080.png\n",
    "d1dbc6ee7c44a7027e935d040e496793186b884a1028d0e26284a206c6f5aff0.png\n",
    "3_t085.png\n",
    "0_t003.png\n",
    "3_t117.png\n",
    "MFGTMPcx7_170731090001_K24f10d0.png\n",
    "IXMtest_D20_s3_w19D371AF3-0189-48A3-AF3B-D108DE6A017F.png\n",
    "3bf7873f11823f4b64422f49c8248dd95c0d01f9ae9075ae3d233bbb21a3d875.png\n",
    "4_t020.png\n",
    "IXMtest_C14_s8_w1612E3D43-FA7E-4FFB-BE53-F34A3A0CAFCD.png\n",
    "6034456567632f4b48dc3dfbb98534b5953c151990f4235df6c912c0a9c08397.png\n",
    "4_t082.png\n",
    "1_t032.png\n",
    "ae9f76b5360df3f60f3cdd389652b96e823080bb830dd8c79e7f1e597d51bc1c.png\n",
    "356d9903d16074f152fe8f2f0ef555d9959c53264228eae7373cad5cf35d4e85.png\n",
    "4_t051.png\n",
    "40bcdad218ac5f0885fc247d88fcad9f729f55c81c79d241a8f1559b6d8c0574.png\n",
    "1_t079.png\n",
    "jw-24h 4_c5.png\n",
    "0_t079.png\n",
    "4_t060.png\n",
    "5_t025.png\n",
    "7ac468eb217b7058d22c1711285d21949b4121bf3fa3217e3e51453666ebecff.png\n",
    "IXMtest_D20_s9_w1588B4C42-5A0D-4B93-9A80-A6527CC1C411.png\n",
    "5_t038.png\n",
    "3ab9cab6212fabd723a2c5a1949c2ded19980398b56e6080978e796f45cbbc90.png\n",
    "bde3727f3a9e8b2b58f383ebc762b2157eb50cdbff23e69b025418b43967556b.png\n",
    "45c3bdef1819ba7029990e159f61543ed25781d13fb4dc5d4de52e803debd7d3.png\n",
    "2_t057.png\n",
    "33d0a9b24c25852ce35274b4b1777484ccd21f44dbe35491cc926e5948c1ce3e.png\n",
    "jw-1h 5_c5.png\n",
    "b6c9b58de0388891221b8f7a83cbf0b8f8379b51b5c9a127bf43a4fc49f1cc48.png\n",
    "1_t075.png\n",
    "1_t024.png\n",
    "IXMtest_L17_s1_w1DDC627E5-ADF1-441C-A437-D1D91CC0D498.png\n",
    "03398329ced0c23b9ac3fac84dd53a87d9ffe4d9d10f1b5fe8df8fac12380776.png\n",
    "9c95eae11da041189e84cda20bdfb75716a6594684de4b6ce12a9aaadbb874c9.png\n",
    "aa4d989d262c618ac2793579e200cc71b3767f84698ae5f669867f23cdfe2568.png\n",
    "e5aeb5b3577abbebe8982b5dd7d22c4257250ad3000661a42f38bf9248d291fd.png\n",
    "0_t047.png\n",
    "IXMtest_J20_s1_w1EEE65E52-7AD8-47C7-A286-6E84C5D77953.png\n",
    "3_t121.png\n",
    "63d981a107091e1e3059102ce08870744dde173afe324bc2274c17d42f661778.png\n",
    "2_t029.png\n",
    "IXMtest_O10_s8_w18F4DB020-BFB7-4F13-B99C-C39F8E54F85D.png\n",
    "40b00d701695d8ea5d59f95ac39e18004040c96d17fbc1a539317c674eca084b.png\n",
    "4_t078.png\n",
    "5_t074.png\n",
    "33618678c167c5e07be02c49d0c43bcd90493ba5d83110a631409a4d3ccc1e51.png\n",
    "3_t096.png\n",
    "cab4875269f44a701c5e58190a1d2f6fcb577ea79d842522dcab20ccb39b7ad2.png\n",
    "IXMtest_N15_s8_w16DBEFA45-FE5A-4233-A1B9-89CA8CF81FB8.png\n",
    "2_t026.png\n",
    "2_t049.png\n",
    "jw-1h 4_c5.png\n",
    "514ccfc78cb55988a238d3ac9dc83460aa88382c95d56bcc0559962d9fe481ef.png\n",
    "5_t018.png\n",
    "3_t058.png\n",
    "84eeec681987753029eb83ea5f3ff7e8b5697783cdb2035f2882d40c9a3f1029.png\n",
    "IXMtest_O01_s6_w11A23978B-BAAD-4287-B1F6-FFBCF45C5E2F.png\n",
    "IXMtest_D06_s5_w13C67AAA9-6E81-42DB-AC5F-7126602F3607.png\n",
    "jw-15min 4_c5.png\n",
    "5_t055.png\n",
    "f43169e3d8b4f71e687945b9e72cbfdfe2e40e68842568e6a30c60d64c1378b6.png\n",
    "2_t001.png\n",
    "2b50b1e3fa5c5aa39bc84ebfaea9961b7199c4d2488ae0b48d0b3459807d59d2.png\n",
    "4_t037.png\n",
    "4_t003.png\n",
    "c44ed955eb2e5c8d820b01477e122b32eff6dd475343e11229c33d8af3473b22.png\n",
    "1_t051.png\n",
    "37ed50eea5a1e0bade3e6753793b6caeb061cd4c2f365658c257f69cab1f6288.png\n",
    "c53326fe49fc26b7fe602b9d8c0c2da2cb157690b44c2b9351a93f8d9bd8043d.png\n",
    "IXMtest_A09_s1_w1CE70AD49-290D-4312-82E6-CDC717F32637.png\n",
    "2_t024.png\n",
    "4_t045.png\n",
    "bbce7ebc40323a0eff6574d0c3842f50f907f55fbfb46c777f0ed9a49e98ff9b.png\n",
    "1_t034.png\n",
    "449a9c32e53a37c8a86e01c199155c8da3958b631088e10f6fe43c2119defe51.png\n",
    "da31f2aa8601afec5c45180a2c448cb9c4a8ec7b35e75190d6ba3588f69058c8.png\n",
    "MFGTMPcx7_170702090001_K22f04d0.png\n",
    "5_t051.png\n",
    "20c37b1ad2f510ed7396969e855fe93d0d05611738f6e706e8ca1d1aed3ded45.png\n",
    "3_t011.png\n",
    "IXMtest_P07_s8_w144364F25-950A-472C-A529-1A9AD0433B6C.png\n",
    "1_t087.png\n",
    "fc345dac2205deb169bd70197f07f053bada80b61ffa69fdfb490758323ead69.png\n",
    "5_t058.png\n",
    "d827a7d80fc67487a3237135e0d43ae01b7bbcb135e1a167601fc974a8348c51.png\n",
    "8cdbdda8b3a64c97409c0160bcfb06eb8e876cedc3691aa63ca16dbafae6f948.png\n",
    "3_t040.png\n",
    "db45946a4412a2137674ec075b6892ccd682b77826aba618210569bbc65cf2b0.png\n",
    "e2d22d3d283915df8350d039278e314a23e6e8f2b41bdfc16df849e22dd13b36.png\n",
    "3_t048.png\n",
    "3_t046.png\n",
    "5_t035.png\n",
    "IXMtest_G08_s6_w1823194BE-DE9A-4638-BACD-CABE5FA4C89C.png\n",
    "5_t030.png\n",
    "d7db360fabfce9828559a21f6bffff589ae868e0dc6101d7c1212de34a25e3cb.png\n",
    "2_t019.png\n",
    "f9ea1a1159c33f39bbe5f18bb278d961188b40508277eab7c0b4b91219b37b5d.png\n",
    "3_t009.png\n",
    "61dc249314d7b965eb4561ec739eab9b0f60af55c97b25ced8cb2a42a0be128e.png\n",
    "dad607a203483439fcbc2acecd0a39fb5e5a94a32a94348f5c802c79cfeb6e7c.png\n",
    "0ddd8deaf1696db68b00c600601c6a74a0502caaf274222c8367bdc31458ae7e.png\n",
    "1_t047.png\n",
    "3_t109.png\n",
    "IXMtest_M04_s3_w1A599DF67-1E7F-4A09-84FD-0080767A735C.png\n",
    "1_t088.png\n",
    "IXMtest_P15_s8_w1D26A5BC7-CF59-4027-B785-85AD33773609.png\n",
    "0b0d577159f0d6c266f360f7b8dfde46e16fa665138bf577ec3c6f9c70c0cd1e.png\n",
    "3_t037.png\n",
    "5_t067.png\n",
    "5_t054.png\n",
    "f73e37957c74f554be132986f38b6f1d75339f636dfe2b681a0cf3f88d2733af.png\n",
    "1_t086.png\n",
    "b3b1626f8ad156acb2963d1faa6a368f9378a266c3b90d9321087fdc5b3032b4.png\n",
    "3_t079.png\n",
    "4_t024.png\n",
    "58c593bcb98386e7fd42a1d34e291db93477624b164e83ab2afa3caa90d1d921.png\n",
    "1815cf307859b3e13669041d181aa3b3dbbac1a95aef4c42164b223110c09168.png\n",
    "0_t015.png\n",
    "4_t046.png\n",
    "2_t030.png\n",
    "2_t050.png\n",
    "c3bec1066aae20f48b82975e7e8b684cd67635a8baf211e4d9e3e13bc54c5d06.png\n",
    "e4537e7893e631f3ba6ae5b1023e24b233c78249a31c2f5e561f6c4cad88fcf6.png\n",
    "d910b2b1be8406caecfe31a503d412ffc4e3d488286242ebc7381836121dd4ef.png\n",
    "IXMtest_I08_s2_w11996D679-5D76-4FB8-A681-2014A8999EC8.png\n",
    "f20eb4592e7d3cf58d421a9c34832d33adcdcbd0e17b7bf009a013847608da27.png\n",
    "IXMtest_J02_s5_w1F53DDD35-C0B2-4E39-BA3B-9F66D289AB02.png\n",
    "12f89395ad5d21491ab9cec137e247652451d283064773507d7dc362243c5b8e.png\n",
    "1_t021.png\n",
    "2_t044.png\n",
    "5afcbfd0dd64392aa1e233b996d0bfb4354ee7119f30ae111c33d0fe4df11590.png\n",
    "IXMtest_I23_s5_w1E3053D6B-8CEF-48E3-A6A5-2F0D7C1AA177.png\n",
    "5_t072.png\n",
    "3_t069.png\n",
    "bc115ff727e997a88f7cfe4ce817745731a6c753cb9fab6a36e7e66b415a1d3d.png\n",
    "IXMtest_O04_s2_w19A18B0D8-8E8B-4572-A5C0-5C678F3AD54C.png\n",
    "jw-2h 2_c5.png\n",
    "IXMtest_F21_s1_w1E2770CF6-417B-4804-9B45-6EE7D783D8CA.png\n",
    "fc22db33a2495f58f118bc182c0087e140df14ccb8dad51373e1a54381f683de.png\n",
    "3_t014.png\n",
    "ef6634efb46567d87b811be786b18c4cd0e2cda23d79b65d6afe0d259ef3ade6.png\n",
    "3_t017.png\n",
    "IXMtest_H11_s6_w19DF4E879-8DE4-45D6-840B-305BDDB27076.png\n",
    "IXMtest_I18_s3_w1544C8B7A-E092-4F9D-B8D3-C489638D770F.png\n",
    "6af82abb29539000be4696884fc822d3cafcb2105906dc7582c92dccad8948c5.png\n",
    "a1f50f101bc471e2d6967ebdb8ba81150588609e769f3b960f0801e4da5fdc6f.png\n",
    "1_t013.png\n",
    "2_t015.png\n",
    "3_t112.png\n",
    "IXMtest_H17_s1_w10A751E6C-5D06-4147-AB73-7FFAE0B57CC5.png\n",
    "8b12e18670e4b24d03567d1e17c0c24fadf0ea2c1e763983dd6bb4c44b7376a6.png\n",
    "jw-24h 2_c5.png\n",
    "0_t063.png\n",
    "d35f25c8e3f7fca5232fc4d5e3faf14b025b20b3731af77fe971a5e2e9d69d28.png\n",
    "564fa390d9a9c26f986bf860d9091cbd84244bc1c8e3c9369f2f2e5b5fd99b92.png\n",
    "IXMtest_C07_s5_w12C9F2926-A017-4962-8660-72C9C20C86E4.png\n",
    "3_t147.png\n",
    "d52958107d0b1f0288f50f346a833df3df485b92d5516cfcb536e73ab7adafd0.png\n",
    "5_t021.png\n",
    "a1777737270c5f96c4523dff76e4097756f8f7d4c9d59bac079e31f9510deabd.png\n",
    "5_t084.png\n",
    "0_t027.png\n",
    "IXMtest_G23_s8_w12910C37A-C52C-45B2-A796-7C60A2247C32.png\n",
    "5_t008.png\n",
    "5_t011.png\n",
    "1a75e9f15481d11084fe66bc2a5afac6dc5bec20ed56a7351a6d65ef0fe8762b.png\n",
    "5_t016.png\n",
    "2_t014.png\n",
    "0_t008.png\n",
    "9e4f8ec60a0d622a02c0e16eedcc0101f88ddefbcec2383946c4572b57a1e43a.png\n",
    "6bd330234b763b77796d4804de8e224881c0fc8dd02650fa708b2edfd8c7461f.png\n",
    "0_t030.png\n",
    "3_t102.png\n",
    "5d21acedb3015c1208b31778561f8b1079cca7487399300390c3947f691e3974.png\n",
    "1_t026.png\n",
    "c169a7782a69ea2f38f64d2739de189e88adbcfd4a829721def8c89ecabe8b71.png\n",
    "5_t086.png\n",
    "3_t032.png\n",
    "7c0157913223365720209ac83ff2e0b1b2b460173acd615c67646014093a2b97.png\n",
    "1609b1b8480ee52652a644403b3f7d5511410a016750aa3b9a4c8ddb3e893e8e.png\n",
    "2_t005.png\n",
    "IXMtest_K11_s4_w139A2D71E-EC27-49CC-BDA0-1118747BDC76.png\n",
    "IXMtest_C05_s7_w1F71963FB-8F29-41CB-A5F5-07CB9584BBC5.png\n",
    "1_t004.png\n",
    "4_t055.png\n",
    "1_t010.png\n",
    "ed8c31b001a0c23c33402f94a5ee6b0209e0c6419eb52d5d02255513e3a672fc.png\n",
    "139946af9e2c7ef4f0298e622b831dbef5e5c0cd088eb5bc3382f8df9355443d.png\n",
    "IXMtest_O13_s3_w12D9C1C9C-C582-4080-B9BE-4807FA3E0843.png\n",
    "3b75fc03a1d12b29bd2870eb1f6fdb44174dbd1118dfc11c31f127bd87bd27ef.png\n",
    "3_t130.png\n",
    "IXMtest_D01_s1_w181AE787C-B5EE-4150-A90E-2FE43165C32E.png\n",
    "d2ce593bddf9998ce3b76328c0151d0ba4b644c293aca7f6254e521c448b305f.png\n",
    "5_t010.png\n",
    "cfabf7379c5591d40aa4a20c86b4197c6a25ab55887a9fca4f06c2dfc0f0e973.png\n",
    "f113626a04125d97b27f21b45a0ce9a686d73dee7b5dbc0725d49194ba0203bd.png\n",
    "f487cc82271cf84b4414552aa8b0a9d82d902451ebe8e8bc639d4121c1672ff7.png\n",
    "5_t079.png\n",
    "04acab7636c4cf61d288a5962f15fa456b7bde31a021e5deedfbf51288e4001e.png\n",
    "jw-15min 5_c5.png\n",
    "5_t037.png\n",
    "3_t082.png\n",
    "3_t004.png\n",
    "1_t028.png\n",
    "958114e5f37d5e1420b410bd716753b3e874b175f2b6958ebf1ec2bdf776e41f.png\n",
    "3_t026.png\n",
    "MFGTMPcx7_170731090001_K24f09d0.png\n",
    "003cee89357d9fe13516167fd67b609a164651b21934585648c740d2c3d86dc1.png\n",
    "3_t018.png\n",
    "IXMtest_E12_s9_w1A811DEC0-ADD9-411A-B5D5-A654C70F253D.png\n",
    "5_t015.png\n",
    "IXMtest_E07_s1_w1641C6847-142B-463F-8B08-5B3296615572.png\n",
    "IXMtest_F13_s7_w13C1B1D8C-293E-454F-B0FD-6C2C3F9F5173.png\n",
    "4_t040.png\n",
    "0_t006.png\n",
    "4_t047.png\n",
    "2c840a94d216f5ef4e499b53ae885e9b022cbf639e004ec788436093837823b2.png\n",
    "3_t080.png\n",
    "5_t053.png\n",
    "516a0e20327d6dfcedcf57e3056115e4fb29cdf4cb349003bdfc75c9b7f5c2cf.png\n",
    "ac782d2cad7f515ce7276926209820e386248e3d619b2df81e22d5e3c160b7cb.png\n",
    "2_t055.png\n",
    "3_t023.png\n",
    "5_t089.png\n",
    "4_t081.png\n",
    "0_t080.png\n",
    "79dfcbc9361edd3a1ffe81a5bdaa22a197ad1341f3fa64b86a646c2607d6b324.png\n",
    "2_t007.png\n",
    "IXMtest_K12_s6_w160D86D6B-648B-433E-9776-8A42DF40E5FB.png\n",
    "IXMtest_G12_s6_w16850371E-A405-4D73-9816-F5F68F885D38.png\n",
    "IXMtest_L06_s4_w14DD3575A-627B-4A71-91F0-3396DE0B33C4.png\n",
    "5_t052.png\n",
    "2_t064.png\n",
    "4_t007.png\n",
    "4bf6a5ec42032bb8dbbb10d25fdc5211b2fe1ce44b6e577ef89dbda17697d819.png\n",
    "3_t108.png\n",
    "MFGTMPcx7_170731090001_B14f13d0.png\n",
    "IXMtest_I04_s9_w16A5CC270-8B92-42EE-AA4A-855776F7D46B.png\n",
    "ecb36c90cdd20245d89173c106f3c6a2d124d07bdea0ae202fb1efa49b0cd169.png\n",
    "fec226e45f49ab81ab71e0eaa1248ba09b56a328338dce93a43f4044eababed5.png\n",
    "IXMtest_A16_s2_w15AF20A10-82AE-48FA-AC50-7AE8AC3AA544.png\n",
    "jw-1h 3_c5.png\n",
    "2_t046.png\n",
    "5ba4facefc949c920d7054813a3e846b000969da2ed860148bdfd18456f59bcc.png\n",
    "3_t036.png\n",
    "IXMtest_E19_s4_w129545707-4CD3-4498-AC27-E4AE24D0253C.png\n",
    "d4d6c683f249d82518431603bf0206d05f2114ac871a99ffade0f5f61cf167e1.png\n",
    "IXMtest_O07_s2_w148B3D2F0-D4D6-4F1A-88D3-F18574F52153.png\n",
    "bf7691b0a79811fa068b7408cbce636a73f01ef9e971a95da1a2d96df73782b6.png\n",
    "76c44d1addac92a65f1331f2d93f4e3b130bd4e538a6e5239c3ac1f4c403608a.png\n",
    "1_t031.png\n",
    "2_t002.png\n",
    "d6a880b1f6056f3086679de5c810e7af87cdf3bbbd0533a83e3681817fce40fc.png\n",
    "1_t046.png\n",
    "0_t013.png\n",
    "305a8baaf726d7c9e695bff31d3a6a61445999a4732f0a3e6174dc9dcbe43931.png\n",
    "3_t020.png\n",
    "5_t006.png\n",
    "feffce59a1a3eb0a6a05992bb7423c39c7d52865846da36d89e2a72c379e5398.png\n",
    "7aa1aaa5e032a980f434c8ed63efb57ab0d338d6154c47f7bb75afdc89f43c04.png\n",
    "IXMtest_L01_s2_w1E5038251-DBA3-44D0-BC37-E43E2FC8C174.png\n",
    "08151b19806eebd58e5acec7e138dbfbb1761f41a1ab9620466584ecc7d5fada.png\n",
    "5_t044.png\n",
    "e5384c905e9879cb6e8ff5250fb03155bc1db035d8dde458eece9078b7de8ff1.png\n",
    "a815a986800a95de0957116c6585deea8ffb6ee09ad00ccc687306937ac698d0.png\n",
    "150b0ffa318c87b31d78af0e87d60390dbcd84b5f228a8c1fb3225cbe5df3e3f.png\n",
    "3_t135.png\n",
    "IXMtest_L01_s3_w1E7E0D198-5FB4-4E10-A27C-C46463DA9E06.png\n",
    "3_t022.png\n",
    "94a5a37c3b1153d5c5aef2eca53c960b9f21f2ef1758209d7ec502ec324b03a3.png\n",
    "5_t033.png\n",
    "4_t069.png\n",
    "98a463483fe3a56deacc8bc00ab8aa62668bd40ad0c70bbe7deb10d3e4aeb0c0.png\n",
    "IXMtest_K03_s5_w1DC4CE558-042C-482E-8CAE-FCCB57AA9A55.png\n",
    "4_t008.png\n",
    "IXMtest_A16_s3_w1032BE329-E21B-4E1B-B4B8-58700685EE0C.png\n",
    "4327d27591871e9c8d317071a390d1b3dcedad05a9746175b005c41ea0d797b2.png\n",
    "IXMtest_L05_s2_w1B9C6FAC9-9D48-4184-8D9B-ABFC3BEC1125.png\n",
    "3_t098.png\n",
    "e50ac10d1dce6496d092d966784ed3795969128ca0bc58199a36d558ed529203.png\n",
    "5ddbfba2519484316e4b7ccabfa605e6e6fd96c3d87ac8cdfd2c134571a15311.png\n",
    "9774c82396327929fea05e40ae153cabf0107178b2ae3e40a5709b409793887e.png\n",
    "0280fa8f60f6bcae0f97d93c28f60be194f9309ff610dc5845e60455b0f87c21.png\n",
    "4b274461c6d001a7a9aeaf5952b40ac4934d1be96b9c176edfd628a8f77e6df2.png\n",
    "b76ff33ae9da28f9cd8bdce465d45f1eca399db3ffa83847535708e0d511fe38.png\n",
    "be26966900aa0e5b41d5a8ecafe04281b37deb05c5cd027968d7b74143398174.png\n",
    "66236902b874b7e4b3891db63a69f6d56f6edcec6aca7ba3c6871d73e7b4c34f.png\n",
    "dae976f161fe42dc58dee87d4bf2eb9f65736597cab0114138641b2a39a5c42b.png\n",
    "1_t066.png\n",
    "1f0008060150b5b93084ae2e4dabd160ab80a95ce8071a321b80ec4e33b58aca.png\n",
    "jw-1h 1_c5.png\n",
    "4_t052.png\n",
    "4_t068.png\n",
    "4_t029.png\n",
    "3_t110.png\n",
    "0_t039.png\n",
    "IXMtest_H16_s4_w16207B133-B3F5-4C39-87A6-D71359B27581.png\n",
    "ba3997edd3fcb2f823ecdf870d2b607f08bff848f72a5cf72340bae5aca7c5ce.png\n",
    "3_t028.png\n",
    "IXMtest_L03_s2_w1AC4550E2-F824-4A58-9CC5-952AD9ECE76A.png\n",
    "0a7d30b252359a10fd298b638b90cb9ada3acced4e0c0e5a3692013f432ee4e9.png\n",
    "IXMtest_B22_s8_w10754C18F-B059-47B4-A423-FF429B984D80.png\n",
    "IXMtest_I15_s8_w196F01FA4-CE06-44AE-AAA5-ADEC35BAE513.png\n",
    "4_t085.png\n",
    "60cb718759bff13f81c4055a7679e81326f78b6a193a2d856546097c949b20ff.png\n",
    "3d0ca3498d97edebd28dbc7035eced40baa4af199af09cbb7251792accaa69fe.png\n",
    "IXMtest_B21_s4_w1521471E0-9BD7-492A-8739-9C782C2585B0.png\n",
    "3_t071.png\n",
    "3bfd6bb152310f93daa6f4e1867c10572946e874b3a30c9ba8e0fcdeb590300b.png\n",
    "4_t048.png\n",
    "4_t067.png\n",
    "4c465a54e329ec7b0f4bc5f6acdfd3192707d6c0fbdf557339485581c5a6b3c1.png\n",
    "ff599c7301daa1f783924ac8cbe3ce7b42878f15a39c2d19659189951f540f48.png\n",
    "1740b0a67ca337ea31648b57c81bcfbb841c7bb5cad185199a9f4da596d531b9.png\n",
    "e5a7b8a9924b26b3abf039255a8a3bb00258f4966f68ff3349560b4350af9367.png\n",
    "jw-24h 5_c5.png\n",
    "ee927e8255096971ddae1bd975cf80c4ad7c847c82d0b5f5dd2ddfe5407007ee.png\n",
    "50a7ea80dd73232a17f98b5c83f62ec89989e892fe25b79b36f99b3872a7d182.png\n",
    "3_t116.png\n",
    "IXMtest_B19_s7_w1E43B84DB-39E2-4BFB-8CB4-554B32098C75.png\n",
    "3_t077.png\n",
    "b4de1e3eec159d8af1bd5447696f8996c31709edaf33e26ba9613816705847db.png\n",
    "0b2e702f90aee4fff2bc6e4326308d50cf04701082e718d4f831c8959fbcda93.png\n",
    "IXMtest_I17_s6_w1EB7CA00F-DF95-466C-BF8C-6304B6A4974E.png\n",
    "3_t034.png\n",
    "0_t001.png\n",
    "72e8c49dea44787114fd191f9e97e260f961c6e7ae4715bc95cc91db8d91a4e3.png\n",
    "IXMtest_J07_s9_w16921AB3C-1E9C-41C5-ADDA-7DE5CBF9CCBB.png\n",
    "1_t015.png\n",
    "1ee4a111f0e0bb9b001121b94ff98ca736fad03797b25285fe33a47046b3e4b0.png\n",
    "c6216cdc42f61bc345434986db42e2ef9b9741aee3210b7a808e952e319d2305.png\n",
    "1_t073.png\n",
    "3_t132.png\n",
    "IXMtest_P05_s5_w18FC141F8-8BCA-4851-9000-31D080922BDD.png\n",
    "5b2ccfb94dedf2ec8797c0404fc324888e35ab903c41bb26f070552033ca8e6c.png\n",
    "IXMtest_L21_s5_w122478CD2-80DC-4B4E-9BC8-A6F6239F4103.png\n",
    "3_t010.png\n",
    "5_t050.png\n",
    "1_t043.png\n",
    "4_t006.png\n",
    "57d88f45e479ce3821839b2706d667758c63ac769d76800d815c73d2507c1e42.png\n",
    "b560dba92fbf2af785739efced50d5866c86dc4dada9be3832138bef4c3524d2.png\n",
    "MFGTMPcx7_170702000001_D13f04d0.png\n",
    "ce37f6dd0615d45e66e41a8f2ed6fbc0bbe3103a290394ad474207507710eacc.png\n",
    "86f9087eb1d0875ffb1a28cca7645b14d6c66f995c7d96aa13969d2f8115d533.png\n",
    "d4d88391bc399a3715440d4da9f8b7a973e010dc1edd9551df2e5a538685add5.png\n",
    "a6593632dcbbe4c9e9429a9cec573d26fd8c91a47d554d315f25e7c2e0280ee3.png\n",
    "0_t009.png\n",
    "0_t048.png\n",
    "2_t021.png\n",
    "3_t100.png\n",
    "2_t009.png\n",
    "e216ec5063d3562b793e434c491051bd8867f6c2e571e41137c7c560cc0e6a03.png\n",
    "3_t086.png\n",
    "4_t086.png\n",
    "5f9d29d6388c700f35a3c29fa1b1ce0c1cba6667d05fdb70bd1e89004dcf71ed.png\n",
    "c0c4a829c8d33d16a02f5dc0411597329f4b4d726ed6a22b5530cf6c8e106c4e.png\n",
    "4_t064.png\n",
    "IXMtest_P07_s8_w19D682C29-5685-4A33-8CAA-F0797DD7F021.png\n",
    "0_t043.png\n",
    "5_t063.png\n",
    "4_t026.png\n",
    "a9d884ba0929dac87c2052ce5b15034163685317d7cff45c40b0f7bd9bd4d9e7.png\n",
    "3_t043.png\n",
    "b4d902d42c93dea77b541456f8d905f35eeb24fc3a5b0b15b5678d78e0aabe0c.png\n",
    "3_t057.png\n",
    "77ceeb87f560775ac150b8b9b09684ed3e806d0af6f26cce8f10c5fc280f5df2.png\n",
    "1_t045.png\n",
    "5bb8508ff8ec8683fc6a8aa6bd470f6feb3af4eccdca07f51a1ebc9dad67cfb8.png\n",
    "IXMtest_L10_s6_w12D12D64C-2639-4CA8-9BB4-99F92C9B7068.png\n",
    "c322c72b9d411e631580fee9312885088b4bb14ed297aa4b246ec943533b3ffb.png\n",
    "7af09f98ec299ba0658d759eebc4c34e1c98289ea6ce37f233e9f5e4e2fc84f4.png\n",
    "fdda64c47361b0d1a146e5b7b48dc6b7de615ea80b31f01227a3b16469589528.png\n",
    "88d5a03f8ecd459f076a06e0d5035149193bfdd727c30905de19054dcb9018ae.png\n",
    "d1ba6089cae2f90cb7275ece10ca393c25f60ea17e5c9c3cea2399d31fd41869.png\n",
    "2_t028.png\n",
    "1f6b7cead15344593b32d5f2345fc26713dc74d9b31306c824209d67da401fd8.png\n",
    "IXMtest_L03_s6_w1BE79472D-5E2C-422F-A16E-7AC0691C0FD8.png\n",
    "MFGTMPcx7_170702090001_A10f11d0.png\n",
    "8ecdb93582b2d5270457b36651b62776256ade3aaa2d7432ae65c14f07432d49.png\n",
    "ff3407842ada5bc18be79ae453e5bdaa1b68afc842fc22fa618ac6e6599d0bb3.png\n",
    "IXMtest_N12_s7_w166EF3FAB-EA33-4B28-91E3-034A1654BAAE.png\n",
    "0_t078.png\n",
    "IXMtest_P01_s3_w1A7DC2612-9C11-4656-B100-102AF8FE8B43.png\n",
    "5488e8df5440ee5161fdfae3aeccd2ee396636430065c90e3f1f73870a975991.png\n",
    "8175a55b711c948fe383bd3b91b6ca1b9e048a5241e0be13aff31ce2674fbe6d.png\n",
    "IXMtest_F12_s9_w1CD127D58-4641-41D3-88CC-E12B7FE77D78.png\n",
    "b1a239838c7dbb34ffea851ad537899f24da62f4e3f3fd6d835ff7b922f27313.png\n",
    "1_t070.png\n",
    "70827e40a7155391984e56703c6df3392fb4a94bbd6c7008da6a6ca3244965d9.png\n",
    "3_t125.png\n",
    "0_t011.png\n",
    "IXMtest_M20_s3_w15C73A7C7-F81B-4583-AB8F-0A64336AF070.png\n",
    "1db1cddf28e305c9478519cfac144eee2242183fe59061f1f15487e925e8f5b5.png\n",
    "0e5edb072788c7b1da8829b02a49ba25668b09f7201cf2b70b111fc3b853d14f.png\n",
    "4_t027.png\n",
    "3_t041.png\n",
    "MFGTMPcx7_170702090001_A12f00d0.png\n",
    "2_t010.png\n",
    "3_t002.png\n",
    "6aa7dd0c88bec4f96cdd497f9c37779733033d9ec6513307461302d36bd32ac7.png\n",
    "df5cdd0ebe1bdf8dc870bc294b8f08961e083bc7f9be69e268454aa9091808b9.png\n",
    "b0d6dfcc95e4d087d232378f860fc3ef9f95ea5a4c26d623a0be091f820a793f.png\n",
    "c89ac06daef5c819309f03d6a35792d1a8a66abb8cb3414013ffe71d3dd9fe96.png\n",
    "29ea4f6eb4545f43868a9b40a60000426bf8dfd9d062546656a37bd2a2aaf9ec.png\n",
    "8a26b134fe9343c0c794513dae7787b7ac1debec3bb2a7096ab0b874a31d8175.png\n",
    "a3a1b8f9794ef589b71faa9f35fd97ad6761c4488718fbcf766e95e31afa8606.png\n",
    "6c85029f850d392791e13f74963391054ff54e508967bbd091ee510e9e58e011.png\n",
    "3_t126.png\n",
    "3_t146.png\n",
    "f6b16c885c0b2bc0d0eb2bb2eeb0a2753ebafb5a7a91da10e89b0b0478984637.png\n",
    "0402a81e75262469925ea893b6706183832e85324f7b1e08e634129f5d522cdd.png\n",
    "1_t062.png\n",
    "0_t059.png\n",
    "IXMtest_J08_s2_w1C146DB1C-05B3-49EF-9C62-1185FD9897AC.png\n",
    "3_t128.png\n",
    "3_t005.png\n",
    "7978812d0e2e034ee1f9c141f019705582fcaa290e4a01c6c75a62753285cb23.png\n",
    "0_t035.png\n",
    "4ee5850b63549794eb3ecd3d5f5673164ac16936e36ecc3700da886e3b616149.png\n",
    "0_t073.png\n",
    "IXMtest_M12_s5_w16D817EFA-C3C9-45DB-AC15-61BB143DEC62.png\n",
    "49edc2f7715100fb0390916e52b3fd11a921f02e59509dc987f67840a36250fc.png\n",
    "3_t087.png\n",
    "bf566e75d5cb0196de4139573f8bbbda0fa38d5048edf7267fe8793dcc094a66.png\n",
    "a7a581e6760df4701941670e73d72533e3b0fbd7563488ad92772b41f7709710.png\n",
    "0bf4b144167694b6846d584cf52c458f34f28fcae75328a2a096c8214e01c0d0.png\n",
    "0_t029.png\n",
    "3b957237bc1e09740b58a414282393d3a91dde996b061e7061f4198fb03dab2e.png\n",
    "3_t119.png\n",
    "4_t036.png\n",
    "3_t139.png\n",
    "IXMtest_D08_s7_w1F476A544-A07C-4E9B-A6CB-BAEF4CD6F64E.png\n",
    "724b6b7044522f6d5ea35b55f8fa71d0a45a28687be2b7cac3149943ab816eec.png\n",
    "1_t005.png\n",
    "2ab91a4408860ae8339689ed9f87aa9359de1bdd4ca5c2eab7fff7724dbd6707.png\n",
    "2ad489c11ed8b77a9d8a2339ac64ffc38e79281c03a2507db4688fd3186c0fe5.png\n",
    "cdab367b30db47061df837c1ae9fa875d6057614f797332d37d3513517d6c694.png\n",
    "e856511ac1c34d24320eb7c56c05a4a3340d06667b4f5b8e8df615d415c7f650.png\n",
    "cf26c41245febfe67c2a1682cc4ee8752ee40ae3e49610314f45923b8bf5b08a.png\n",
    "f35ab34528e3e2d2589d24cbffc0e10024dfc474a68585d0b5feb7b05aa0067f.png\n",
    "5_t087.png\n",
    "IXMtest_P10_s7_w1F78192AF-7D11-4D41-80F3-8CD6DB05AB57.png\n",
    "3_t133.png\n",
    "IXMtest_P24_s9_w13AC6C03C-E8D7-4A23-B649-514BB4052F52.png\n",
    "IXMtest_F04_s5_w1D94DA1A2-873C-44B3-80EB-36DC2A97E9A3.png\n",
    "3_t143.png\n",
    "3_t111.png\n",
    "5_t029.png\n",
    "1_t050.png\n",
    "2_t048.png\n",
    "MFGTMPcx7_170702090001_H03f10d0.png\n",
    "1_t022.png\n",
    "6bc8cda54f5b66a2a27d962ac219f8075bf7cc43b87ba0c9e776404370429e80.png\n",
    "IXMtest_N11_s4_w142A84EA3-47C3-4B49-B6CA-BBC6685BBE1E.png\n",
    "a22b7882fa85b9f0fcef659a7b82bfcddf01710f9a7617a9e036e84ac6901841.png\n",
    "IXMtest_P21_s5_w1ACEBEE91-BAFA-49E6-9D97-D07197400A15.png\n",
    "4c032609d377bd980e01f888e0b298600bf8af0e33c4271a1f3aaf76964dce06.png\n",
    "fadeb0ab092833f27daaeb3e24223eb090f9536b83f68cde8f49df7c544f711b.png\n",
    "MFGTMPcx7_170702090001_A02f07d0.png\n",
    "jw-Kontrolle2_c5.png\n",
    "f534b43bf37ff946a310a0f08315d76c3fb3394681cf523acef7c0682240072a.png\n",
    "IXMtest_D06_s8_w1BE84C8EF-4CD0-4B56-8267-4E662F57AC25.png\n",
    "IXMtest_I07_s4_w1F156255A-3842-46FB-ABF2-9D041E523F86.png\n",
    "0_t066.png\n",
    "6b61ab2e3ff0e2c7a55fd71e290b51e142555cf82bc7574fc27326735e8acbd1.png\n",
    "IXMtest_G06_s7_w19444140C-EF22-42DE-863A-514D836BE850.png\n",
    "eb96fc6cbf6880bf05c4309857ae33844a4bc2152e228eff31024e5265cf9fc3.png\n",
    "IXMtest_B04_s4_w1F6AEFA0F-AF87-4B3B-A334-698647CFE043.png\n",
    "3_t131.png\n",
    "0_t061.png\n",
    "1_t057.png\n",
    "5_t045.png\n",
    "IXMtest_A12_s7_w1EAEEA614-51ED-43B3-A4FF-088730911E4C.png\n",
    "3_t021.png\n",
    "b1f23c4d27afed8af7b6b64793a3760bfea31b65f582d48aaa62d2b988ef2eac.png\n",
    "0_t091.png\n",
    "IXMtest_D04_s2_w1E05C134E-BAFE-4FD7-8116-2D05E0839879.png\n",
    "1_t056.png\n",
    "ed4b8e0d756836be7acb2e2b7799c473b52424e3092a71d3c6d23558e500dc4c.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
