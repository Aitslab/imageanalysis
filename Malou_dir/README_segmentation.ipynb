{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Segmentation\n",
    "\n",
    "\t1.1 Load images and convert to png\n",
    "    \n",
    "    1.2 Annotate images using cvat\n",
    "    \n",
    "    1.3 Preprocessing of images\n",
    "\t\t- Create training/validation/test fraction text files\n",
    "\t\t- Normalization\n",
    "\t\t- Creating border labels\n",
    "\t\t- Augmentation (affine transformation)\n",
    "    \n",
    "    1.4 Training\n",
    "    \n",
    "    1.5 Prediction\n",
    "    \n",
    "    1.6 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have with help from the script by Broad Bioimage Benchmarc Collection (BBBC), found at https://github.com/carpenterlab/unet4nuclei,\n",
    "recreated their experiment with the use of images from Aits lab.\n",
    "\n",
    "In the BBBC repository, the full script can be found for their experiments, but for our purpose the script has been modified.\n",
    "\n",
    "Some modifications had to be done due to outdated versions of python packages, and some modifications because of different image-formats. \n",
    "In our experiment it was also of importance to include micronucleis in the modelprediction, which was not covered by the BBBC group, so the scripts are modified to fit that purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up folders and scripts\n",
    "\n",
    "In the folder where the scripts will be stored, there should also be a script called config.py and a folder named utils containing scripts with functions. The filetree should look like this:\n",
    "\n",
    "\n",
    "**2_Final_Models**  \n",
    "- **1_Model1**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **2_Model2**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **3_Model3**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **4_Model4**\n",
    "    - **Unet**\n",
    "        - 02-training.py\n",
    "        - 03-prediction.py\n",
    "        - 04-evaluation.ipynb\n",
    "        - config.py\n",
    "        - **utils**\n",
    "            - augmentation.py\n",
    "            - data_provider.py\n",
    "            - dirtools.py\n",
    "            - evaluation.py\n",
    "            - experiment.py\n",
    "            - metrics.py\n",
    "            - model_builder.py\n",
    "            - objectives.py\n",
    "                \n",
    "- **data**\n",
    "    - **1_raw_annotations**\n",
    "    - **2_raw_images**\n",
    "    - **3_preprocessing_of_data**\n",
    "        - 00-load-and-reformat-dataset.py\n",
    "        - 01-Augmentation.py \n",
    "        - config.py \n",
    "    - **4_filelists**\n",
    "        - 1-2_training.txt\n",
    "        - 3_training.txt\n",
    "        - 4_training.txt\n",
    "        - TEST.txt\n",
    "        - VALIDATION.txt\n",
    "    \n",
    "\n",
    "The folder **2_Final_Models/data/1_raw_annotations** is where the annotations will be stored.\n",
    "\n",
    "The folder **2_Final_Models/data/1_raw_data** is where the images will be stored. \n",
    "\n",
    "\n",
    "The config.py file is set up to look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import utils.dirtools\n",
    "\n",
    "config_vars = {}\n",
    "\n",
    "# ************ 01 ************ #\n",
    "# ****** PREPROCESSING ******* #\n",
    "# **************************** #\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.01 INPUT DIRECTORIES AND FILES\n",
    "\n",
    "config_vars[\"root_directory\"] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/'\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.02 DATA PARTITION INFO\n",
    "\n",
    "## Maximum number of training images (use 0 for all)\n",
    "config_vars[\"max_training_images\"] = 0\n",
    "\n",
    "## Generate partitions?\n",
    "## If False, load predefined partitions (training.txt, validation.txt and test.txt)\n",
    "config_vars[\"create_split_files\"] = False\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.03 IMAGE STORAGE OPTIONS\n",
    "\n",
    "## Transform gray scale TIF images to PNG\n",
    "config_vars[\"transform_images_to_PNG\"] = True\n",
    "config_vars[\"pixel_depth\"] = 8\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.04 PRE-PROCESSING OF ANNOTATIONS\n",
    "\n",
    "## Area of minimun object in pixels\n",
    "config_vars[\"min_nucleus_size\"] = 10\n",
    "\n",
    "## Pixels of the boundary (min 2 pixels)\n",
    "config_vars[\"boundary_size\"] = 2\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 01.05 DATA AUGMENTATION USING ELASTIC DEFORMATIONS\n",
    "\n",
    "## Elastic deformation takes a lot of times to compute. \n",
    "## It is computed only once in the preprocessing. \n",
    "config_vars[\"augment_images\"] =  False\n",
    "\n",
    "## Augmentation parameters. \n",
    "## Calibrate parameters using the 00-elastic-deformation.ipynb\n",
    "config_vars[\"elastic_points\"] = 16\n",
    "config_vars[\"elastic_distortion\"] = 5\n",
    "\n",
    "## Number of augmented images\n",
    "config_vars[\"elastic_augmentations\"] = 10\n",
    "\n",
    "\n",
    "# ************ 02 ************ #\n",
    "# ********* TRAINING ********* #\n",
    "# **************************** #\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 02.01 OPTIMIZATION\n",
    "\n",
    "config_vars[\"learning_rate\"] = 1e-4\n",
    "\n",
    "config_vars[\"epochs\"] = 15\n",
    "\n",
    "config_vars[\"steps_per_epoch\"] = 500\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 02.02 BATCHES\n",
    "\n",
    "config_vars[\"batch_size\"] = 10\n",
    "\n",
    "config_vars[\"val_batch_size\"] = 10\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# 02.03 DATA NORMALIZATION\n",
    "\n",
    "config_vars[\"rescale_labels\"] = True\n",
    "\n",
    "config_vars[\"crop_size\"] = 256\n",
    "\n",
    "# ************ 03 ************ #\n",
    "# ******** PREDICTION ******** #\n",
    "# **************************** #\n",
    "\n",
    "config_vars[\"cell_min_size\"] = 30\n",
    "\n",
    "config_vars[\"boundary_boost_factor\"] = 1\n",
    "\n",
    "# ************ 04 ************ #\n",
    "# ******** EVALUATION ******** #\n",
    "# **************************** #\n",
    "\n",
    "config_vars[\"object_dilation\"] = 3\n",
    "\n",
    "# **************************** #\n",
    "# ******** FINAL SETUP ******* #\n",
    "# **************************** #\n",
    "\n",
    "config_vars = utils.dirtools.setup_working_directories(config_vars)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load images and convert to png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I have worked with 100 randomly selected images from the full data set consisting of approx. 6 million images, these images are of the format .C01 which is a microscopy format. The input images in the BBBC scripts are expected to be .tiff or .png, so all 100 images are first converted to png.\n",
    "\n",
    "For this I have created a script that will take a directory as input, and output the converted images to a new selected directory.\n",
    "\n",
    "The script is done with argparse, and can be used just by downloading the script and following these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and installing bftools:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd ~/bin\n",
    "wget http://downloads.openmicroscopy.org/latest/bio-formats/artifacts/bftools.zip\n",
    "unzip bftools.zip\n",
    "rm bftools.zip\n",
    "export PATH=$PATH:~/bin/bftools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing required python packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install argparse\n",
    "pip install os\n",
    "pip install subprocess\n",
    "pip install tqdm\n",
    "pip install pathlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The program is run like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python3 format_convertion.py -i INDIR -o OUTDIR -ift IN_FILETYPE -oft OUT_FILETYPE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script format_convertion.py:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import argparse\n",
    "import os\n",
    "import os.path\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "#################################### ARGPARSE ##################################\n",
    "usage = 'Enter the directory name where the files to convert are located, what format to convert the files to \\\n",
    "and name a directory where you want the converted files to end up.'\n",
    "parser = argparse.ArgumentParser(description=usage)\n",
    "parser.add_argument(\n",
    "    '-i',\n",
    "    dest = 'infile',\n",
    "    metavar = 'INDIR',\n",
    "    type = str,\n",
    "    help = 'set the directory where the input files are located',\n",
    "    required = True\n",
    "    )\n",
    "parser.add_argument(\n",
    "    '-o',\n",
    "    dest = 'outfile',\n",
    "    metavar = 'OUTDIR',\n",
    "    type = str,\n",
    "    help = 'set the directory to store the converted files',\n",
    "    required = True\n",
    "    )\n",
    "parser.add_argument(\n",
    "    '-ift',\n",
    "    dest = 'input_filetype',\n",
    "    metavar = 'IN_FILETYPE',\n",
    "    type = str,\n",
    "    help = 'Set what format the input files are, e.g C01 png',\n",
    "    required = True\n",
    "    )\n",
    "parser.add_argument(\n",
    "    '-oft',\n",
    "    dest = 'output_filetype',\n",
    "    metavar = 'OUT_FILETYPE',\n",
    "    type = str,\n",
    "    help = 'Chose format to convert to, e.g. tiff or png',\n",
    "    required = True\n",
    "    )\n",
    "args = parser.parse_args()\n",
    "################################################################################\n",
    "\n",
    "# Convert the input to the absolute path\n",
    "input_dir = os.path.abspath(args.infile)\n",
    "output_dir = os.path.abspath(args.outfile)\n",
    "\n",
    "\n",
    "out_filetype = '.{}'.format(args.output_filetype)\n",
    "in_filetype = args.input_filetype\n",
    "\n",
    "# If the output directory does not exist,\n",
    "# a directory will be created with that name.\n",
    "my_file = Path(output_dir)\n",
    "if not my_file.exists():\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# If the path provided is not a directory, raise error\n",
    "if not os.path.isdir(input_dir):\n",
    "    raise argparse.ArgumentTypeError('Input must be a directory')\n",
    "if not os.path.isdir(output_dir):\n",
    "    raise argparse.ArgumentTypeError('Output must be a directory')\n",
    "\n",
    "input_files = []\n",
    "converted_files = []\n",
    "os.chdir(input_dir)\n",
    "for i in os.listdir(input_dir):\n",
    "    if i.split('.')[-1] == in_filetype: # Checks that filename ends with format chosen\n",
    "        input_files.append(input_dir + '/' + i)\n",
    "        converted_files.append(output_dir + '/' + i.split('.')[0] + out_filetype)\n",
    "\n",
    "for i,j in tqdm(zip(input_files,converted_files), total = len(input_files)): # tqdm creates a progressbar to see the progress.\n",
    "    subprocess.run(['bfconvert', '-overwrite', '-nogroup',i,j],stdout = subprocess.PIPE, stderr = subprocess.DEVNULL) #Runs bftools which needs to be preinstalled, output to DEVNULL.\n",
    "    subprocess.run(['convert', i, '-auto-level', '-depth', '16', '-define', 'quantum:format=unsigned', '-type', 'grayscale', j],stdout = subprocess.PIPE, stderr = subprocess.DEVNULL) #Convert images to 16-bits tiff images.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download bbbc images\n",
    "\n",
    "The images from the bbbc experiment can be found here:\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC039/images.zip\n",
    "\n",
    "The images are extracted and put in the folder **2_Final_Models/data/1_raw_data**\n",
    "\n",
    "\n",
    "And the annotations for the images:\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC039/masks.zip\n",
    "\n",
    "The mask images are extracted and put in the folder **2_Final_Models/data/2_raw_annotations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Annotate images using cvat\n",
    "\n",
    "\n",
    "We have annotated 50 images to use in the experiment, we have used the annotation program cvat. Information about the program and installation instructions are found on their github page, https://github.com/opencv/cvat.\n",
    "\n",
    "Only one label is used for annotation, nucleus, and each nucleus is drawn with the polygon tool.\n",
    "\n",
    "The work is saved using the option “DUMP ANNOTATION” -> “MASK ZIP 1.1”\n",
    "\n",
    "That will create and download a zip file with one folder of images only with the class (nucleus), showing all nucleus in the same color, and one folder with annotations of the objects, each image will be an RGB image, with all objects being different colors to distinguish between them.\n",
    "\n",
    "In the creation of our labels, the object images was used. These images are not of the same format as the bbbc institute’s, so the script had to be modified to fit these images.\n",
    "\n",
    "\n",
    "The images we have annotated can be found here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{insert link}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Preprocessing of images\n",
    "\n",
    "When later training the model, the imageset is divided in to 3 categories; training-, validation-, and test- set.\n",
    "\n",
    "For our experiments we have done four different models, with different training set.\n",
    "10 images is saved as a test set, 10 is used for validation, and for the different models we have different training sets.\n",
    "\n",
    "Model 1: 30 images from Aitslab\n",
    "\n",
    "Model 2: 30 images from Aitslab that has been augmented with elastic transformation so that a total of 300 images is used.\n",
    "\n",
    "Model 3: The same as Model 2 but with additional 100 images from the bbbc group.\n",
    "\n",
    "Model 4: The same as Model 2 but with additional 200 images from the bbbc group.\n",
    "\n",
    "### Normalization and creation of boundary labels\n",
    "\n",
    "First the images are normalized to have pixel values between 0-1 instead of 0-255, and converted to png if that is not already done. \n",
    "\n",
    "Then boundary labels are created. \n",
    "Objects are found using the skimage module, both for finding distinguished objects, and for finding boundaries of the objects. The boundaries are created outside of the object.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00-load-and-reformat-dataset.py\n",
    "\n",
    "```python\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import requests\n",
    "from config import config_vars\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "import utils.dirtools\n",
    "import utils.augmentation\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2lab\n",
    "\n",
    "# Create output directories for transformed data\n",
    "\n",
    "os.makedirs(config_vars[\"normalized_images_dir\"], exist_ok=True)\n",
    "os.makedirs(config_vars[\"boundary_labels_dir\"], exist_ok=True)\n",
    "\n",
    "config_vars[\"raw_images_dir\"]='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/2_raw_images/'\n",
    "config_vars[\"raw_annotations_dir\"]='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/1_raw_annotations/'\n",
    "\n",
    "# ## Normalize images\n",
    "\n",
    "if config_vars[\"transform_images_to_PNG\"]:\n",
    "    \n",
    "    filelist = sorted(os.listdir(config_vars[\"raw_images_dir\"]))\n",
    "\n",
    "    # run over all raw images\n",
    "    for filename in tqdm(filelist):\n",
    "\n",
    "        # load image and its annotation\n",
    "        orig_img = skimage.io.imread(config_vars[\"raw_images_dir\"] + filename)       \n",
    "\n",
    "        # IMAGE\n",
    "\n",
    "        # normalize to [0,1]\n",
    "        percentile = 99.9\n",
    "        high = np.percentile(orig_img, percentile)\n",
    "        low = np.percentile(orig_img, 100-percentile)\n",
    "\n",
    "        img = np.minimum(high, orig_img)\n",
    "        img = np.maximum(low, img)\n",
    "\n",
    "        img = (img - low) / (high - low) # gives float64, thus cast to 8 bit later\n",
    "        img = skimage.img_as_ubyte(img) \n",
    "\n",
    "        skimage.io.imsave(config_vars[\"normalized_images_dir\"] + filename[:-3] + 'png', img)    \n",
    "else:\n",
    "    config_vars[\"normalized_images_dir\"] = config_vars[\"raw_images_dir\"]\n",
    "\n",
    "# ## Create boundary labels\n",
    "\n",
    "filelist = sorted(os.listdir(config_vars[\"raw_annotations_dir\"]))\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2lab\n",
    "total_objects = 0\n",
    "\n",
    "# run over all raw images\n",
    "for filename in tqdm(filelist):\n",
    "    \n",
    "    # GET ANNOTATION\n",
    "    annot = skimage.io.imread(config_vars[\"raw_annotations_dir\"] + filename)\n",
    "\n",
    "    # strip the first channel\n",
    "    if annot.shape[2]!=3:\n",
    "        annot = annot[:,:,0]\n",
    "    else:\n",
    "        annot = rgb2lab(annot)\n",
    "        annot = annot[:,:,0]\n",
    "    # label the annotations nicely to prepare for future filtering operation\n",
    "    \n",
    "    annot = skimage.morphology.label(annot)\n",
    "    total_objects += len(np.unique(annot)) - 1\n",
    "      \n",
    "    # find boundaries\n",
    "    boundaries = skimage.segmentation.find_boundaries(annot, mode = 'outer')\n",
    "\n",
    "    # BINARY LABEL\n",
    "    \n",
    "    # prepare buffer for binary label\n",
    "    label_binary = np.zeros((annot.shape + (3,)))\n",
    "    \n",
    "    # write binary label\n",
    "    label_binary[(annot == 0) & (boundaries == 0), 0] = 1\n",
    "    label_binary[(annot != 0) & (boundaries == 0), 1] = 1\n",
    "    label_binary[boundaries == 1, 2] = 1\n",
    "    \n",
    "    label_binary = img_as_ubyte(label_binary)\n",
    "    # save it - converts image to range from 0 to 255\n",
    "    skimage.io.imsave(config_vars[\"boundary_labels_dir\"] + filename, label_binary)\n",
    "    \n",
    "print(\"Total objects: \",total_objects)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "\n",
    "For Model 1, the 30 images will be augmented with affine transformation, which is done with the following script:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-Augmentation.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "from config import config_vars\n",
    "import utils.dirtools\n",
    "import utils.augmentation\n",
    "\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "\n",
    "# ## Augment (elastic transformation)\n",
    "\n",
    "config_vars[\"augment_images\"] = True\n",
    "def generate_augmented_examples(filelist, n_augmentations, n_points, distort, dir_boundary_labels, dir_images_normalized_8bit):\n",
    "    \n",
    "    updated_filelist = []\n",
    "    \n",
    "    # run over all raw images\n",
    "    for filename in tqdm(filelist):\n",
    "        print(\"Augmenting {}\".format(filename))\n",
    "            \n",
    "        # check if boundary labels were calculated \n",
    "        my_file = pathlib.Path(dir_boundary_labels + filename)\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            \n",
    "            # load image \n",
    "            x = skimage.io.imread(dir_images_normalized_8bit + filename)\n",
    "            \n",
    "            # load annotation \n",
    "            y = skimage.io.imread(dir_boundary_labels + filename)\n",
    "            \n",
    "            for n in range(1,n_augmentations):\n",
    "                # augment image and annotation \n",
    "                x_augmented, y_augmented = utils.augmentation.deform(x, y, points = n_points, distort = distort)\n",
    "                \n",
    "                # filename for augmented images\n",
    "                filename_augmented = os.path.splitext(filename)[0] + '_aug_{:03d}'.format(n) + os.path.splitext(filename)[1]\n",
    "                skimage.io.imsave(dir_images_normalized_8bit + filename_augmented, x_augmented)\n",
    "                skimage.io.imsave(dir_boundary_labels + filename_augmented, y_augmented)\n",
    "                updated_filelist.append(filename_augmented)\n",
    "                \n",
    "    return filelist + updated_filelist \n",
    "\n",
    "if config_vars[\"augment_images\"]:\n",
    "    \n",
    "    tmp_value = config_vars[\"max_training_images\"]\n",
    "    config_vars[\"max_training_images\"] = 0\n",
    "    tmp_partitions = utils.dirtools.read_data_partitions(config_vars, load_augmented=False)\n",
    "    \n",
    "    training_files = generate_augmented_examples(\n",
    "        tmp_partitions[\"training\"], \n",
    "        config_vars[\"elastic_augmentations\"], \n",
    "        config_vars[\"elastic_points\"], \n",
    "        config_vars[\"elastic_distortion\"], \n",
    "        config_vars[\"boundary_labels_dir\"], \n",
    "        config_vars[\"normalized_images_dir\"]\n",
    "    )\n",
    "    \n",
    "    config_vars[\"max_training_images\"] = tmp_value\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Training\n",
    "\n",
    "The training script looks the same for each model except for the variable \"config_vars['path_files_training']\"\n",
    "and \"experiment_name\", and \"data_partitions\" which are modified as follows:\n",
    "\n",
    "for Model 1, the script is the one below,\n",
    "\n",
    "for Model 2:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "experiment_name = 'Model_2'\n",
    "```\n",
    "\n",
    "for Model 3:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/3_training.txt'\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "experiment_name = 'Model_3'\n",
    "```\n",
    "\n",
    "for Model 4:\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/4_training.txt'\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "experiment_name = 'Model_4'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02-training.py\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend\n",
    "import keras.callbacks\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.optimizers\n",
    "\n",
    "import utils.model_builder\n",
    "import utils.data_provider\n",
    "import utils.metrics\n",
    "import utils.objectives\n",
    "import utils.dirtools\n",
    "\n",
    "from config import config_vars\n",
    "\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "experiment_name = 'Model_1'\n",
    "\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars, load_augmented = False)\n",
    "\n",
    "\n",
    "# build session running on GPU 1\n",
    "configuration = tf.compat.v1.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"1\"\n",
    "session = tf.compat.v1.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "train_gen = utils.data_provider.random_sample_generator(\n",
    "    config_vars[\"normalized_images_dir\"],\n",
    "    config_vars[\"boundary_labels_dir\"],\n",
    "    data_partitions[\"training\"],\n",
    "    config_vars[\"batch_size\"],\n",
    "    config_vars[\"pixel_depth\"],\n",
    "    config_vars[\"crop_size\"],\n",
    "    config_vars[\"crop_size\"],\n",
    "    config_vars[\"rescale_labels\"]\n",
    ")\n",
    "\n",
    "val_gen = utils.data_provider.single_data_from_images(\n",
    "     config_vars[\"normalized_images_dir\"],\n",
    "     config_vars[\"boundary_labels_dir\"],\n",
    "     data_partitions[\"validation\"],\n",
    "     config_vars[\"val_batch_size\"],\n",
    "     config_vars[\"pixel_depth\"],\n",
    "     config_vars[\"crop_size\"],\n",
    "     config_vars[\"crop_size\"],\n",
    "     config_vars[\"rescale_labels\"]\n",
    ")\n",
    "\n",
    "\n",
    "# build model\n",
    "model = utils.model_builder.get_model_3_class(config_vars[\"crop_size\"], config_vars[\"crop_size\"], activation=None)\n",
    "model.summary()\n",
    "\n",
    "#loss = \"categorical_crossentropy\"\n",
    "loss = utils.objectives.weighted_crossentropy\n",
    "\n",
    "metrics = [keras.metrics.categorical_accuracy, \n",
    "           utils.metrics.channel_recall(channel=0, name=\"background_recall\"), \n",
    "           utils.metrics.channel_precision(channel=0, name=\"background_precision\"),\n",
    "           utils.metrics.channel_recall(channel=1, name=\"interior_recall\"), \n",
    "           utils.metrics.channel_precision(channel=1, name=\"interior_precision\"),\n",
    "           utils.metrics.channel_recall(channel=2, name=\"boundary_recall\"), \n",
    "           utils.metrics.channel_precision(channel=2, name=\"boundary_precision\"),\n",
    "          ]\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=config_vars[\"learning_rate\"])\n",
    "\n",
    "model.compile(loss=loss, metrics=metrics, optimizer=optimizer)\n",
    "\n",
    "# Performance logging\n",
    "callback_csv = keras.callbacks.CSVLogger(filename=config_vars[\"csv_log_file\"])\n",
    "\n",
    "callbacks=[callback_csv]\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "statistics = model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    steps_per_epoch=config_vars[\"steps_per_epoch\"],\n",
    "    epochs=config_vars[\"epochs\"],\n",
    "#    epochs = 3,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=int(len(data_partitions[\"validation\"])/config_vars[\"val_batch_size\"]),\n",
    "    callbacks=callbacks,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "model.save_weights(config_vars[\"model_file\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Prediction\n",
    "\n",
    "As for the training scripts, the prediction scripts look the same for each model except for the variable \"config_vars['path_files_training']\"\n",
    "and \"experiment_name\", which are modified as follows:\n",
    "\n",
    "for Model 1, the script is the one below,\n",
    "\n",
    "for Model 2:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "\n",
    "experiment_name = 'Model_2'\n",
    "```\n",
    "\n",
    "for Model 3:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/3_training.txt'\n",
    "\n",
    "experiment_name = 'Model_3'\n",
    "```\n",
    "\n",
    "for Model 4:\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/4_training.txt'\n",
    "\n",
    "experiment_name = 'Model_4'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-prediction.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import utils.metrics\n",
    "import utils.model_builder\n",
    "print(skimage.__version__)\n",
    "\n",
    "\n",
    "# # Configuration\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from config import config_vars\n",
    "\n",
    "# Partition of the data to make predictions (test or validation)\n",
    "\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "partition = \"validation\"\n",
    "\n",
    "experiment_name = 'Model_1'\n",
    "\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "\n",
    "# Configuration to run on GPU\n",
    "configuration = tf.compat.v1.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"0\"\n",
    "\n",
    "session = tf.compat.v1.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "\n",
    "# # Load images and run predictions\n",
    "\n",
    "image_names = [os.path.join(config_vars[\"normalized_images_dir\"], f) for f in data_partitions[partition]]\n",
    "\n",
    "imagebuffer = skimage.io.imread_collection(image_names)\n",
    "\n",
    "images = imagebuffer.concatenate()\n",
    "\n",
    "dim1 = images.shape[1]\n",
    "dim2 = images.shape[2]\n",
    "\n",
    "images = images.reshape((-1, dim1, dim2, 1))\n",
    "\n",
    "# preprocess (assuming images are encoded as 8-bits in the preprocessing step)\n",
    "images = images / 255\n",
    "\n",
    "# build model and load weights\n",
    "model = utils.model_builder.get_model_3_class(dim1, dim2)\n",
    "model.load_weights(config_vars[\"model_file\"])\n",
    "\n",
    "# Normal prediction time\n",
    "predictions = model.predict(images, batch_size=1)\n",
    "\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Code inspired by scikit-images source-code for skimage.morphology.remove_small_objects()\n",
    "def remove_large_objects(image, min_size):\n",
    "    out = np.copy(image)\n",
    "    \n",
    "    if out.dtype == bool:\n",
    "        selem = ndi.generate_binary_structure(image.ndim,1)\n",
    "        ccs = np.zeros_like(image, dtype=np.int32)\n",
    "        ndi.label(image, selem, output=ccs)\n",
    "    else:\n",
    "        ccs = out\n",
    "    component_sizes = np.bincount(ccs.ravel())\n",
    "    too_large = component_sizes > min_size\n",
    "    too_large_mask = too_large[ccs]\n",
    "    out[too_large_mask] = 0\n",
    "    return out\n",
    "\n",
    "def pred_to_label(pred, cell_min_size, cell_label=1):\n",
    "    # Only marks interior of cells (cell_label = 1 is interior, cell_label = 2 is boundary)\n",
    "    cell_orig = (pred == cell_label)\n",
    "    \n",
    "    cell_small = (pred == 1) + (pred == 2)\n",
    "    cell_small = remove_large_objects(cell_small,100) \n",
    "    \n",
    "    cell_concat = cell_orig + cell_small\n",
    "    \n",
    "    cell_orig = skimage.morphology.remove_small_holes(cell_concat, area_threshold=cell_min_size)\n",
    "    cell_orig = skimage.morphology.remove_small_objects(cell_concat, min_size=cell_min_size)\n",
    "    # label cells only\n",
    "    [label, num] = skimage.morphology.label(cell_orig, return_num=True)\n",
    "    return label\n",
    "\n",
    "\n",
    "# # Transform predictions to label matrices\n",
    "\n",
    "for i in range(len(images)):\n",
    "\n",
    "    filename = imagebuffer.files[i]\n",
    "    filename = os.path.basename(filename)\n",
    "    \n",
    "    probmap = predictions[i].squeeze()\n",
    "    \n",
    "    skimage.io.imsave(config_vars[\"probmap_out_dir\"] + filename, probmap)\n",
    "    \n",
    "    pred = np.argmax(probmap * [1, 1, 1], -1)\n",
    "    \n",
    "    label = pred_to_label(pred, config_vars[\"cell_min_size\"])\n",
    "    \n",
    "    skimage.io.imsave(config_vars[\"labels_out_dir\"] + filename, label)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Evaluation\n",
    "\n",
    "The evaluation script looks the same for each model except for the variable \"config_vars['path_files_training']\"\n",
    "and \"experiment_name\", which are modified as follows:\n",
    "\n",
    "for Model 1, the script is the one below,\n",
    "\n",
    "for Model 2:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "\n",
    "experiment_name = 'Model_2'\n",
    "```\n",
    "\n",
    "for Model 3:\n",
    "\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/3_training.txt'\n",
    "\n",
    "experiment_name = 'Model_3'\n",
    "```\n",
    "\n",
    "for Model 4:\n",
    "```python\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/4_training.txt'\n",
    "\n",
    "experiment_name = 'Model_4'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-evaluation.py\n",
    "\n",
    "```python\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "\n",
    "import utils.evaluation\n",
    "from config import config_vars\n",
    "\n",
    "\n",
    "# Partition of the data to make predictions (test or validation)\n",
    "config_vars['path_files_training'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/1-2_training.txt'\n",
    "config_vars['path_files_validation'] ='/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/VALIDATION.txt'\n",
    "config_vars['path_files_test'] = '/home/maloua/Malou_Master/5_Models/2_Final_Models/data/4_filelists/TEST.txt'\n",
    "\n",
    "partition = \"validation\"\n",
    "\n",
    "experiment_name = 'Model_1'\n",
    "\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "\n",
    "\n",
    "# Display prediction along with segmentation to visualize errors\n",
    "\n",
    "def show(ground_truth, prediction, threshold=0.5, image_name=\"N\"):\n",
    "    \n",
    "    # Compute Intersection over Union\n",
    "    IOU = utils.evaluation.intersection_over_union(ground_truth, prediction)\n",
    "    \n",
    "    # Create diff map\n",
    "    diff = np.zeros(ground_truth.shape + (3,))\n",
    "    A = ground_truth.copy()\n",
    "    B = prediction.copy()\n",
    "    A[A > 0] = 1\n",
    "    B[B > 0] = 1\n",
    "    D = A - B\n",
    "    #diff[D > 0,:2] = 1\n",
    "    #diff[D < 0,1:] = 1\n",
    "    \n",
    "    # Object-level errors\n",
    "    C = IOU.copy()\n",
    "    C[C>=threshold] = 1\n",
    "    C[C<threshold] = 0\n",
    "    missed = np.where(np.sum(C,axis=1) == 0)[0]\n",
    "    extra = np.where(np.sum(C,axis=0) == 0)[0]\n",
    "\n",
    "    for m in missed:\n",
    "        diff[ground_truth == m+1, 0] = 1\n",
    "    for e in extra:\n",
    "        diff[prediction == e+1, 2] = 1\n",
    "    \n",
    "    # Display figures\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18,6))\n",
    "    ax[0].imshow(ground_truth)\n",
    "    ax[0].set_title(\"True objects:\"+str(len(np.unique(ground_truth))))\n",
    "    ax[1].imshow(diff)\n",
    "    ax[1].set_title(\"Segmentation errors:\"+str(len(missed)))\n",
    "    ax[2].imshow(prediction)\n",
    "    ax[2].set_title(\"Predicted objects:\"+str(len(np.unique(prediction))))\n",
    "    ax[3].imshow(IOU)\n",
    "    ax[3].set_title(image_name)\n",
    "\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Code inspired by scikit-images source-code for skimage.morphology.remove_small_objects()\n",
    "def remove_large_objects(image, min_size):\n",
    "    out = np.copy(image)\n",
    "    \n",
    "    if out.dtype == bool:\n",
    "        selem = ndi.generate_binary_structure(image.ndim,1)\n",
    "        ccs = np.zeros_like(image, dtype=np.int32)\n",
    "        ndi.label(image, selem, output=ccs)\n",
    "    else:\n",
    "        ccs = out\n",
    "    component_sizes = np.bincount(ccs.ravel())\n",
    "    too_large = component_sizes > min_size\n",
    "    too_large_mask = too_large[ccs]\n",
    "    out[too_large_mask] = 0\n",
    "    return out\n",
    "\n",
    "def pred_to_label(pred, cell_min_size, cell_label=1):\n",
    "    # Only marks interior of cells (cell_label = 1 is interior, cell_label = 2 is boundary)\n",
    "    cell_orig = (pred == cell_label)\n",
    "    \n",
    "    cell_small = (pred == 1) + (pred == 2)\n",
    "    cell_small = remove_large_objects(cell_small,100) \n",
    "    \n",
    "    cell_concat = cell_orig + cell_small\n",
    "    \n",
    "    cell_orig = skimage.morphology.remove_small_holes(cell_concat, area_threshold=cell_min_size)\n",
    "    cell_orig = skimage.morphology.remove_small_objects(cell_concat, min_size=cell_min_size)\n",
    "    # label cells only\n",
    "    [label, num] = skimage.morphology.label(cell_concat, return_num=True)\n",
    "    return label\n",
    "\n",
    "\n",
    "# Run the evaluation\n",
    "\n",
    "l_images = data_partitions[partition]\n",
    "from skimage.color import rgb2gray,rgb2lab\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Image\", \"Threshold\", \"F1\", \"Jaccard\", \"TP\", \"FP\", \"FN\"])\n",
    "false_negatives = pd.DataFrame(columns=[\"False_Negative\", \"Area\"])\n",
    "splits_merges = pd.DataFrame(columns=[\"Image_Name\", \"Merges\", \"Splits\"])\n",
    "\n",
    "for image_name in all_images:\n",
    "    # Load ground truth data\n",
    "    img_filename = os.path.join(config_vars[\"boundary_labels_dir\"], image_name)\n",
    "    ground_truth = skimage.io.imread(img_filename)\n",
    "    ground_truth = ground_truth.squeeze()\n",
    "    #if len(ground_truth.shape) == 3:\n",
    "    #    ground_truth = rgb2lab(ground_truth)\n",
    "    #    ground_truth = ground_truth[:,:,0]\n",
    "    \n",
    "    ground_truth = np.argmax(ground_truth * [1, 1, 1], -1)\n",
    "    \n",
    "    ground_truth = pred_to_label(ground_truth, config_vars[\"cell_min_size\"])\n",
    "    # Transform to label matrix\n",
    "    #ground_truth = skimage.morphology.label(ground_truth)\n",
    "    \n",
    "    # Load predictions\n",
    "    pred_filename = os.path.join(config_vars[\"labels_out_dir\"], image_name)\n",
    "    prediction = skimage.io.imread(pred_filename)\n",
    "    \n",
    "    # Apply object dilation\n",
    "    if config_vars[\"object_dilation\"] > 0:\n",
    "        struct = skimage.morphology.square(config_vars[\"object_dilation\"])\n",
    "        prediction = skimage.morphology.dilation(prediction, struct)\n",
    "    elif config_vars[\"object_dilation\"] < 0:\n",
    "        struct = skimage.morphology.square(-config_vars[\"object_dilation\"])\n",
    "        prediction = skimage.morphology.erosion(prediction, struct)\n",
    "        \n",
    "    # Relabel objects (cut margin of 30 pixels to make a fair comparison with DeepCell)\n",
    "    ground_truth = skimage.segmentation.relabel_sequential(ground_truth)[0] #[30:-30,30:-30])[0]\n",
    "    prediction = skimage.segmentation.relabel_sequential(prediction)[0] #[30:-30,30:-30])[0]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    results = utils.evaluation.compute_af1_results(\n",
    "        ground_truth, \n",
    "        prediction, \n",
    "        results, \n",
    "        image_name\n",
    "    )\n",
    "    \n",
    "    false_negatives = utils.evaluation.get_false_negatives(\n",
    "        ground_truth, \n",
    "        prediction, \n",
    "        false_negatives, \n",
    "        image_name\n",
    "    )\n",
    "    \n",
    "    splits_merges = utils.evaluation.get_splits_and_merges(\n",
    "        ground_truth, \n",
    "        prediction, \n",
    "        splits_merges, \n",
    "        image_name\n",
    "    )\n",
    "    \n",
    "    # Display an example image\n",
    "    #if image_name == all_images[0]:\n",
    "    show(ground_truth, prediction, image_name=image_name)\n",
    "\n",
    "\n",
    "# Display accuracy results\n",
    "\n",
    "average_performance = results.groupby(\"Threshold\").mean().reset_index()\n",
    "\n",
    "R = results.groupby(\"Image\").mean().reset_index()\n",
    "g = sb.jointplot(data=R[R[\"F1\"] > 0.4], x=\"Jaccard\", y=\"F1\")\n",
    "\n",
    "average_performance\n",
    "R.sort_values(by=\"F1\",ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# Plot accuracy results\n",
    "\n",
    "sb.regplot(data=average_performance, x=\"Threshold\", y=\"F1\", order=3, ci=None)\n",
    "average_performance\n",
    "\n",
    "\n",
    "\n",
    "# Compute and print Average F1\n",
    "\n",
    "average_F1_score = average_performance[\"F1\"].mean()\n",
    "jaccard_index = average_performance[\"Jaccard\"].mean()\n",
    "print(\"Average F1 score:\", average_F1_score)\n",
    "print(\"Jaccard index:\", jaccard_index)\n",
    "\n",
    "# Summarize False Negatives by area\n",
    "\n",
    "false_negatives = false_negatives[false_negatives[\"False_Negative\"] == 1]\n",
    "\n",
    "false_negatives.groupby(\n",
    "    pd.cut(\n",
    "        false_negatives[\"Area\"], \n",
    "        [0,250,625,900,10000], # Area intervals\n",
    "        labels=[\"Tiny nuclei\",\"Small nuclei\",\"Normal nuclei\",\"Large nuclei\"],\n",
    "    )\n",
    ")[\"False_Negative\"].sum()\n",
    "\n",
    "\n",
    "# Summarize splits and merges\n",
    "\n",
    "print(\"Splits:\",np.sum(splits_merges[\"Splits\"]))\n",
    "print(\"Merges:\",np.sum(splits_merges[\"Merges\"]))\n",
    "\n",
    "# Report false positives\n",
    "\n",
    "print(\"Extra objects (false postives):\",results[results[\"Threshold\"].round(3) == 0.7].sum()[\"FP\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentation.py\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "from skimage.util import img_as_ubyte\n",
    "# Based on example code from:\n",
    "# http://scikit-image.org/docs/dev/auto_examples/transform/plot_piecewise_affine.html\n",
    "\n",
    "def deform(image1, image2, points=10, distort=5.0):\n",
    "    \n",
    "    # create deformation grid \n",
    "    rows, cols = image1.shape[0], image1.shape[1]\n",
    "    src_cols = np.linspace(0, cols, points)\n",
    "    src_rows = np.linspace(0, rows, points)\n",
    "    src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "    src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    # add distortion to coordinates\n",
    "    s = src[:, 1].shape\n",
    "    dst_rows = src[:, 1] + np.random.normal(size=s)*np.random.uniform(0.0, distort, size=s)\n",
    "    dst_cols = src[:, 0] + np.random.normal(size=s)*np.random.uniform(0.0, distort, size=s)\n",
    "    \n",
    "    dst = np.vstack([dst_cols, dst_rows]).T\n",
    "\n",
    "    tform = skimage.transform.PiecewiseAffineTransform()\n",
    "    tform.estimate(src, dst)\n",
    "\n",
    "    out_rows = rows \n",
    "    out_cols = cols\n",
    "    out1 = skimage.transform.warp(image1, tform, output_shape=(out_rows, out_cols), mode=\"symmetric\")\n",
    "    out2 = skimage.transform.warp(image2, tform, output_shape=(out_rows, out_cols), mode=\"symmetric\")\n",
    "    \n",
    "    return img_as_ubyte(out1), img_as_ubyte(out2)\n",
    "\n",
    "\n",
    "def resize(x, y):\n",
    "    wf = 1 + np.random.uniform(-0.25, 0.25)\n",
    "    hf = 1 + np.random.uniform(-0.25, 0.25)\n",
    "\n",
    "    w,h = x.shape[0:2]\n",
    "\n",
    "    wt, ht = int(wf*w), int(hf*h)\n",
    "\n",
    "    new_x = skimage.transform.resize(x, (wt,ht))\n",
    "    new_y = skimage.transform.resize(y, (wt,ht))\n",
    "\n",
    "    return new_x, new_y\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_provider.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io\n",
    "import keras.preprocessing.image\n",
    "\n",
    "import utils.augmentation\n",
    "\n",
    "\n",
    "def setup_working_directories(config_vars):\n",
    "\n",
    "    ## Expected raw data directories:\n",
    "    config_vars[\"raw_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_images/')\n",
    "    config_vars[\"raw_annotations_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_annotations/')\n",
    "\n",
    "    ## Split files\n",
    "    config_vars[\"path_files_training\"] = os.path.join(config_vars[\"root_directory\"], 'training.txt')\n",
    "    config_vars[\"path_files_validation\"] = os.path.join(config_vars[\"root_directory\"], 'validation.txt')\n",
    "    config_vars[\"path_files_test\"] = os.path.join(config_vars[\"root_directory\"], 'test.txt')\n",
    "\n",
    "    ## Transformed data directories:\n",
    "    config_vars[\"normalized_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'norm_images/')\n",
    "    config_vars[\"boundary_labels_dir\"] = os.path.join(config_vars[\"root_directory\"], 'boundary_labels/')\n",
    "\n",
    "    return config_vars\n",
    "\n",
    "def single_data_from_images(x_dir, y_dir, image_names, batch_size, bit_depth, dim1, dim2, rescale_labels):\n",
    "\n",
    "    ## Prepare image names\n",
    "    x_image_names = [os.path.join(x_dir, f) for f in image_names]\n",
    "    y_image_names = [os.path.join(y_dir, f) for f in image_names]\n",
    "\n",
    "    ## Load all images in memory\n",
    "    x = skimage.io.imread_collection(x_image_names).concatenate()\n",
    "    y = skimage.io.imread_collection(y_image_names).concatenate()\n",
    "\n",
    "    ## Crop the desired size\n",
    "    x = x[:, 0:dim1, 0:dim2]\n",
    "    x = x.reshape(-1, dim1, dim2, 1)\n",
    "    y = y[:, 0:dim1, 0:dim2, :]\n",
    "\n",
    "    ## Setup Keras Generators\n",
    "    rescale_factor = 1./(2**bit_depth - 1)\n",
    "    \n",
    "    if(rescale_labels):\n",
    "        rescale_factor_labels = rescale_factor\n",
    "    else:\n",
    "        rescale_factor_labels = 1\n",
    "\n",
    "    gen_x = keras.preprocessing.image.ImageDataGenerator(rescale=rescale_factor)\n",
    "    gen_y = keras.preprocessing.image.ImageDataGenerator(rescale=rescale_factor_labels)\n",
    "    \n",
    "    seed = 42\n",
    "\n",
    "    stream_x = gen_x.flow(\n",
    "        x,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    stream_y = gen_y.flow(\n",
    "        y,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    flow = zip(stream_x, stream_y)\n",
    "    \n",
    "    return flow\n",
    "\n",
    "\n",
    "def random_sample_generator(x_dir, y_dir, image_names, batch_size, bit_depth, dim1, dim2, rescale_labels):\n",
    "\n",
    "    do_augmentation = True\n",
    "    \n",
    "    # get image names\n",
    "    print('Training with',len(image_names), 'images.')\n",
    "\n",
    "    # get dimensions right -- understand data set\n",
    "    n_images = len(image_names)\n",
    "    ref_img = skimage.io.imread(os.path.join(y_dir, image_names[0]))\n",
    "\n",
    "    if(len(ref_img.shape) == 2):\n",
    "        gray = True\n",
    "    else:\n",
    "        gray = False\n",
    "    \n",
    "    # rescale images\n",
    "    rescale_factor = 1./(2**bit_depth - 1)\n",
    "    if(rescale_labels):\n",
    "        rescale_factor_labels = rescale_factor\n",
    "    else:\n",
    "        rescale_factor_labels = 1\n",
    "        \n",
    "    while(True):\n",
    "        \n",
    "        if(gray):\n",
    "            y_channels = 1\n",
    "        else:\n",
    "            y_channels = 3\n",
    "            \n",
    "        # buffers for a batch of data\n",
    "        x = np.zeros((batch_size, dim1, dim2, 1))\n",
    "        y = np.zeros((batch_size, dim1, dim2, y_channels))\n",
    "        \n",
    "        # get one image at a time\n",
    "        for i in range(batch_size):\n",
    "                       \n",
    "            # get random image\n",
    "            img_index = np.random.randint(low=0, high=n_images)\n",
    "            \n",
    "            # open images\n",
    "            x_big = skimage.io.imread(os.path.join(x_dir, image_names[img_index])) * rescale_factor\n",
    "            y_big = skimage.io.imread(os.path.join(y_dir, image_names[img_index])) * rescale_factor_labels\n",
    "\n",
    "            # resizing\n",
    "            #x_big, y_big = utils.augmentation.resize(patch_x, patch_y)\n",
    "\n",
    "\n",
    "            # get random crop\n",
    "            start_dim1 = np.random.randint(low=0, high=x_big.shape[0] - dim1)\n",
    "            start_dim2 = np.random.randint(low=0, high=x_big.shape[1] - dim2)\n",
    "\n",
    "            patch_x = x_big[start_dim1:start_dim1 + dim1, start_dim2:start_dim2 + dim2] #* rescale_factor\n",
    "            patch_y = y_big[start_dim1:start_dim1 + dim1, start_dim2:start_dim2 + dim2] #* rescale_factor_labels\n",
    "\n",
    "            if(do_augmentation):\n",
    "                \n",
    "                rand_flip = np.random.randint(low=0, high=2)\n",
    "                rand_rotate = np.random.randint(low=0, high=4)\n",
    "                \n",
    "                # flip\n",
    "                if(rand_flip == 0):\n",
    "                    patch_x = np.flip(patch_x, 0)\n",
    "                    patch_y = np.flip(patch_y, 0)\n",
    "                \n",
    "                # rotate\n",
    "                for rotate_index in range(rand_rotate):\n",
    "                    patch_x = np.rot90(patch_x)\n",
    "                    patch_y = np.rot90(patch_y)\n",
    "\n",
    "                # illumination\n",
    "                ifactor = 1 + np.random.uniform(-0.75, 0.75)\n",
    "                patch_x *= ifactor\n",
    "                    \n",
    "            # save image to buffer\n",
    "            x[i, :, :, 0] = patch_x\n",
    "            \n",
    "            if(gray):\n",
    "                y[i, :, :, 0] = patch_y\n",
    "            else:\n",
    "                y[i, :, :, 0:y_channels] = patch_y\n",
    "            \n",
    "        # return the buffer\n",
    "        yield(x, y)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dirtools.py \n",
    "\n",
    "```python\n",
    "import os\n",
    "import glob\n",
    "import random \n",
    "\n",
    "def create_image_lists(dir_raw_images, fraction_train = 0.5, fraction_validation = 0.25):\n",
    "    file_list = os.listdir(dir_raw_images)\n",
    "\n",
    "    if (fraction_train + fraction_validation >= 1):\n",
    "        print(\"fraction_train + fraction_validation is > 1!\")\n",
    "        print(\"setting fraction_train = 0.5, fraction_validation = 0.25\")\n",
    "        fraction_train = 0.5\n",
    "        fraction_validation = 0.25\n",
    "        \n",
    "    fraction_test = 1 - fraction_train - fraction_validation\n",
    "\n",
    "    image_list = [x for x in file_list if x.endswith(\"png\") ]\n",
    "\n",
    "    random.shuffle(image_list)\n",
    "\n",
    "    index_train_end = int( len(image_list) * fraction_train)\n",
    "    index_validation_end = index_train_end + int(len(image_list) * fraction_validation)\n",
    "\n",
    "    # split into two parts for training and testing \n",
    "    image_list_train = image_list[0:index_train_end]\n",
    "    image_list_test = image_list[index_train_end:(index_validation_end)]\n",
    "    image_list_validation = image_list[index_validation_end:]\n",
    "    return(image_list_train, image_list_test, image_list_validation)\n",
    "\n",
    "\n",
    "def write_path_files(file_path, list):\n",
    "    with open(file_path, 'w') as myfile:\n",
    "        for line in  list: myfile.write(line + '\\n')\n",
    "\n",
    "\n",
    "def setup_working_directories(config_vars):\n",
    "\n",
    "    ## Expected raw data directories:\n",
    "    config_vars[\"raw_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_images/')\n",
    "    config_vars[\"raw_annotations_dir\"] = os.path.join(config_vars[\"root_directory\"], 'raw_annotations/')\n",
    "\n",
    "    ## Split files\n",
    "    config_vars[\"path_files_training\"] = os.path.join(config_vars[\"root_directory\"], 'training.txt')\n",
    "    config_vars[\"path_files_validation\"] = os.path.join(config_vars[\"root_directory\"], 'validation.txt')\n",
    "    config_vars[\"path_files_test\"] = os.path.join(config_vars[\"root_directory\"], 'test.txt')\n",
    "\n",
    "    ## Transformed data directories:\n",
    "    config_vars[\"normalized_images_dir\"] = os.path.join(config_vars[\"root_directory\"], 'norm_images/')\n",
    "    config_vars[\"boundary_labels_dir\"] = os.path.join(config_vars[\"root_directory\"], 'boundary_labels/')\n",
    "\n",
    "    return config_vars\n",
    "\n",
    "\n",
    "def read_data_partitions(config_vars, load_augmented=True):\n",
    "    with open(config_vars[\"path_files_training\"]) as f:\n",
    "        training_files = f.read().splitlines()\n",
    "        if config_vars[\"max_training_images\"] > 0:\n",
    "            random.shuffle(training_files)\n",
    "            training_files = training_files[0:config_vars[\"max_training_images\"]]\n",
    "        \n",
    "    with open(config_vars[\"path_files_validation\"]) as f:\n",
    "        validation_files = f.read().splitlines()\n",
    "    \n",
    "    with open(config_vars[\"path_files_test\"]) as f:\n",
    "        test_files = f.read().splitlines()\n",
    "\n",
    "    # Add augmented images to the training list\n",
    "    if load_augmented:\n",
    "        files = glob.glob(config_vars[\"root_directory\"] + \"norm_images/*_aug_*.png\")\n",
    "        files = [f.split(\"/\")[-1] for f in files]\n",
    "        augmentedtraining = []\n",
    "        augmentedvalidation = []\n",
    "        for trf in training_files:\n",
    "            augmentedtraining += [f for f in files if f.startswith(trf.split(\".\")[0])]\n",
    "        training_files += augmentedtraining\n",
    "        #for vlf in validation_files:\n",
    "        #    augmentedvalidation += [f for f in files if f.startswith(vlf.split(\".\")[0])]\n",
    "        #validation_files += augmentedvalidation\n",
    "        #else:\n",
    "         #   training_files += files\n",
    "\n",
    "    partitions = {\n",
    "        \"training\": training_files,\n",
    "        \"validation\": validation_files,\n",
    "        \"test\": test_files\n",
    "    }\n",
    "\n",
    "    return partitions\n",
    "\n",
    "def setup_experiment(config_vars, tag):\n",
    "\n",
    "    # Output dirs\n",
    "    config_vars[\"experiment_dir\"] = os.path.join(config_vars[\"root_directory\"], \"experiments/\" + tag + \"/out/\")\n",
    "    config_vars[\"probmap_out_dir\"] = os.path.join(config_vars[\"experiment_dir\"], \"prob/\")\n",
    "    config_vars[\"labels_out_dir\"] = os.path.join(config_vars[\"experiment_dir\"], \"segm/\")\n",
    "\n",
    "    # Files\n",
    "    config_vars[\"model_file\"] = config_vars[\"root_directory\"] + \"experiments/\" + tag + \"/model.hdf5\"\n",
    "    config_vars[\"csv_log_file\"] = config_vars[\"root_directory\"] + \"experiments/\" + tag + \"/log.csv\"\n",
    "\n",
    "    # Make output directories\n",
    "    os.makedirs(config_vars[\"experiment_dir\"], exist_ok=True)\n",
    "    os.makedirs(config_vars[\"probmap_out_dir\"], exist_ok=True)\n",
    "    os.makedirs(config_vars[\"labels_out_dir\"], exist_ok=True)\n",
    "\n",
    "    return config_vars\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation.py\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def intersection_over_union(ground_truth, prediction):\n",
    "    \n",
    "    # Count objects\n",
    "    true_objects = len(np.unique(ground_truth))\n",
    "    pred_objects = len(np.unique(prediction))\n",
    "    \n",
    "    # Compute intersection\n",
    "    h = np.histogram2d(ground_truth.flatten(), prediction.flatten(), bins=(true_objects,pred_objects))\n",
    "    intersection = h[0]\n",
    "    \n",
    "    # Area of objects\n",
    "    area_true = np.histogram(ground_truth, bins=true_objects)[0]\n",
    "    area_pred = np.histogram(prediction, bins=pred_objects)[0]\n",
    "    \n",
    "    # Calculate union\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "    union = area_true + area_pred - intersection\n",
    "    \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    \n",
    "    # Compute Intersection over Union\n",
    "    union[union == 0] = 1e-9\n",
    "    IOU = intersection/union\n",
    "    \n",
    "    return IOU\n",
    "    \n",
    "\n",
    "\n",
    "def measures_at(threshold, IOU):\n",
    "    \n",
    "    matches = IOU > threshold\n",
    "    \n",
    "    true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Extra objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Missed objects\n",
    "    \n",
    "    assert np.all(np.less_equal(true_positives, 1))\n",
    "    assert np.all(np.less_equal(false_positives, 1))\n",
    "    assert np.all(np.less_equal(false_negatives, 1))\n",
    "    \n",
    "    TP, FP, FN = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "    \n",
    "    f1 = 2*TP / (2*TP + FP + FN + 1e-9)\n",
    "    \n",
    "    return f1, TP, FP, FN\n",
    "\n",
    "# Compute Average Precision for all IoU thresholds\n",
    "\n",
    "def compute_af1_results(ground_truth, prediction, results, image_name):\n",
    "\n",
    "    # Compute IoU\n",
    "    IOU = intersection_over_union(ground_truth, prediction)\n",
    "    if IOU.shape[0] > 0:\n",
    "        jaccard = np.max(IOU, axis=0).mean()\n",
    "    else:\n",
    "        jaccard = 0.0\n",
    "    \n",
    "    # Calculate F1 score at all thresholds\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        f1, tp, fp, fn = measures_at(t, IOU)\n",
    "        res = {\"Image\": image_name, \"Threshold\": t, \"F1\": f1, \"Jaccard\": jaccard, \"TP\": tp, \"FP\": fp, \"FN\": fn}\n",
    "        row = len(results)\n",
    "        results.loc[row] = res\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Count number of False Negatives at 0.7 IoU\n",
    "\n",
    "def get_false_negatives(ground_truth, prediction, results, image_name, threshold=0.7):\n",
    "\n",
    "    # Compute IoU\n",
    "    IOU = intersection_over_union(ground_truth, prediction)\n",
    "    \n",
    "    true_objects = len(np.unique(ground_truth))\n",
    "    if true_objects <= 1:\n",
    "        return results\n",
    "        \n",
    "    area_true = np.histogram(ground_truth, bins=true_objects)[0][1:]\n",
    "    true_objects -= 1\n",
    "    \n",
    "    # Identify False Negatives\n",
    "    matches = IOU > threshold\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Missed objects\n",
    "\n",
    "    data = np.asarray([ \n",
    "        area_true.copy(), \n",
    "        np.array(false_negatives, dtype=np.int32)\n",
    "    ])\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame(data=data.T, columns=[\"Area\", \"False_Negative\"])])\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Count the number of splits and merges\n",
    "\n",
    "def get_splits_and_merges(ground_truth, prediction, results, image_name):\n",
    "\n",
    "    # Compute IoU\n",
    "    IOU = intersection_over_union(ground_truth, prediction)\n",
    "    \n",
    "    matches = IOU > 0.1\n",
    "    merges = np.sum(matches, axis=0) > 1\n",
    "    splits = np.sum(matches, axis=1) > 1\n",
    "    r = {\"Image_Name\":image_name, \"Merges\":np.sum(merges), \"Splits\":np.sum(splits)}\n",
    "    results.loc[len(results)+1] = r\n",
    "    return results\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment.py\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "import tensorflow as tf\n",
    "    \n",
    "import keras.backend\n",
    "import keras.callbacks\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.optimizers\n",
    "    \n",
    "import utils.model_builder\n",
    "import utils.data_provider\n",
    "import utils.metrics\n",
    "import utils.objectives\n",
    "import utils.dirtools\n",
    "import utils.evaluation\n",
    "    \n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "\n",
    "\n",
    "def run(config_vars, data_partitions, experiment_name, partition, GPU=\"2\"):\n",
    "\n",
    "    # Device configuration\n",
    "    configuration = tf.ConfigProto()\n",
    "    configuration.gpu_options.allow_growth = True\n",
    "    configuration.gpu_options.visible_device_list = GPU\n",
    "    session = tf.Session(config = configuration)\n",
    "    \n",
    "    # apply session\n",
    "    keras.backend.set_session(session)\n",
    "\n",
    "    # # Step 02\n",
    "    # # Training a U-Net model    \n",
    "    \n",
    "    train_gen = utils.data_provider.random_sample_generator(\n",
    "        config_vars[\"normalized_images_dir\"],\n",
    "        config_vars[\"boundary_labels_dir\"],\n",
    "        data_partitions[\"training\"],\n",
    "        config_vars[\"batch_size\"],\n",
    "        config_vars[\"pixel_depth\"],\n",
    "        config_vars[\"crop_size\"],\n",
    "        config_vars[\"crop_size\"],\n",
    "        config_vars[\"rescale_labels\"]\n",
    "    )\n",
    "    \n",
    "    val_gen = utils.data_provider.single_data_from_images(\n",
    "         config_vars[\"normalized_images_dir\"],\n",
    "         config_vars[\"boundary_labels_dir\"],\n",
    "         data_partitions[\"validation\"],\n",
    "         config_vars[\"val_batch_size\"],\n",
    "         config_vars[\"pixel_depth\"],\n",
    "         config_vars[\"crop_size\"],\n",
    "         config_vars[\"crop_size\"],\n",
    "         config_vars[\"rescale_labels\"]\n",
    "    )\n",
    "    \n",
    "    model = utils.model_builder.get_model_3_class(config_vars[\"crop_size\"], config_vars[\"crop_size\"], activation=None)\n",
    "    \n",
    "    loss = utils.objectives.weighted_crossentropy\n",
    "    \n",
    "    metrics = [keras.metrics.categorical_accuracy, \n",
    "               utils.metrics.channel_recall(channel=0, name=\"background_recall\"), \n",
    "               utils.metrics.channel_precision(channel=0, name=\"background_precision\"),\n",
    "               utils.metrics.channel_recall(channel=1, name=\"interior_recall\"), \n",
    "               utils.metrics.channel_precision(channel=1, name=\"interior_precision\"),\n",
    "               utils.metrics.channel_recall(channel=2, name=\"boundary_recall\"), \n",
    "               utils.metrics.channel_precision(channel=2, name=\"boundary_precision\"),\n",
    "              ]\n",
    "    \n",
    "    optimizer = keras.optimizers.RMSprop(lr=config_vars[\"learning_rate\"])\n",
    "    \n",
    "    model.compile(loss=loss, metrics=metrics, optimizer=optimizer)\n",
    "    \n",
    "    callback_csv = keras.callbacks.CSVLogger(filename=config_vars[\"csv_log_file\"])\n",
    "    \n",
    "    callbacks=[callback_csv]\n",
    "    \n",
    "    # TRAIN\n",
    "    statistics = model.fit_generator(\n",
    "        generator=train_gen,\n",
    "        steps_per_epoch=config_vars[\"steps_per_epoch\"],\n",
    "        epochs=config_vars[\"epochs\"],\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=int(len(data_partitions[\"validation\"])/config_vars[\"val_batch_size\"]),\n",
    "        callbacks=callbacks,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    model.save_weights(config_vars[\"model_file\"])\n",
    "    \n",
    "    print('Training Done! :)')\n",
    "    \n",
    "    \n",
    "    # # Step 03\n",
    "    # # Predict segmentations\n",
    "        \n",
    "    image_names = [f for f in data_partitions[partition] if f.startswith(\"IXM\")]\n",
    "    image_names = [os.path.join(config_vars[\"normalized_images_dir\"], f) for f in image_names]#data_partitions[partition]]\n",
    "    \n",
    "    imagebuffer = skimage.io.imread_collection(image_names)\n",
    "    \n",
    "    images = imagebuffer.concatenate()\n",
    "    \n",
    "    dim1 = images.shape[1]\n",
    "    dim2 = images.shape[2]\n",
    "    \n",
    "    images = images.reshape((-1, dim1, dim2, 1))\n",
    "    \n",
    "    images = images / 255\n",
    "    \n",
    "    model = utils.model_builder.get_model_3_class(dim1, dim2)\n",
    "    model.load_weights(config_vars[\"model_file\"])\n",
    "    \n",
    "    predictions = model.predict(images, batch_size=1)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "    \n",
    "        filename = imagebuffer.files[i]\n",
    "        filename = os.path.basename(filename)\n",
    "        \n",
    "        probmap = predictions[i].squeeze()\n",
    "        \n",
    "        skimage.io.imsave(config_vars[\"probmap_out_dir\"] + filename, probmap)\n",
    "        \n",
    "        pred = utils.metrics.probmap_to_pred(probmap, config_vars[\"boundary_boost_factor\"])\n",
    "    \n",
    "        label = utils.metrics.pred_to_label(pred, config_vars[\"cell_min_size\"])\n",
    "        \n",
    "        skimage.io.imsave(config_vars[\"labels_out_dir\"] + filename, label)\n",
    "    \n",
    "    \n",
    "    # # Step 04\n",
    "    # # Evaluation of performance\n",
    "    \n",
    "    all_images = data_partitions[partition]\n",
    "    #all_images = [f for f in data_partitions[partition] if f.startswith(\"IXM\")]\n",
    "    \n",
    "    \n",
    "    results = pd.DataFrame(columns=[\"Image\", \"Threshold\", \"Precision\"])\n",
    "    false_negatives = pd.DataFrame(columns=[\"False_Negative\", \"Area\"])\n",
    "    splits_merges = pd.DataFrame(columns=[\"Image_Name\", \"Merges\",\"Splits\"])\n",
    "    \n",
    "    for image_name in all_images:\n",
    "        img_filename = os.path.join(config_vars[\"raw_annotations_dir\"], image_name)\n",
    "        ground_truth = skimage.io.imread(img_filename)\n",
    "        if len(ground_truth.shape) == 3:\n",
    "            ground_truth = ground_truth[:,:,0]\n",
    "        \n",
    "        ground_truth = skimage.morphology.label(ground_truth)\n",
    "        \n",
    "        pred_filename = os.path.join(config_vars[\"labels_out_dir\"], image_name)\n",
    "        prediction = skimage.io.imread(pred_filename) #.replace(\".png\",\".tiff\"))\n",
    "        \n",
    "        if config_vars[\"object_dilation\"] > 0:\n",
    "            struct = skimage.morphology.square(config_vars[\"object_dilation\"])\n",
    "            prediction = skimage.morphology.dilation(prediction, struct)\n",
    "        elif config_vars[\"object_dilation\"] < 0:\n",
    "            struct = skimage.morphology.square(-config_vars[\"object_dilation\"])\n",
    "            prediction = skimage.morphology.erosion(prediction, struct)\n",
    "            \n",
    "        ground_truth = skimage.segmentation.relabel_sequential(ground_truth[30:-30,30:-30])[0] # )[0] #\n",
    "        prediction = skimage.segmentation.relabel_sequential(prediction[30:-30,30:-30])[0] # )[0] #\n",
    "        \n",
    "        results = utils.evaluation.compute_ap_results(\n",
    "            ground_truth, \n",
    "            prediction, \n",
    "            results, \n",
    "            image_name\n",
    "        )\n",
    "        \n",
    "        false_negatives = utils.evaluation.get_false_negatives(\n",
    "            ground_truth, \n",
    "            prediction, \n",
    "            false_negatives, \n",
    "            image_name\n",
    "        )\n",
    "        \n",
    "        splits_merges = utils.evaluation.get_splits_and_merges(\n",
    "            ground_truth, \n",
    "            prediction, \n",
    "            splits_merges, \n",
    "            image_name\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # # Report of results\n",
    "    \n",
    "    output = {}\n",
    "\n",
    "    average_precision = results.groupby(\"Threshold\").mean().reset_index()\n",
    "    mean_average_precision = average_precision[\"Precision\"].mean()\n",
    "    output[\"MAP\"] = mean_average_precision\n",
    "    \n",
    "    false_negatives = false_negatives[false_negatives[\"False_Negative\"] == 1]\n",
    "    \n",
    "    missed = false_negatives.groupby(\n",
    "        pd.cut(\n",
    "            false_negatives[\"Area\"], \n",
    "            [0,250,625,900,10000], # Area intervals\n",
    "            labels=[\"Tiny nuclei\",\"Small nuclei\",\"Normal nuclei\",\"Large nuclei\"],\n",
    "        )\n",
    "    )[\"False_Negative\"].sum()\n",
    "    \n",
    "    output[\"Missed\"] = missed\n",
    "    output[\"Splits\"] = np.sum(splits_merges[\"Splits\"])\n",
    "    output[\"Merges\"] = np.sum(splits_merges[\"Merges\"])\n",
    "\n",
    "    return output\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics.py\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import skimage.segmentation\n",
    "import skimage.io\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "debug = False\n",
    "\n",
    "def channel_precision(channel, name):\n",
    "    def precision_func(y_true, y_pred):\n",
    "        y_pred_tmp = K.cast(tf.equal( K.argmax(y_pred, axis=-1), channel), \"float32\")\n",
    "        true_positives = K.sum(K.round(K.clip(y_true[:,:,:,channel] * y_pred_tmp, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred_tmp, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "        return precision\n",
    "    precision_func.__name__ = name\n",
    "    return precision_func\n",
    "\n",
    "\n",
    "def channel_recall(channel, name):\n",
    "    def recall_func(y_true, y_pred):\n",
    "        y_pred_tmp = K.cast(tf.equal( K.argmax(y_pred, axis=-1), channel), \"float32\")\n",
    "        true_positives = K.sum(K.round(K.clip(y_true[:,:,:,channel] * y_pred_tmp, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true[:,:,:,channel], 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "        return recall\n",
    "    recall_func.__name__ = name\n",
    "    return recall_func\n",
    "\n",
    "\n",
    "## PROBMAP TO CONTOURS TO LABEL\n",
    "\n",
    "def probmap_to_contour(probmap, threshold = 0.5):\n",
    "    # assume 2D input\n",
    "    outline = probmap >= threshold\n",
    "    \n",
    "    return outline\n",
    "\n",
    "def contour_to_label(outline, image):\n",
    "    # see notebook contours_to_labels for why we do what we do here\n",
    "    \n",
    "    # get connected components\n",
    "    labels = skimage.morphology.label(outline, background=1)\n",
    "    skimage.morphology.remove_small_objects(labels, min_size = 100, in_place = True)\n",
    "    \n",
    "    n_ccs = np.max(labels)\n",
    "\n",
    "    # buffer label image\n",
    "    filtered_labels = np.zeros_like(labels, dtype=np.uint16)\n",
    "\n",
    "    # relabel as we don't know what connected component the background has been given before\n",
    "    label_index = 1\n",
    "    \n",
    "    # start at 1 (0 is contours), end at number of connected components\n",
    "    for i in range(1, n_ccs + 1):\n",
    "\n",
    "        # get mask of connected compoenents\n",
    "        mask = labels == i\n",
    "\n",
    "        # get mean\n",
    "        mean = np.mean(np.take(image.flatten(),np.nonzero(mask.flatten())))\n",
    "\n",
    "        if(mean > 50/255):\n",
    "            filtered_labels[mask] = label_index\n",
    "            label_index = label_index + 1\n",
    "            \n",
    "    return filtered_labels\n",
    "\n",
    "\n",
    "## PROBMAP TO PRED TO LABEL\n",
    "\n",
    "def probmap_to_pred(probmap, boundary_boost_factor):\n",
    "    # we need to boost the boundary class to make it more visible\n",
    "    # this shrinks the cells a little bit but avoids undersegmentation\n",
    "    pred = np.argmax(probmap * [1, 1, boundary_boost_factor], -1)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def pred_to_label(pred, cell_min_size, cell_label=1):\n",
    "    # Only marks interior of cells (cell_label = 1 is interior, cell_label = 2 is boundary)\n",
    "    cell=(pred == cell_label)\n",
    "    # fix cells\n",
    "    cell = skimage.morphology.remove_small_holes(cell, area_threshold=cell_min_size)\n",
    "    cell = skimage.morphology.remove_small_objects(cell, min_size=cell_min_size)\n",
    "    \n",
    "    # label cells only\n",
    "    [label, num] = skimage.morphology.label(cell, return_num=True)\n",
    "    return label\n",
    "\n",
    "\n",
    "def compare_two_labels(label_model, label_gt, return_IoU_matrix):\n",
    "    \n",
    "    # get number of detected nuclei\n",
    "    nb_nuclei_gt = np.max(label_gt)\n",
    "    nb_nuclei_model = np.max(label_model)\n",
    "    \n",
    "    # catch the case of an empty picture in model and gt\n",
    "    if nb_nuclei_gt == 0 and nb_nuclei_model == 0:\n",
    "        if(return_IoU_matrix):\n",
    "            return [0, 0, 1, np.empty(0)]     \n",
    "        else:\n",
    "            return [0, 0, 1]\n",
    "    \n",
    "    # catch the case of empty picture in model\n",
    "    if nb_nuclei_model == 0:\n",
    "        if(return_IoU_matrix):\n",
    "            return [0, nb_nuclei_gt, 0, np.empty(0)]     \n",
    "        else:\n",
    "            return [0, nb_nuclei_gt, 0]\n",
    "    \n",
    "    # catch the case of empty picture in gt\n",
    "    if nb_nuclei_gt == 0:\n",
    "        if(return_IoU_matrix):\n",
    "            return [nb_nuclei_model, 0, 0, np.empty(0)]     \n",
    "        else:\n",
    "            return [nb_nuclei_model, 0, 0]\n",
    "    \n",
    "    # build IoU matrix\n",
    "    IoUs = np.full((nb_nuclei_gt, nb_nuclei_model), -1, dtype = np.float32)\n",
    "\n",
    "    # calculate IoU for each nucleus index_gt in GT and nucleus index_pred in prediction    \n",
    "    # TODO improve runtime of this algorithm\n",
    "    for index_gt in range(1,nb_nuclei_gt+1):\n",
    "\n",
    "        nucleus_gt = label_gt == index_gt\n",
    "        number_gt = np.sum(nucleus_gt)\n",
    "\n",
    "        for index_model in range(1,nb_nuclei_model+1):\n",
    "            \n",
    "            if debug:\n",
    "                print(index_gt, \"/\", index_model)\n",
    "            \n",
    "            nucleus_model = label_model == index_model \n",
    "            number_model = np.sum(nucleus_model)\n",
    "            \n",
    "            same_and_1 = np.sum((nucleus_gt == nucleus_model) * nucleus_gt)\n",
    "            \n",
    "            IoUs[index_gt-1,index_model-1] = same_and_1 / (number_gt + number_model - same_and_1)\n",
    "    \n",
    "    # get matches and errors\n",
    "    detection_map = (IoUs > 0.5)\n",
    "    nb_matches = np.sum(detection_map)\n",
    "\n",
    "    detection_rate = IoUs * detection_map\n",
    "    \n",
    "    nb_overdetection = nb_nuclei_model - nb_matches\n",
    "    nb_underdetection = nb_nuclei_gt - nb_matches\n",
    "    \n",
    "    mean_IoU = np.mean(np.sum(detection_rate, axis = 1))\n",
    "    \n",
    "    if(return_IoU_matrix):\n",
    "        result = [nb_overdetection, nb_underdetection, mean_IoU, IoUs]\n",
    "    else:\n",
    "        result = [nb_overdetection, nb_underdetection, mean_IoU]\n",
    "    return result\n",
    "\n",
    "def splits_and_merges_3_class(y_model_pred, y_gt_pred):\n",
    "    \n",
    "    # get segmentations\n",
    "    label_gt = pred_to_label(y_gt_pred, cell_min_size=2)\n",
    "    label_model = pred_to_label(y_model_pred, cell_min_size=2)\n",
    "    \n",
    "    # compare labels\n",
    "    result = compare_two_labels(label_model, label_gt, False)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def splits_and_merges_boundary(y_model_outline, y_gt_outline, image):\n",
    "    \n",
    "    # get segmentations\n",
    "    label_gt = contour_to_label(y_gt_outline, image)\n",
    "    label_model = contour_to_label(y_model_outline, image)\n",
    "    \n",
    "    # compare labels\n",
    "    result = compare_two_labels(label_model, label_gt, False)\n",
    "        \n",
    "    return result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_builder.py\n",
    "\n",
    "```python\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import tensorflow as tf\n",
    "\n",
    "CONST_DO_RATE = 0.5\n",
    "\n",
    "option_dict_conv = {\"activation\": \"relu\", \"border_mode\": \"same\"}\n",
    "option_dict_bn = {\"mode\": 0, \"momentum\" : 0.9}\n",
    "\n",
    "\n",
    "# returns a core model from gray input to 64 channels of the same size\n",
    "def get_core(dim1, dim2):\n",
    "    \n",
    "    x = keras.layers.Input(shape=(dim1, dim2, 1))\n",
    "\n",
    "    a = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(x)  \n",
    "    a = keras.layers.BatchNormalization(**option_dict_bn)(a)\n",
    "\n",
    "    a = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(a)\n",
    "    a = keras.layers.BatchNormalization(**option_dict_bn)(a)\n",
    "\n",
    "    \n",
    "    y = keras.layers.MaxPooling2D()(a)\n",
    "\n",
    "    b = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(y)\n",
    "    b = keras.layers.BatchNormalization(**option_dict_bn)(b)\n",
    "\n",
    "    b = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(b)\n",
    "    b = keras.layers.BatchNormalization(**option_dict_bn)(b)\n",
    "\n",
    "    \n",
    "    y = keras.layers.MaxPooling2D()(b)\n",
    "\n",
    "    c = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(y)\n",
    "    c = keras.layers.BatchNormalization(**option_dict_bn)(c)\n",
    "\n",
    "    c = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(c)\n",
    "    c = keras.layers.BatchNormalization(**option_dict_bn)(c)\n",
    "\n",
    "    \n",
    "    y = keras.layers.MaxPooling2D()(c)\n",
    "\n",
    "    d = keras.layers.Convolution2D(512, 3, 3, **option_dict_conv)(y)\n",
    "    d = keras.layers.BatchNormalization(**option_dict_bn)(d)\n",
    "\n",
    "    d = keras.layers.Convolution2D(512, 3, 3, **option_dict_conv)(d)\n",
    "    d = keras.layers.BatchNormalization(**option_dict_bn)(d)\n",
    "\n",
    "    \n",
    "    # UP\n",
    "\n",
    "    d = keras.layers.UpSampling2D()(d)\n",
    "\n",
    "    y = keras.layers.merge.concatenate([d, c], axis=3)\n",
    "\n",
    "    e = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(y)\n",
    "    e = keras.layers.BatchNormalization(**option_dict_bn)(e)\n",
    "\n",
    "    e = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(e)\n",
    "    e = keras.layers.BatchNormalization(**option_dict_bn)(e)\n",
    "\n",
    "    e = keras.layers.UpSampling2D()(e)\n",
    "\n",
    "    \n",
    "    y = keras.layers.merge.concatenate([e, b], axis=3)\n",
    "\n",
    "    f = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(y)\n",
    "    f = keras.layers.BatchNormalization(**option_dict_bn)(f)\n",
    "\n",
    "    f = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(f)\n",
    "    f = keras.layers.BatchNormalization(**option_dict_bn)(f)\n",
    "\n",
    "    f = keras.layers.UpSampling2D()(f)\n",
    "\n",
    "    \n",
    "    y = keras.layers.merge.concatenate([f, a], axis=3)\n",
    "\n",
    "    y = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(y)\n",
    "    y = keras.layers.BatchNormalization(**option_dict_bn)(y)\n",
    "\n",
    "    y = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(y)\n",
    "    y = keras.layers.BatchNormalization(**option_dict_bn)(y)\n",
    "\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "def get_model_3_class(dim1, dim2, activation=\"softmax\"):\n",
    "    \n",
    "    [x, y] = get_core(dim1, dim2)\n",
    "\n",
    "    y = keras.layers.Convolution2D(3, 1, 1, **option_dict_conv)(y)\n",
    "\n",
    "    if activation is not None:\n",
    "        y = keras.layers.Activation(activation)(y)\n",
    "\n",
    "    model = keras.models.Model(x, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## objectives.py\n",
    "\n",
    "```python\n",
    "import keras.metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def weighted_crossentropy(y_true, y_pred):\n",
    "\n",
    "    class_weights = tf.constant([[[[1., 1., 10.]]]])\n",
    "\n",
    "    unweighted_losses = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "\n",
    "    weights = tf.reduce_sum(class_weights * y_true, axis=-1)\n",
    "\n",
    "    weighted_losses = weights * unweighted_losses\n",
    "\n",
    "    loss = tf.reduce_mean(weighted_losses)\n",
    "\n",
    "    return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
