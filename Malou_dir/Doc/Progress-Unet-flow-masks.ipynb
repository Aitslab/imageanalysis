{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using energy flow masks in the Unet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellpose is a software to segment object with irregular shapes, such as cells, but is also general and work for any image with similar objects such as rocks or shells https://www.biorxiv.org/content/10.1101/2020.02.02.931238v1.full.pdf.\n",
    "\n",
    "To create this software they have used a Unet model architechture. As labels they have converted regular mask images with one pixel value per object to energy flow maps. Creating a heat diffusion simulation starting at the center of the cell expanding to the edges. \n",
    "\n",
    "My idea is to use the Unet we have, and try to implement the labels used in the cellpose model so that we would get a model specialized on our dataset. I think that the main thing we need to change for it to work is the loss function, and then do some tweaks in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The model I am using now is the Unet originally created by Broad Institute (BBBC) for nuclei segmentation https://www.biorxiv.org/content/10.1101/335216v2.full.pdf\n",
    "\n",
    "The architecture of the model can be found here https://github.com/Aitslab/imageanalysis/blob/master/Malou_dir/README_Folder/Nuclei_Segmentation_Project/2_Final_Models/1_Model1/Unet/utils/model_builder.py\n",
    "\n",
    "The labels for this model are 3 class labels; background(red), boundary(blue) and interior(green).\n",
    "\n",
    "\n",
    "images show:\n",
    "**Cell channel**\n",
    "1. Normalized input image\n",
    "2. Raw annotation \n",
    "3. 3 class boundary label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Cell images</center>\n",
    "\n",
    "<center>Normalized input image</center> | <center>Raw annotation </center>|<center> 3 class boundary label</center>\n",
    "- | - | - \n",
    "<img src=\"images_jupyter/norm_images/MFGTMPcx7_170702000001_B14f07d1.png\">| <img src=\"images_jupyter/raw_annotation/MFGTMPcx7_170702000001_B14f07d1.png\">| <img src=\"images_jupyter/boundary_labels/MFGTMPcx7_170702000001_B14f07d1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images show:\n",
    "**Nuclei channel**\n",
    "1. Normalized input image\n",
    "2. Raw annotation \n",
    "3. 3 class boundary label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Nuclei images</center>\n",
    "\n",
    "<center>Normalized input image</center> | <center>Raw annotation </center>|<center> 3 class boundary label</center>\n",
    "- | - | - \n",
    "<img src=\"images_jupyter/norm_images/MFGTMPcx7_170702000001_B14f07d0.png\">| <img src=\"images_jupyter/raw_annotation/MFGTMPcx7_170702000001_B14f07d0.png\">| <img src=\"images_jupyter/boundary_labels/MFGTMPcx7_170702000001_B14f07d0.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function for BBBC unet\n",
    "\n",
    "The current loss function looks like this, with softmax crossentropy loss function, and added penalty for the boundary class\n",
    "\n",
    "```python\n",
    "def weighted_crossentropy(y_true, y_pred):\n",
    "\n",
    "    class_weights = tf.constant([[[[1., 1., 10.]]]])\n",
    "\n",
    "    unweighted_losses = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "\n",
    "    weights = tf.reduce_sum(class_weights * y_true, axis=-1)\n",
    "\n",
    "    weighted_losses = weights * unweighted_losses\n",
    "\n",
    "    loss = tf.reduce_mean(weighted_losses)\n",
    "\n",
    "    return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellpose approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating of energy flow labels\n",
    "\n",
    "To create the energy flow masks, I have selected code from cellpose github page and converted the current masks (script provided at the end of this notebook, starting with the cellpose code, and my additional code to create my masks). \n",
    "\n",
    "I interpret it as this is the final masks to input to the model. the function ```flows_to_labels``` will take a list of images and create masks using the ```masks_to_flows```function. I manage to create the masks, looking as follows. What I am unsure about is if they are created correctly. Looking in the function  ```flows_to_labels``` on the following line; \n",
    "```python\n",
    "veci = [masks_to_flows(labels[n][0])[0] for n in trange(nimg)]\n",
    "```\n",
    "this line will create a list of the flows, the indexing here will only take the first dimension value (1104 in the case of our images) of the images as input to the ```masks_to_flows``` function, which I am unsure about being correct. Although, it works and creates the following images (the merged image being the one I will use in the model):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images show:\n",
    "1. Xflow image\n",
    "2. Yflow image \n",
    "3. Cell probability label\n",
    "4. Merged image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Flow images</center>\n",
    "\n",
    "<center>X flow image</center> | <center>Y flow image </center>|<center> Cell probability image</center>|<center> Merged image </center>\n",
    "- | - | - | -\n",
    "<img src=\"images_jupyter/flows/Xflow/MFGTMPcx7_170702000001_B14f07d1.png\">| <img src=\"images_jupyter/flows/Yflow/MFGTMPcx7_170702000001_B14f07d1.png\">| <img src=\"images_jupyter/flows/Cellprob/MFGTMPcx7_170702000001_B14f07d1.png\">| <img src=\"images_jupyter/flows/MFGTMPcx7_170702000001_B14f07d1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image from Cellpose: a generalist algorithm for cellular segmentation paper describing the flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_jupyter/cellpose-img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellpose model\n",
    "\n",
    "\n",
    "The Cellpose model is created with the python package mxnet, which is all new to me. I have looked at their code in their github page, and interpret the loss function. \n",
    "\n",
    "On their github I found two loss functions, they seem to combine several model architectures that I don't know how it works. \n",
    "\n",
    "The loss function I tried to convert looks like this: \n",
    "\n",
    "```python \n",
    "    def loss_fn(self, lbl, y):\n",
    "        \"\"\" loss function between true labels lbl and prediction y \"\"\"\n",
    "        criterion  = gluon.loss.L2Loss()\n",
    "        criterion2 = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "        veci = 5. * nd.array(lbl[:,1:], ctx=self.device)\n",
    "        lbl  = nd.array(lbl[:,0]>.5, ctx=self.device)\n",
    "        loss = criterion(y[:,:-1] , veci) + criterion2(y[:,-1] , lbl)\n",
    "        return loss\n",
    "```\n",
    "\n",
    "found at https://github.com/MouseLand/cellpose/blob/4ac3858b48a5d049d81f412055d6d2c2dab4393c/cellpose/models.py#L1257\n",
    "\n",
    "\n",
    "I interpret it as this:\n",
    "\n",
    "the variable veci will consist of the first two channels of the image (Xflow and Yflow) multiplied by 5 (I don't know why)\n",
    "\n",
    "and lbl will consist of the third channel of the image (cellprobability channel), which I think is an image with probability values for the pixel belonging to a cell or not. If the probability is higher than 0.5, it will be considered a pixel belonging to a cell (True).\n",
    "\n",
    "Then two separate loss functions are applied, L2Loss for veci (Xflow and Yflow channel), and SigmoidBinaryCrossEntropyLoss for the cellprobability channel. \n",
    "\n",
    "\n",
    "I tried to convert this to work on our model, and using Keras. I did like this:\n",
    "\n",
    "\n",
    "```python \n",
    "def loss_fn(y, y_pred):\n",
    "    \n",
    "    criterion1 = tf.keras.losses.MeanSquaredError()\n",
    "    criterion2 = tf.keras.losses.BinaryCrossentropy()\n",
    "    lab_ch = y_pred[:,:,2]\n",
    "    flow_ch = y_pred[:,:,0:2]\n",
    "    loss = criterion1(y[:,:,0:2], flow_ch) + criterion2(y[:,:,2], lab_ch)\n",
    "    \n",
    "    return loss\n",
    "```\n",
    "\n",
    "I wanted to set ```lab_ch = y_pred[:,:,2]>0.5``` but it was then converted to a bool object which caused error, and I am lost in how I would implement the threshold to this function. I got a model to run with this settings, but the predictions did not give any good results. They looked like this:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images show:\n",
    "1. Predicted image\n",
    "2. Image it was predicted from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Prediction cell-model 17</center>\n",
    "\n",
    "<center>Predicted image </center> | <center>Image it was predicted from</center>\n",
    "- | - \n",
    "<img src=\"images_jupyter/prob_maps/MFGTMPcx7_170702090001_B22f15d1.png\">| <img src=\"images_jupyter/norm_images/MFGTMPcx7_170702090001_B22f15d1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not done any other tweaks with the model, I thought that if I manage to implement a loss function which seem to work, I would continue to tweak the model and doing other changes.\n",
    "\n",
    "The cellpose model is described under methods in their article. Perhaps the Unet also needs to be changed to get reasonable results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating-flow-masks.py\n",
    "\n",
    "```python\n",
    "\n",
    "##################################### Cellpose script to create masks #############################################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.io\n",
    "import os\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "from skimage.color import rgb2lab\n",
    "from skimage import img_as_ubyte\n",
    "import skimage.morphology\n",
    "from tqdm import trange\n",
    "\n",
    "#utils\n",
    "def diameters(masks):\n",
    "    \"\"\" get median 'diameter' of masks \"\"\"\n",
    "    _, counts = np.unique(np.int32(masks), return_counts=True)\n",
    "    counts = counts[1:]\n",
    "    md = np.median(counts**0.5)\n",
    "    if np.isnan(md):\n",
    "        md = 0\n",
    "    md /= (np.pi**0.5)/2\n",
    "    return md, counts**0.5\n",
    "\n",
    "def _extend_centers(T,y,x,ymed,xmed,Lx, niter):\n",
    "    \"\"\" run diffusion from center of mask (ymed, xmed) on mask pixels (y, x)\n",
    "    Parameters\n",
    "    --------------\n",
    "    T: float64, array\n",
    "        _ x Lx array that diffusion is run in\n",
    "    y: int32, array\n",
    "        pixels in y inside mask\n",
    "    x: int32, array\n",
    "        pixels in x inside mask\n",
    "    ymed: int32\n",
    "        center of mask in y\n",
    "    xmed: int32\n",
    "        center of mask in x\n",
    "    Lx: int32\n",
    "        size of x-dimension of masks\n",
    "    niter: int32\n",
    "        number of iterations to run diffusion\n",
    "    Returns\n",
    "    ---------------\n",
    "    T: float64, array\n",
    "        amount of diffused particles at each pixel\n",
    "    \"\"\"\n",
    "\n",
    "    for t in range(niter):\n",
    "        T[ymed*Lx + xmed] += 1\n",
    "        T[y*Lx + x] = 1/9. * (T[y*Lx + x] + T[(y-1)*Lx + x]   + T[(y+1)*Lx + x] +\n",
    "                                            T[y*Lx + x-1]     + T[y*Lx + x+1] +\n",
    "                                            T[(y-1)*Lx + x-1] + T[(y-1)*Lx + x+1] +\n",
    "                                            T[(y+1)*Lx + x-1] + T[(y+1)*Lx + x+1])\n",
    "    return T\n",
    "\n",
    "\n",
    "\n",
    "def masks_to_flows(masks):\n",
    "    \"\"\" convert masks to flows using diffusion from center pixel\n",
    "    Center of masks where diffusion starts is defined to be the \n",
    "    closest pixel to the median of all pixels that is inside the \n",
    "    mask. Result of diffusion is converted into flows by computing\n",
    "    the gradients of the diffusion density map. \n",
    "    Parameters\n",
    "    -------------\n",
    "    masks: int, 2D or 3D array\n",
    "        labelled masks 0=NO masks; 1,2,...=mask labels\n",
    "    Returns\n",
    "    -------------\n",
    "    mu: float, 3D or 4D array \n",
    "        flows in Y = mu[-2], flows in X = mu[-1].\n",
    "        if masks are 3D, flows in Z = mu[0].\n",
    "    mu_c: float, 2D or 3D array\n",
    "        for each pixel, the distance to the center of the mask \n",
    "        in which it resides \n",
    "    \"\"\"\n",
    "    #if len(masks.shape) >2:\n",
    "    #    masks = rgb2lab(masks)\n",
    "    #    masks = masks[:,:,0]\n",
    "    #masks = skimage.morphology.label(masks)\n",
    "    #print(masks.shape)\n",
    "    if masks.ndim > 2:\n",
    "        Lz, Ly, Lx = masks.shape\n",
    "        mu = np.zeros((3, Lz, Ly, Lx), np.float32)\n",
    "        for z in range(Lz):\n",
    "            mu0 = masks_to_flows(masks[z])[0]\n",
    "            mu[[1,2], z] += mu0\n",
    "        for y in range(Ly):\n",
    "            mu0 = masks_to_flows(masks[:,y])[0]\n",
    "            mu[[0,2], :, y] += mu0\n",
    "        for x in range(Lx):\n",
    "            mu0 = masks_to_flows(masks[:,:,x])[0]\n",
    "            mu[[0,1], :, :, x] += mu0\n",
    "        return mu, None\n",
    "\n",
    "    Ly, Lx = masks.shape\n",
    "    mu = np.zeros((2, Ly, Lx), np.float64)\n",
    "    mu_c = np.zeros((Ly, Lx), np.float64)\n",
    "    \n",
    "    nmask = masks.max()\n",
    "    slices = scipy.ndimage.find_objects(masks)\n",
    "    dia = diameters(masks)[0]\n",
    "    s2 = (.15 * dia)**2\n",
    "    for i,si in enumerate(slices):\n",
    "        if si is not None:\n",
    "            sr,sc = si\n",
    "            ly, lx = sr.stop - sr.start + 1, sc.stop - sc.start + 1\n",
    "            y,x = np.nonzero(masks[sr, sc] == (i+1))\n",
    "            y = y.astype(np.int32) + 1\n",
    "            x = x.astype(np.int32) + 1\n",
    "            ymed = np.median(y)\n",
    "            xmed = np.median(x)\n",
    "            imin = np.argmin((x-xmed)**2 + (y-ymed)**2)\n",
    "            xmed = x[imin]\n",
    "            ymed = y[imin]\n",
    "\n",
    "            d2 = (x-xmed)**2 + (y-ymed)**2\n",
    "            mu_c[sr.start+y-1, sc.start+x-1] = np.exp(-d2/s2)\n",
    "\n",
    "            niter = 2*np.int32(np.ptp(x) + np.ptp(y))\n",
    "            T = np.zeros((ly+2)*(lx+2), np.float64)\n",
    "            T = _extend_centers(T, y, x, ymed, xmed, np.int32(lx), niter)\n",
    "            T[(y+1)*lx + x+1] = np.log(1.+T[(y+1)*lx + x+1])\n",
    "\n",
    "            dy = T[(y+1)*lx + x] - T[(y-1)*lx + x]\n",
    "            dx = T[y*lx + x+1] - T[y*lx + x-1]\n",
    "            mu[:, sr.start+y-1, sc.start+x-1] = np.stack((dy,dx))\n",
    "\n",
    "    mu /= (1e-20 + (mu**2).sum(axis=0)**0.5)\n",
    "\n",
    "    return mu, mu_c\n",
    "\n",
    "\n",
    "def labels_to_flows(labels, files=None):\n",
    "    \"\"\" convert labels (list of masks or flows) to flows for training model \n",
    "    if files is not None, flows are saved to files to be reused\n",
    "    Parameters\n",
    "    --------------\n",
    "    labels: list of ND-arrays\n",
    "        labels[k] can be 2D or 3D, if [3 x Ly x Lx] then it is assumed that flows were precomputed.\n",
    "        Otherwise labels[k][0] or labels[k] (if 2D) is used to create flows and cell probabilities.\n",
    "    Returns\n",
    "    --------------\n",
    "    flows: list of [4 x Ly x Lx] arrays\n",
    "        flows[k][0] is labels[k], flows[k][1] is cell probability, flows[k][2] is Y flow, and flows[k][3] is X flow\n",
    "    \"\"\"\n",
    "    \n",
    "    nimg = len(labels)\n",
    "    if labels[0].ndim < 3:\n",
    "        labels = [labels[n][np.newaxis,:,:] for n in range(nimg)]\n",
    "\n",
    "    if labels[0].shape[0] == 1 or labels[0].ndim < 3:\n",
    "        print('NOTE: computing flows for labels (could be done before to save time)')\n",
    "        # compute flows        \n",
    "        veci = []\n",
    "            \n",
    "        veci = [masks_to_flows(labels[n][0])[0] for n in trange(nimg)]\n",
    "        #concatenate flows with cell probability\n",
    "        flows = [np.concatenate((labels[n][[0]], labels[n][[0]]>0.5, veci[n], labels[n]), axis=0).astype(np.float32)\n",
    "                    for n in range(nimg)]\n",
    "        if files is not None:\n",
    "            for flow, file in zip(flows, files):\n",
    "                file_name = os.path.splitext(file)[0]\n",
    "                tifffile.imsave(file_name+'_flows.tif', flow)\n",
    "    else:\n",
    "        print('flows precomputed')\n",
    "        flows = [labels[n].astype(np.float32) for n in range(nimg)]\n",
    "    return flows\n",
    "\n",
    "\n",
    "################################################ Addition by Malou ##############################################\n",
    "\n",
    "## Path to where the raw annotations are located.\n",
    "file_path = \"/media/malou/Seagate Expansion Drive/Malou_Master/Master/data/Annotationsets/Cell-annotationset-1and2/\"\n",
    "\n",
    "\n",
    "# Load all images to list to use in flows_to_labels\n",
    "filelist = os.listdir(file_path)\n",
    "save_path = file_path + \"flows/\"\n",
    "imlist = []\n",
    "imname = []\n",
    "for file in filelist:\n",
    "    if file.endswith(\".png\"):\n",
    "        imname.append(file)\n",
    "        im = skimage.io.imread(file_path + file)\n",
    "        im = rgb2lab(im)\n",
    "        im = im[:,:,0]\n",
    "        im = skimage.morphology.label(im)\n",
    "        imlist.append(im)\n",
    "\n",
    "\n",
    "# Creating flow masks\n",
    "flows = labels_to_flows(imlist)\n",
    "\n",
    "\n",
    "\n",
    "cellprob_im = []\n",
    "Yflow = []\n",
    "Xflow = []\n",
    "\n",
    "# Create lists of flows_to_labels output (indexing described in function)\n",
    "for i in range(len(flows)):\n",
    "\n",
    "    cellprob_im.append(flows[i][1])\n",
    "    Yflow.append(flows[i][2])\n",
    "    Xflow.append(flows[i][3])\n",
    "\n",
    "    \n",
    "# Converting lists to array to stack them later\n",
    "cellprob_im = np.asarray(cellprob_im)\n",
    "Yflow = np.asarray(Yflow)\n",
    "Xflow = np.asarray(Xflow)\n",
    "\n",
    "# Currently ranges from -1 to 1, change to 0-255 8bit\n",
    "cellprob_im = img_as_ubyte(cellprob_im)\n",
    "Yflow = img_as_ubyte(Yflow)\n",
    "Xflow = img_as_ubyte(Xflow)\n",
    "for i in range(len(cellprob_im)):\n",
    "\n",
    "    merged = np.dstack((Xflow[i],Yflow[i],cellprob_im[i])) # Merging output from flows_to_labels\n",
    "    skimage.io.imsave(save_path + imname[i], merged)\n",
    "    \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
