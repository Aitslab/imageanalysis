{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1599a432",
   "metadata": {},
   "source": [
    "# Logbook\n",
    "### Leo Westerberg & Marisa Wodrich\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2c031",
   "metadata": {},
   "source": [
    "\n",
    "#### Date: 5 april\n",
    "\n",
    "#### Project: \n",
    "Image analysis for high-throughput microscopy screening\n",
    "\n",
    "#### Aim: \n",
    "To understand how the hoVer-Net is built and what part of the github code belongs to what in the architecture\n",
    "\n",
    "#### Stepwise description of work:\n",
    "* Read the papers about HoVer-Net to truly understand its concept\n",
    "* Try to extract code which belongs to each part of the model code\n",
    "* Try to filter out the part which belongs to classification\n",
    "* Create a notebook for example code comment your results\n",
    "\n",
    "#### Result/Conclusion: \n",
    "After having a hard time understanding the HoVer-Net and its underlying structure, https://www.sciencedirect.com/science/article/abs/pii/S1361841519301045?via%3Dihub, I found a great video which explains the concepts thoroughly: https://www.youtube.com/watch?v=PfDauqZdUCE and now I understand each part of the architecture and what its benefits are.\n",
    "\n",
    "Going through the code in the HoVer-Net github repositoty, was great for getting some connection between intuition and code and I created some trivial comments in a newly created notebook. \n",
    "https://github.com/Aitslab/imageanalysis/blob/master/marisa_leo_dir/example_code.ipynb\n",
    "\n",
    "#### Next steps: \n",
    "* Get a deeper understanding how input is passed into the model\n",
    "* Understand how to use Cvat\n",
    "* Annotate some images\n",
    "* Setting up our own segmentation model based on code in the ***example_code.ipynb*** notebook\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947de287",
   "metadata": {},
   "source": [
    "\n",
    "#### Date: 6 april\n",
    "\n",
    "#### Project: \n",
    "Image analysis for high-throughput microscopy screening\n",
    "\n",
    "#### Aim: \n",
    "Understand the imput to the HoVer-Net and then try to run the HoVer-Net on Google colab to better understand its underlying structure with the example data\n",
    "#### Stepwise description of work:\n",
    "* Browse the code and watch the input data\n",
    "* Clone the project att step by step transfer parts to google colab\n",
    "\n",
    "\n",
    "#### Result/Conclusion: \n",
    "The result of the day was that we got a better understanding of the data passed into the HoVer-Net. We also tried to run the project on our own laptops with the example data. After bumping into several import errors and configuration differences, we tried to upload the project to Google colab but came across many hard bugs and errors when trying the copy and paste code into the notebook partwise.\n",
    "#### Next steps: \n",
    "* Continue to setup the project on Google colab\n",
    "* Annotate some images\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f15926",
   "metadata": {},
   "source": [
    "\n",
    "#### Date: 8 april\n",
    "\n",
    "#### Project: \n",
    "Image analysis for high-throughput microscopy screening\n",
    "\n",
    "#### Aim: \n",
    "Try to get HoverNet or MicroNet to work on my machine also setting upp the report document\n",
    "\n",
    "\n",
    "#### Stepwise description of work:\n",
    "\n",
    "\n",
    "* Try to fix the error of:\n",
    "2022-04-08 22:32:47.231415: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
    "\n",
    "AND\n",
    "\n",
    "File \"src/train.py\", line 270, in <module>\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "  File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/os.py\", line 674, in __setitem__\n",
    "    value = self.encodevalue(value)\n",
    "  File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/os.py\", line 744, in encode\n",
    "    raise TypeError(\"str expected, not %s\" % type(value).__name__)\n",
    "TypeError: str expected, not NoneType\n",
    "\n",
    "\n",
    "* Creating wordfile with IEEE template and share with supervisors\n",
    "#### Result/Conclusion: \n",
    "Finally the first error was solved with the following commands in a specific conda enviroment\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\n",
    "sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "wget https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb\n",
    "sudo dpkg -i cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb\n",
    "sudo apt-key add /var/cuda-repo-ubuntu2004-11-3-local/7fa2af80.pub\n",
    "sudo apt-get update\n",
    "sudo apt-get -y install cuda\n",
    "\n",
    "No progress on solving the second error and I am wondering if it is a machine specific error, but since it does not work on google colab, which have a GPU, it am not certain.\n",
    "\n",
    "I created a word file and found a IEEE template which can be converted to latex later\n",
    "\n",
    "#### Next steps: \n",
    "* Try to solve the second error. If still stuck, try to run on the university system\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c6e9a",
   "metadata": {},
   "source": [
    "#### Date: 9 april\n",
    "\n",
    "#### Project: \n",
    "Image analysis for high-throughput microscopy screening\n",
    "\n",
    "#### Aim: \n",
    "* Try to get HoverNet on work on own machine or Google colab\n",
    "\n",
    "* Try to fix the error of:\n",
    "    File \"src/train.py\", line 270, in <module>\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "      File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/os.py\", line 674, in __setitem__\n",
    "        value = self.encodevalue(value)\n",
    "      File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/os.py\", line 744, in encode\n",
    "        raise TypeError(\"str expected, not %s\" % type(value).__name__)\n",
    "    TypeError: str expected, not NoneType\n",
    "\n",
    "\n",
    "#### Stepwise description of work:\n",
    "* Try different compatible versions of cudatoolkit and cudnn to fix yesterdays error\n",
    "* complete settings in opt/hover with pretrained set\n",
    "* debug errors in hovernet code\n",
    "\n",
    "\n",
    "\n",
    "#### Result/Conclusion: \n",
    "Yesterday I thought that I had solved the problem with:\n",
    "\n",
    " Try to fix the error of:\n",
    "    2022-04-08 22:32:47.231415: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
    "\n",
    "However, this was not the case and the error was shadowed by another one. Starting from the beginning I tried different conda enviroments with different settings and concludingly the commands nessesary for setting up the right enviroment is\n",
    "    conda create --name hovernet python=3.6\n",
    "    conda activate hovernet\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "where requirements.txt consists of:\n",
    "\n",
    "    tensorflow-gpu==1.12.0\n",
    "    tensorpack==0.9.0.1\n",
    "    scikit-image==0.14.2\n",
    "    matplotlib===3.0.2\n",
    "    numpy==1.15.4\n",
    "    scipy==1.4.1\n",
    "    opencv-python==4.1.2.30\n",
    "    openslide-python==1.1.2\n",
    "\n",
    "    conda install cudatoolkit=9.0.0\n",
    "\n",
    "The next problem was the error\n",
    "\n",
    "    File \"src/train.py\", line 270, in <module>\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "      File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/os.py\", line 674, in __setitem__\n",
    "        value = self.encodevalue(value)\n",
    "      File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/os.py\", line 744, in encode\n",
    "        raise TypeError(\"str expected, not %s\" % type(value).__name__)\n",
    "    TypeError: str expected, not NoneType\n",
    "\n",
    "which I realized was due to not setting the right arguments to the run command. Initially we ran it with:\n",
    "    python3 train.py\n",
    "But it as missing the --gpu='...' argument. For example\n",
    "    python train.py --gpu='0'\n",
    "Where the 0 represent a gpu index\n",
    "\n",
    "\n",
    "We also had to download the pretrained set according to the README in the github repository and place the relative path in the opt/hover.py\n",
    "\n",
    "Now we are stuck with an error\n",
    "\n",
    "(hovernet) leo@leo:~/Skrivbord/hover_net/src$ python train.py --gpu='0'\n",
    "[270, 270] [80, 80]\n",
    "Traceback (most recent call last):\n",
    "  File \"train.py\", line 272, in <module>\n",
    "    trainer.run()\n",
    "  File \"train.py\", line 240, in run\n",
    "    self.run_once(opt, sess_init=init_weights, save_dir=log_dir)\n",
    "  File \"train.py\", line 174, in run_once\n",
    "    train_datagen = self.get_datagen(opt['train_batch_size'], mode='train')\n",
    "  File \"train.py\", line 162, in get_datagen\n",
    "    nr_procs=nr_procs)\n",
    "  File \"/home/leo/Skrivbord/hover_net/src/loader/loader.py\", line 72, in train_generator\n",
    "    ds = BatchDataByShape(ds, batch_size, idx=0)\n",
    "  File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/site-packages/tensorpack/dataflow/common.py\", line 179, in __init__\n",
    "    super(BatchDataByShape, self).__init__(ds, batch_size, remainder=False)\n",
    "  File \"/home/leo/anaconda3/envs/hovernet/lib/python3.6/site-packages/tensorpack/dataflow/common.py\", line 95, in __init__\n",
    "    assert batch_size <= len(ds)\n",
    "AssertionError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Next steps: \n",
    "* Try to solve the new error showed above\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d1f8f",
   "metadata": {},
   "source": [
    "#### Date: 11 april\n",
    "\n",
    "#### Project: \n",
    "Image analysis for high-throughput microscopy screening\n",
    "\n",
    "#### Aim: \n",
    "* Try the micronet with the newly installed conda enviroment\n",
    "* Write about different metrics to evaluate the segmentation model\n",
    "\n",
    "\n",
    "#### Stepwise description of work:\n",
    "* Try the micronet with the new versions installed, refer to setup steps from 8th april.\n",
    "* Go through malous report internet to search for different metrics\n",
    "* Write brefly about these metrics\n",
    "\n",
    "\n",
    "#### Result/Conclusion: \n",
    "When trying the micronet using its Demo.ipynb jupyter notebook we bump into the error:\n",
    "\n",
    "    AssertionError                            Traceback (most recent call last)\n",
    "    <ipython-input-3-645e4c6e65b9> in <module>()\n",
    "          3     out_file = out_dir + img_path.split('/')[-2]\n",
    "          4     out_path = out_file+'/'+img_name+'.mat'\n",
    "    ----> 5     pred_map = inferer.run(img_path)\n",
    "          6     pred_inst, pred_type = process_instance_micro(pred_map, inferer.nr_types)\n",
    "          7     labels={'Instance':pred_inst,'Type':pred_type}\n",
    "\n",
    "    /home/leo/Skrivbord/Instance_based_Vision_Transformer/nuclei_seg_cls_infer/single_image_infer.py in run(self, file_path)\n",
    "        271         model_constructor = self.get_model()\n",
    "        272         pred_config = PredictConfig(\n",
    "    --> 273             model        = model_constructor(),\n",
    "        274             session_init = get_model_loader(model_path),\n",
    "        275             input_names  = self.eval_inf_input_tensor_names,\n",
    "\n",
    "    /home/leo/Skrivbord/Instance_based_Vision_Transformer/nuclei_seg_cls_infer/micronet.py in __init__(self)\n",
    "        19     def __init__(self):\n",
    "        20         super(Graph, self).__init__()\n",
    "    ---> 21         assert tf.test.is_gpu_available()\n",
    "        22         self.data_format = 'channels_first'\n",
    "        23 \n",
    "\n",
    "    AssertionError: \n",
    "\n",
    "This is caused by the laptop used not having a dedicated gpu and since this is an error from the last cell of the notebook I assume it should be working fine if it was connected to a GPU. For the hovernet, the status is the same as 9th april, but we will try to run that from a laptop with a GPU as well to see if we proceed further.\n",
    "\n",
    "Looking into different metrics, the report is filled with breif information of Jaccard index, recall, precision and f1 score together with links to sources. For more info, look at the report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Next steps: \n",
    "* Try the micronet on a computer with a cuda compatible gpu\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6e918",
   "metadata": {},
   "source": [
    "#### Date: 17 april\n",
    "\n",
    "#### Project: \n",
    "Image analysis for high-throughput microscopy screening\n",
    "\n",
    "#### Aim: \n",
    "Try the micronet on Google colab\n",
    "\n",
    "#### Stepwise description of work:\n",
    "* Experiment with training the micronet on Google colab\n",
    "* Having the demo.ipynb as entry point, add needed code and folders\n",
    "\n",
    "#### Result/Conclusion: \n",
    "\n",
    "Today, we experimented on trying the micronet on google collab. The progress was pretty good until we bumped into the same error as Leo did on his personal laptop\n",
    "\n",
    "        AssertionError                            Traceback (most recent call last)\n",
    "        <ipython-input-33-1a42ad9e7890> in <module>()\n",
    "            4     out_path = out_file+'/'+img_name+'.mat'\n",
    "            5     print(img_path)\n",
    "        ----> 6     pred_map = inferer.run(img_path)\n",
    "            7     pred_inst, pred_type = process_instance_micro(pred_map, inferer.nr_types)\n",
    "            8     labels={'Instance':pred_inst,'Type':pred_type}\n",
    "\n",
    "        1 frames\n",
    "        <ipython-input-28-80ce3c1597bd> in run(self, file_path)\n",
    "            268         model_constructor = self.get_model()\n",
    "            269         pred_config = PredictConfig(\n",
    "        --> 270             model        = model_constructor(),\n",
    "            271             session_init = get_model_loader(model_path),\n",
    "            272             input_names  = self.eval_inf_input_tensor_names,\n",
    "\n",
    "        <ipython-input-25-096bf8af8f19> in __init__(self)\n",
    "            112             def __init__(self):\n",
    "            113                 super(Graph, self).__init__()\n",
    "        --> 114                 assert tf.test.is_gpu_available()\n",
    "            115                 self.data_format = 'channels_first'\n",
    "            116 \n",
    "\n",
    "        AssertionError: \n",
    "\n",
    "While knowing we have a GPU running on google colab, it assertion says that is is not available. \n",
    "\n",
    "\n",
    "#### Next steps: \n",
    "* Try to fix the issue and contine\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563cbb9f",
   "metadata": {},
   "source": [
    "#### Date: 20 april\n",
    "\n",
    "#### Project: \n",
    "Image analysis for high-throughput microscopy screening\n",
    "\n",
    "#### Aim: \n",
    "Set up the enviroment on a GPU compatible device\n",
    "\n",
    "#### Stepwise description of work:\n",
    "* Try doing the same steps as mensioned on 8th april.\n",
    "* Export the enviroment settings file\n",
    "* Try fixing the problem of Tensorflow not resolving\n",
    "* Try another fresh attempt on Google colab.\n",
    "\n",
    "#### Result/Conclusion: \n",
    "\n",
    "Since Leo's laptop has the correct dependency configuration, the next step was to transfer this enviroment to Marisa's Laptop, having a GPU. Marisa have bumped into loads of problems trying to set up the enviroment and therefore we tried to do the same steps as we did on Leo's computer. Weirdly, Tensorflow-gpu and Cudatoolkit is installed, with the same versions working on leos laptop, \"Tensorflow as tf\" can not be resolved. We tried different pure \"tensorflow\" versions but that only messed up other dependencies. \n",
    "\n",
    "After some research it is a problem sometimes occuring with not recognizing cudatoolkit, making the tensorflow-gpu package visible. But this is weird since cudatoolkit, version 9.0, was in the installed packages.\n",
    "\n",
    "The next appempt was to make a transfer of Leo's enviroment through an .yml enviroment file. However, the same problems with Tensorflow now resolving occured. We wondered if it maybe had to do with the base configuration on Leo's laptop. But browsing through the installed packages, the pure tensorflow version where not there either, so we dispanded that hypothesis.\n",
    "\n",
    "After hours of trying similar things and different versions, we decided to try another attempt at the hovernet on Google colab.\n",
    "\n",
    "However, after studying the segmentation model into detail we discovered that it will not be enought computing power on either Marisa's laptop or Colab. Therefore, so we do not to double work, after this attempt with google colab, the next step is to set up the enviroment on a system with guarenteed computing power, like the university system.\n",
    "\n",
    "#### Next steps: \n",
    "* If no progress on the fresh colab, try the micronet on a university computer with a cuda compatible GPU\n",
    "\n",
    "*** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
