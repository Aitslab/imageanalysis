{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGMENTATION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICTURE OF THE MODEL\n",
    "![](diagram.png \"MarineGEO logo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/vqdang/hover_net/blob/tensorflow-final/src/model/graph.py\n",
    "\"\"\"\n",
    "The following code is an extract from the HoVer-Net github repository\n",
    "https://github.com/vqdang/hover_net/blob/tensorflow-final/src/model/graph.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TRYING TO COMMENT EACH PART OF THE CODE TO SEE HOW IT FITS IN THE PICTURE ABOVE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorpack import *\n",
    "from tensorpack.models import BatchNorm, BNReLU, Conv2D, MaxPooling, FixedUnPooling\n",
    "from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n",
    "\n",
    "from .utils import *\n",
    "\n",
    "####\n",
    "\"\"\"\n",
    "REPRESENTS THE UPSAMPLE BLOCK OF THE PICTURE ABOVE\n",
    "\"\"\"\n",
    "def upsample2x(name, x):\n",
    "    \"\"\"\n",
    "    Nearest neighbor up-sampling\n",
    "    \"\"\"\n",
    "    return FixedUnPooling(\n",
    "                name, x, 2, unpool_mat=np.ones((2, 2), dtype='float32'),\n",
    "                data_format='channels_first')\n",
    "####\n",
    "\"\"\"\n",
    "REPRESENTS A RESIDUAL BLOCK IN THE PICTURE ABOVE\n",
    "\"\"\"\n",
    "def res_blk(name, l, ch, ksize, count, split=1, strides=1, freeze=False):\n",
    "    ch_in = l.get_shape().as_list()\n",
    "    with tf.variable_scope(name):\n",
    "        for i in range(0, count):\n",
    "            with tf.variable_scope('block' + str(i)):  \n",
    "                x = l if i == 0 else BNReLU('preact', l)\n",
    "                x = Conv2D('conv1', x, ch[0], ksize[0], activation=BNReLU)\n",
    "                x = Conv2D('conv2', x, ch[1], ksize[1], split=split, \n",
    "                                strides=strides if i == 0 else 1, activation=BNReLU)\n",
    "                x = Conv2D('conv3', x, ch[2], ksize[2], activation=tf.identity)\n",
    "                if (strides != 1 or ch_in[1] != ch[2]) and i == 0:\n",
    "                    l = Conv2D('convshortcut', l, ch[2], 1, strides=strides)\n",
    "                x = tf.stop_gradient(x) if freeze else x\n",
    "                l = l + x\n",
    "        # end of each group need an extra activation\n",
    "        l = BNReLU('bnlast',l)  \n",
    "    return l\n",
    "####\n",
    "\"\"\"\n",
    "REPRESENTS A DENSE BLOCK IN THE PICTURE ABOVE\n",
    "\"\"\"\n",
    "def dense_blk(name, l, ch, ksize, count, split=1, padding='valid'):\n",
    "    with tf.variable_scope(name):\n",
    "        for i in range(0, count):\n",
    "            with tf.variable_scope('blk/' + str(i)):\n",
    "                x = BNReLU('preact_bna', l)\n",
    "                x = Conv2D('conv1', x, ch[0], ksize[0], padding=padding, activation=BNReLU)\n",
    "                x = Conv2D('conv2', x, ch[1], ksize[1], padding=padding, split=split)\n",
    "                ##\n",
    "                if padding == 'valid':\n",
    "                    x_shape = x.get_shape().as_list()\n",
    "                    l_shape = l.get_shape().as_list()\n",
    "                    l = crop_op(l, (l_shape[2] - x_shape[2], \n",
    "                                    l_shape[3] - x_shape[3]))\n",
    "\n",
    "                l = tf.concat([l, x], axis=1)\n",
    "        l = BNReLU('blk_bna', l)\n",
    "    return l\n",
    "####\n",
    "\"\"\"\n",
    "REPRESENTS THE FIRST PART BEFORE THE BRANCHING IN THE PICTURE ABOVE\n",
    "\"\"\"\n",
    "def encoder(i, freeze):\n",
    "    \"\"\"\n",
    "    Pre-activated ResNet50 Encoder\n",
    "    \"\"\"\n",
    "\n",
    "    d1 = Conv2D('conv0',  i, 64, 7, padding='valid', strides=1, activation=BNReLU)\n",
    "    d1 = res_blk('group0', d1, [ 64,  64,  256], [1, 3, 1], 3, strides=1, freeze=freeze)                       \n",
    "    \n",
    "    d2 = res_blk('group1', d1, [128, 128,  512], [1, 3, 1], 4, strides=2, freeze=freeze)\n",
    "    d2 = tf.stop_gradient(d2) if freeze else d2\n",
    "\n",
    "    d3 = res_blk('group2', d2, [256, 256, 1024], [1, 3, 1], 6, strides=2, freeze=freeze)\n",
    "    d3 = tf.stop_gradient(d3) if freeze else d3\n",
    "\n",
    "    d4 = res_blk('group3', d3, [512, 512, 2048], [1, 3, 1], 3, strides=2, freeze=freeze)\n",
    "    d4 = tf.stop_gradient(d4) if freeze else d4\n",
    "    \n",
    "    d4 = Conv2D('conv_bot',  d4, 1024, 1, padding='same')\n",
    "    return [d1, d2, d3, d4]\n",
    "####\n",
    "\"\"\"\n",
    "REPRESENTS EACH BRANCH PART AFTER THE BRANCHING IN THE PICTURE ABOVE\n",
    "\"\"\"\n",
    "def decoder(name, i):\n",
    "    pad = 'valid' # to prevent boundary artifacts\n",
    "    with tf.variable_scope(name):\n",
    "        with tf.variable_scope('u3'):\n",
    "            u3 = upsample2x('rz', i[-1])\n",
    "            u3_sum = tf.add_n([u3, i[-2]])\n",
    "\n",
    "            u3 = Conv2D('conva', u3_sum, 256, 5, strides=1, padding=pad)   \n",
    "            u3 = dense_blk('dense', u3, [128, 32], [1, 5], 8, split=4, padding=pad)\n",
    "            u3 = Conv2D('convf', u3, 512, 1, strides=1)   \n",
    "        ####\n",
    "        with tf.variable_scope('u2'):          \n",
    "            u2 = upsample2x('rz', u3)\n",
    "            u2_sum = tf.add_n([u2, i[-3]])\n",
    "\n",
    "            u2x = Conv2D('conva', u2_sum, 128, 5, strides=1, padding=pad)\n",
    "            u2 = dense_blk('dense', u2x, [128, 32], [1, 5], 4, split=4, padding=pad)\n",
    "            u2 = Conv2D('convf', u2, 256, 1, strides=1)   \n",
    "        ####\n",
    "        with tf.variable_scope('u1'):          \n",
    "            u1 = upsample2x('rz', u2)\n",
    "            u1_sum = tf.add_n([u1, i[-4]])\n",
    "\n",
    "            u1 = Conv2D('conva', u1_sum, 64, 5, strides=1, padding='same')\n",
    "\n",
    "    return [u3, u2x, u1]\n",
    "\n",
    "####\n",
    "\n",
    "class Model(ModelDesc, Config):\n",
    "    def __init__(self, freeze=False):\n",
    "        super(Model, self).__init__()\n",
    "        assert tf.test.is_gpu_available()\n",
    "        self.freeze = freeze\n",
    "        self.data_format = 'NCHW'\n",
    "\n",
    "    def _get_inputs(self):\n",
    "        return [InputDesc(tf.float32, [None] + self.train_input_shape + [3], 'images'),\n",
    "                InputDesc(tf.float32, [None] + self.train_mask_shape  + [None], 'truemap-coded')]\n",
    "    \n",
    "    # for node to receive manual info such as learning rate.\n",
    "    def add_manual_variable(self, name, init_value, summary=True):\n",
    "        var = tf.get_variable(name, initializer=init_value, trainable=False)\n",
    "        if summary:\n",
    "            tf.summary.scalar(name + '-summary', var)\n",
    "        return\n",
    "\n",
    "    def _get_optimizer(self):\n",
    "        with tf.variable_scope(\"\", reuse=True):\n",
    "            lr = tf.get_variable('learning_rate')\n",
    "        opt = self.optimizer(learning_rate=lr)\n",
    "        return opt\n",
    "\n",
    "####\n",
    "class Model_NP_HV(Model):\n",
    "    def _build_graph(self, inputs):\n",
    "        \n",
    "        images, truemap_coded = inputs\n",
    "        orig_imgs = images\n",
    "\n",
    "        true_np = truemap_coded[...,0]\n",
    "        true_np = tf.cast(true_np, tf.int32)\n",
    "        true_np = tf.identity(true_np, name='truemap-np')            \n",
    "        one_np  = tf.one_hot(true_np, 2, axis=-1)\n",
    "        true_np = tf.expand_dims(true_np, axis=-1)\n",
    "\n",
    "        true_hv = truemap_coded[...,-2:]\n",
    "        true_hv = tf.identity(true_hv, name='truemap-hv')\n",
    "\n",
    "        ####\n",
    "        with argscope(Conv2D, activation=tf.identity, use_bias=False, # K.he initializer\n",
    "                      W_init=tf.variance_scaling_initializer(scale=2.0, mode='fan_out')), \\\n",
    "                argscope([Conv2D, BatchNorm], data_format=self.data_format):\n",
    "\n",
    "            i = tf.transpose(images, [0, 3, 1, 2])\n",
    "            i = i if not self.input_norm else i / 255.0\n",
    "\n",
    "            ####\n",
    "\n",
    "            \"\"\"\n",
    "            USE ALL THE METHODS DECLARED ABOVE\n",
    "            \"\"\"\n",
    "            d = encoder(i, self.freeze)\n",
    "            d[0] = crop_op(d[0], (184, 184))\n",
    "            d[1] = crop_op(d[1], (72, 72))\n",
    "\n",
    "            ####\n",
    "            np_feat = decoder('np', d)\n",
    "            npx = BNReLU('preact_out_np', np_feat[-1])\n",
    "\n",
    "            hv_feat = decoder('hv', d)\n",
    "            hv = BNReLU('preact_out_hv', hv_feat[-1])\n",
    "\n",
    "            #### Nuclei Pixels (NP)\n",
    "            logi_np = Conv2D('conv_out_np', npx, 2, 1, use_bias=True, activation=tf.identity)\n",
    "            logi_np = tf.transpose(logi_np, [0, 2, 3, 1])\n",
    "            soft_np = tf.nn.softmax(logi_np, axis=-1)\n",
    "            prob_np = tf.identity(soft_np[...,1], name='predmap-prob-np')\n",
    "            prob_np = tf.expand_dims(prob_np, axis=-1)\n",
    "\n",
    "            #### Horizontal-Vertival (HV)\n",
    "            logi_hv = Conv2D('conv_out_hv', hv, 2, 1, use_bias=True, activation=tf.identity)\n",
    "            logi_hv = tf.transpose(logi_hv, [0, 2, 3, 1])\n",
    "            prob_hv = tf.identity(logi_hv, name='predmap-prob-hv')\n",
    "            pred_hv = tf.identity(logi_hv, name='predmap-hv')\n",
    "    \n",
    "            # * channel ordering: type-map, segmentation map\n",
    "            # encoded so that inference can extract all output at once\n",
    "           \n",
    "            predmap_coded = tf.concat([prob_np, pred_hv], axis=-1, name='predmap-coded')\n",
    "        ####\n",
    "        def get_gradient_hv(l, h_ch, v_ch):\n",
    "            \"\"\"\n",
    "            Calculate the horizontal partial differentiation for horizontal channel\n",
    "            and the vertical partial differentiation for vertical channel.\n",
    "            The partial differentiation is approximated by calculating the central differnce\n",
    "            which is obtained by using Sobel kernel of size 5x5. The boundary is zero-padded\n",
    "            when channel is convolved with the Sobel kernel.\n",
    "            Args:\n",
    "                l (tensor): tensor of shape NHWC with C should be 2 (1 channel for horizonal \n",
    "                            and 1 channel for vertical)\n",
    "                h_ch(int) : index within C axis of `l` that corresponds to horizontal channel\n",
    "                v_ch(int) : index within C axis of `l` that corresponds to vertical channel\n",
    "            \"\"\"\n",
    "            def get_sobel_kernel(size):\n",
    "                assert size % 2 == 1, 'Must be odd, get size=%d' % size\n",
    "\n",
    "                h_range = np.arange(-size//2+1, size//2+1, dtype=np.float32)\n",
    "                v_range = np.arange(-size//2+1, size//2+1, dtype=np.float32)\n",
    "                h, v = np.meshgrid(h_range, v_range)\n",
    "                kernel_h = h / (h * h + v * v + 1.0e-15)\n",
    "                kernel_v = v / (h * h + v * v + 1.0e-15)\n",
    "                return kernel_h, kernel_v            \n",
    "\n",
    "            mh, mv = get_sobel_kernel(5)\n",
    "            mh = tf.constant(mh, dtype=tf.float32)\n",
    "            mv = tf.constant(mv, dtype=tf.float32)\n",
    "\n",
    "            mh = tf.reshape(mh, [5, 5, 1, 1])\n",
    "            mv = tf.reshape(mv, [5, 5, 1, 1])\n",
    "            \n",
    "            # central difference to get gradient, ignore the boundary problem  \n",
    "            h = tf.expand_dims(l[...,h_ch], axis=-1)  \n",
    "            v = tf.expand_dims(l[...,v_ch], axis=-1)  \n",
    "            dh = tf.nn.conv2d(h, mh, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            dv = tf.nn.conv2d(v, mv, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            output = tf.concat([dh, dv], axis=-1)\n",
    "            return output\n",
    "        def loss_mse(true, pred, name=None):\n",
    "            ### regression loss\n",
    "            loss = pred - true\n",
    "            loss = tf.reduce_mean(loss * loss, name=name)\n",
    "            return loss\n",
    "        def loss_msge(true, pred, focus, name=None):\n",
    "            focus = tf.stack([focus, focus], axis=-1)\n",
    "            pred_grad = get_gradient_hv(pred, 1, 0)\n",
    "            true_grad = get_gradient_hv(true, 1, 0) \n",
    "            loss = pred_grad - true_grad\n",
    "            loss = focus * (loss * loss)\n",
    "            # artificial reduce_mean with focus region\n",
    "            loss = tf.reduce_sum(loss) / (tf.reduce_sum(focus) + 1.0e-8)\n",
    "            loss = tf.identity(loss, name=name)\n",
    "            return loss\n",
    "\n",
    "        ####\n",
    "        if get_current_tower_context().is_training:\n",
    "            #---- LOSS ----#\n",
    "            loss = 0\n",
    "            for term, weight in self.loss_term.items():\n",
    "                if term == 'mse':\n",
    "                    term_loss = loss_mse(true_hv, pred_hv, name='loss-mse')\n",
    "                elif term == 'msge':\n",
    "                    focus = truemap_coded[...,0]\n",
    "                    term_loss = loss_msge(true_hv, pred_hv, focus, name='loss-msge')\n",
    "                elif term == 'bce':\n",
    "                    term_loss = categorical_crossentropy(soft_np, one_np)\n",
    "                    term_loss = tf.reduce_mean(term_loss, name='loss-bce')\n",
    "                elif 'dice' in self.loss_term:\n",
    "                    term_loss = dice_loss(soft_np[...,0], one_np[...,0]) \\\n",
    "                              + dice_loss(soft_np[...,1], one_np[...,1])\n",
    "                    term_loss = tf.identity(term_loss, name='loss-dice')\n",
    "                else:\n",
    "                    assert False, 'Not support loss term: %s' % term\n",
    "                add_moving_summary(term_loss)\n",
    "                loss += term_loss * weight\n",
    "\n",
    "            if self.type_classification:\n",
    "                term_loss = categorical_crossentropy(soft_class, one_type)\n",
    "                term_loss = tf.reduce_mean(term_loss, name='loss-xentropy-class')\n",
    "                add_moving_summary(term_loss)\n",
    "                loss = loss + term_loss\n",
    "\n",
    "                term_loss = 0\n",
    "                for type_id in range(self.nr_types):\n",
    "                    term_loss += dice_loss(soft_class[...,type_id], \n",
    "                                           one_type[...,type_id])\n",
    "                term_loss = tf.identity(term_loss, name='loss-dice-class')\n",
    "                add_moving_summary(term_loss)\n",
    "                loss = loss + term_loss\n",
    "\n",
    "            ### combine the loss into single cost function\n",
    "            self.cost = tf.identity(loss, name='overall-loss')            \n",
    "            add_moving_summary(self.cost)\n",
    "            ####\n",
    "\n",
    "            add_param_summary(('.*/W', ['histogram']))   # monitor W\n",
    "\n",
    "            ### logging visual sthg\n",
    "            orig_imgs = tf.cast(orig_imgs  , tf.uint8)\n",
    "            tf.summary.image('input', orig_imgs, max_outputs=1)\n",
    "\n",
    "            orig_imgs = crop_op(orig_imgs, (190, 190), \"NHWC\")\n",
    "\n",
    "            pred_np = colorize(prob_np[...,0], cmap='jet')\n",
    "            true_np = colorize(true_np[...,0], cmap='jet')\n",
    "            \n",
    "            pred_h = colorize(prob_hv[...,0], vmin=-1, vmax=1, cmap='jet')\n",
    "            pred_v = colorize(prob_hv[...,1], vmin=-1, vmax=1, cmap='jet')\n",
    "            true_h = colorize(true_hv[...,0], vmin=-1, vmax=1, cmap='jet')\n",
    "            true_v = colorize(true_hv[...,1], vmin=-1, vmax=1, cmap='jet')\n",
    "\n",
    "            if not self.type_classification:\n",
    "                viz = tf.concat([orig_imgs, \n",
    "                                pred_h, pred_v, pred_np, \n",
    "                                true_h, true_v, true_np], 2)\n",
    "            else:\n",
    "                pred_type = tf.transpose(soft_class, (0, 1, 3, 2))\n",
    "                pred_type = tf.reshape(pred_type, [-1, 80, 80 * self.nr_types])\n",
    "                true_type = tf.cast(true_type[...,0] / self.nr_classes, tf.float32)\n",
    "                true_type = colorize(true_type, vmin=0, vmax=1, cmap='jet')\n",
    "                pred_type = colorize(pred_type, vmin=0, vmax=1, cmap='jet')\n",
    "\n",
    "                viz = tf.concat([orig_imgs, \n",
    "                                pred_h, pred_v, pred_np, pred_type, \n",
    "                                true_h, true_v, true_np, true_type,], 2)\n",
    "\n",
    "            viz = tf.concat([viz[0], viz[-1]], axis=0)\n",
    "            viz = tf.expand_dims(viz, axis=0)\n",
    "            tf.summary.image('output', viz, max_outputs=1)\n",
    "\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
