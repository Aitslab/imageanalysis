{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fochJKHAdGWA"
      },
      "source": [
        "# Micro-Net re-implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXRwH9welaml"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgDZXCN9lcVT",
        "outputId": "580b1326-d51f-4532-c8bf-63bc586091ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Collecting tensorpack\n",
            "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.21.6)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.3.0)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.3)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n",
            "Installing collected packages: msgpack-numpy, tensorpack\n",
            "Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.44.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorpack\n",
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b7PPlL5JeQn",
        "outputId": "63d6f85f-2821-4a36-d547-f6583b2e38b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9pypcmTfbcR"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BzJso_NgSgT"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import random\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorpack import imgaug\n",
        "import os\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import math\n",
        "import os\n",
        "from collections import deque\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorpack.predict import OfflinePredictor, PredictConfig\n",
        "from tensorpack.tfutils.sessinit import get_model_loader\n",
        "import json\n",
        "import operator\n",
        "from scipy.ndimage import filters, measurements\n",
        "from scipy.ndimage.morphology import (\n",
        "                                    binary_erosion,\n",
        "                                    binary_dilation, \n",
        "                                    binary_fill_holes,\n",
        "                                    distance_transform_cdt,\n",
        "                                    distance_transform_edt)\n",
        "from skimage.morphology import remove_small_objects, watershed\n",
        "import importlib\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorpack import imgaug\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS8gbbTAffdw"
      },
      "source": [
        "### Load data & folder paths\n",
        "Press on the folder symbol to the right of the notebook and then look for \"mount drive\". The folders used below should be in the root folder.\n",
        "\n",
        "First place the dataset folder from the github repo into your drive (change \"../dataset\" on each row to \"/content/drive/MyDrive/dataset\" in each of the .txt files in the dataset folder, easy using replace in vs code)\n",
        "\n",
        "then place the papillary RCC subtyping dataset(1,2, nuclei_prediction) in the same folder\n",
        "\n",
        "Download the two model files and place them in the root folder\n",
        "\n",
        "link: https://nextcloud.chenli.group/index.php/s/c4HzzCWXep5B24S\n",
        "passwd: KrfmCJen\n",
        "\n",
        "The dataset can be found using the link\n",
        "https://dataset.chenli.group/home/prcc-subtyping\n",
        "where you should download the dataset folder. Take its content of folder \"1\" and \"2\" and place in the already created datafolder\n",
        "\n",
        "The structure will look like this\n",
        "\n",
        "* drive (folder)\n",
        " * MyDrive (folder)\n",
        "  * dataset (folder)\n",
        "   * 1 (folder with images )\n",
        "   * 2 (folder with images)\n",
        "   * nuclei_prediction (folder)\n",
        "   dataset.txt\n",
        "   testset.txt\n",
        "   trainset.txt\n",
        "   validset.txt\n",
        "  \n",
        "   model-36000.data-00000-of-00001\n",
        "   \n",
        "   model-36000.index\n",
        "\n",
        "\n",
        "out_dir changed to the folder where we put the nuclei_prediction folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mo8Xm84jP0s"
      },
      "outputs": [],
      "source": [
        "# Connect to a drive which have the folders imported \n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/dataset/dataset.txt'\n",
        "out_dir = '/content/drive/MyDrive/dataset/nuclei_prediction/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuiAcs1osoXT"
      },
      "source": [
        "### utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr2QHsNbswS1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorpack import *\n",
        "from tensorpack.tfutils.symbolic_functions import *\n",
        "from tensorpack.tfutils.summary import *\n",
        "\n",
        "from matplotlib import cm\n",
        "\n",
        "# TODO: assert for data format\n",
        "####\n",
        "def resize_op(x, height_factor=None, width_factor=None, size=None, \n",
        "                interp='bicubic', data_format='channels_last'):\n",
        "    \"\"\"\n",
        "    Resize by a factor if `size=None` else resize to `size`\n",
        "    \"\"\"\n",
        "    original_shape = x.get_shape().as_list()\n",
        "    if size is not None:\n",
        "        if data_format == 'channels_first':\n",
        "            x = tf.transpose(x, [0, 2, 3, 1])\n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, size)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, size)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, size)\n",
        "            x = tf.transpose(x, [0, 3, 1, 2])\n",
        "            x.set_shape((None, \n",
        "                original_shape[1] if original_shape[1] is not None else None, \n",
        "                size[0], size[1]))\n",
        "        else:\n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, size)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, size)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, size)\n",
        "            x.set_shape((None, \n",
        "                size[0], size[1], \n",
        "                original_shape[3] if original_shape[3] is not None else None))\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            new_shape = tf.cast(tf.shape(x)[2:], tf.float32)    \n",
        "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('float32'))\n",
        "            new_shape = tf.cast(new_shape, tf.int32)    \n",
        "            x = tf.transpose(x, [0, 2, 3, 1])\n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, new_shape)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, new_shape)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, new_shape)\n",
        "            x = tf.transpose(x, [0, 3, 1, 2])\n",
        "            x.set_shape((None,\n",
        "                        original_shape[1] if original_shape[1] is not None else None,\n",
        "                        int(original_shape[2] * height_factor) if original_shape[2] is not None else None,\n",
        "                        int(original_shape[3] * width_factor) if original_shape[3] is not None else None))\n",
        "        else:\n",
        "            original_shape = x.get_shape().as_list()\n",
        "            new_shape = tf.cast(tf.shape(x)[1:3], tf.float32)    \n",
        "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('float32'))\n",
        "            new_shape = tf.cast(new_shape, tf.int32)    \n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, new_shape)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, new_shape)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, new_shape)\n",
        "            x.set_shape((None,\n",
        "                        int(original_shape[1] * height_factor) if original_shape[1] is not None else None,\n",
        "                        int(original_shape[2] * width_factor) if original_shape[2] is not None else None,\n",
        "                        original_shape[3] if original_shape[3] is not None else None))\n",
        "    return x \n",
        "\n",
        "####\n",
        "def crop_op(x, cropping, data_format='channels_first'):\n",
        "    \"\"\"\n",
        "    Center crop image\n",
        "    Args:\n",
        "        cropping is the substracted portion\n",
        "    \"\"\"\n",
        "    crop_t = cropping[0] // 2\n",
        "    crop_b = cropping[0] - crop_t\n",
        "    crop_l = cropping[1] // 2\n",
        "    crop_r = cropping[1] - crop_l\n",
        "    if data_format == 'channels_first':\n",
        "        x = x[:,:,crop_t:-crop_b,crop_l:-crop_r]\n",
        "    else:\n",
        "        x = x[:,crop_t:-crop_b,crop_l:-crop_r]\n",
        "    return x       \n",
        "####\n",
        "\n",
        "def categorical_crossentropy(output, target):\n",
        "    \"\"\"\n",
        "        categorical cross-entropy, accept probabilities not logit\n",
        "    \"\"\"\n",
        "    # scale preds so that the class probs of each sample sum to 1\n",
        "    output /= tf.reduce_sum(output,\n",
        "                            reduction_indices=len(output.get_shape()) - 1,\n",
        "                            keepdims=True)\n",
        "    # manual computation of crossentropy\n",
        "    epsilon = tf.convert_to_tensor(10e-8, output.dtype.base_dtype)\n",
        "    output = tf.clip_by_value(output, epsilon, 1. - epsilon)\n",
        "    return - tf.reduce_sum(target * tf.log(output),\n",
        "                            reduction_indices=len(output.get_shape()) - 1)\n",
        "####\n",
        "def dice_loss(output, target, loss_type='sorensen', axis=None, smooth=1e-3):\n",
        "    \"\"\"Soft dice (Sørensen or Jaccard) coefficient for comparing the similarity\n",
        "    of two batch of data, usually be used for binary image segmentation\n",
        "    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n",
        "    Parameters\n",
        "    -----------\n",
        "    output : Tensor\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\n",
        "    target : Tensor\n",
        "        The target distribution, format the same with `output`.\n",
        "    loss_type : str\n",
        "        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n",
        "    axis : tuple of int\n",
        "        All dimensions are reduced, default ``[1,2,3]``.\n",
        "    smooth : float\n",
        "        This small value will be added to the numerator and denominator.\n",
        "            - If both output and target are empty, it makes sure dice is 1.\n",
        "            - If either output or target are empty (all pixels are background), \n",
        "              dice = ```smooth/(small_value + smooth)``, then if smooth is very small, \n",
        "              dice close to 0 (even the image values lower than the threshold), \n",
        "              so in this case, higher smooth can have a higher dice.\n",
        "    Examples\n",
        "    ---------\n",
        "    >>> dice_loss = dice_coe(outputs, y_)\n",
        "    \"\"\"\n",
        "    target = tf.squeeze(tf.cast(target, tf.float32))\n",
        "    output = tf.squeeze(tf.cast(output, tf.float32))\n",
        "\n",
        "    inse = tf.reduce_sum(output * target, axis=axis)\n",
        "    if loss_type == 'jaccard':\n",
        "        l = tf.reduce_sum(output * output, axis=axis)\n",
        "        r = tf.reduce_sum(target * target, axis=axis)\n",
        "    elif loss_type == 'sorensen':\n",
        "        l = tf.reduce_sum(output, axis=axis)\n",
        "        r = tf.reduce_sum(target, axis=axis)\n",
        "    else:\n",
        "        raise Exception(\"Unknown loss_type\")\n",
        "    # already flatten\n",
        "    dice = 1.0 - (2. * inse + smooth) / (l + r + smooth)\n",
        "    ##\n",
        "    return dice\n",
        "####\n",
        "def colorize(value, vmin=None, vmax=None, cmap=None):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      - value: input tensor, NHWC ('channels_last')\n",
        "      - vmin: the minimum value of the range used for normalization.\n",
        "        (Default: value minimum)\n",
        "      - vmax: the maximum value of the range used for normalization.\n",
        "        (Default: value maximum)\n",
        "      - cmap: a valid cmap named for use with matplotlib's `get_cmap`.\n",
        "        (Default: 'gray')\n",
        "    Example usage:\n",
        "    ```\n",
        "    output = tf.random_uniform(shape=[256, 256, 1])\n",
        "    output_color = colorize(output, vmin=0.0, vmax=1.0, cmap='viridis')\n",
        "    tf.summary.image('output', output_color)\n",
        "    ```\n",
        "    \n",
        "    Returns a 3D tensor of shape [height, width, 3], uint8.\n",
        "    \"\"\"\n",
        "\n",
        "    # normalize\n",
        "    if vmin is None:\n",
        "        vmin = tf.reduce_min(value, axis=[1,2])\n",
        "        vmin = tf.reshape(vmin, [-1, 1, 1])\n",
        "    if vmax is None:\n",
        "        vmax = tf.reduce_max(value, axis=[1,2])\n",
        "        vmax = tf.reshape(vmax, [-1, 1, 1])\n",
        "    value = (value - vmin) / (vmax - vmin) # vmin..vmax\n",
        "\n",
        "    # squeeze last dim if it exists\n",
        "    # NOTE: will throw error if use get_shape()\n",
        "    # value = tf.squeeze(value)\n",
        "\n",
        "    # quantize\n",
        "    value = tf.round(value * 255)\n",
        "    indices = tf.cast(value, np.int32)\n",
        "\n",
        "    # gather\n",
        "    colormap = cm.get_cmap(cmap if cmap is not None else 'gray')\n",
        "    colors = colormap(np.arange(256))[:, :3]\n",
        "    colors = tf.constant(colors, dtype=tf.float32)\n",
        "    value = tf.gather(colors, indices)\n",
        "    value = tf.cast(value * 255, tf.uint8)\n",
        "    return value\n",
        "####\n",
        "def make_image(x, cy, cx, scale_y, scale_x):\n",
        "    \"\"\"\n",
        "    Take 1st image from x and turn channels representations\n",
        "    into 2D image, with cx number of channels in x-axis and\n",
        "    cy number of channels in y-axis\n",
        "    \"\"\"\n",
        "    # norm x for better visual\n",
        "    x = tf.transpose(x,(0,2,3,1)) # NHWC\n",
        "    max_x = tf.reduce_max(x, axis=-1, keep_dims=True)\n",
        "    min_x = tf.reduce_min(x, axis=-1, keep_dims=True)\n",
        "    x = 255 * (x - min_x) / (max_x - min_x)\n",
        "    ###\n",
        "    x_shape = tf.shape(x)\n",
        "    channels = x_shape[-1]\n",
        "    iy , ix = x_shape[1], x_shape[2] \n",
        "    ###\n",
        "    x = tf.slice(x,(0,0,0,0),(1,-1,-1,-1))\n",
        "    x = tf.reshape(x,(iy,ix,channels))\n",
        "    ix += 4\n",
        "    iy += 4\n",
        "    x = tf.image.resize_image_with_crop_or_pad(x, iy, ix)\n",
        "    x = tf.reshape(x,(iy,ix,cy,cx)) \n",
        "    x = tf.transpose(x,(2,0,3,1)) #cy,iy,cx,ix\n",
        "    x = tf.reshape(x,(1,cy*iy,cx*ix,1))\n",
        "    x = resize_op(x, scale_y, scale_x)\n",
        "    return tf.cast(x, tf.uint8)\n",
        "####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48KytT3wlE4V"
      },
      "source": [
        "### Config.py\n",
        "Contains:\n",
        "* Config class\n",
        " * Dependent on utils.py\n",
        "\n",
        "changed\n",
        "\n",
        "        config_file = importlib.import_module('other') # fcn8, dcan, etc.\n",
        "        config_dict = config_file.__getattribute__(self.model_type)\n",
        "\n",
        "to\n",
        "\n",
        "        config_dict = {\n",
        "    'train_input_shape' : [252, 252],\n",
        "    'train_mask_shape'  : [252, 252],\n",
        "    'infer_input_shape' : [252, 252],\n",
        "    'infer_mask_shape'  : [252, 252], \n",
        "    'infer_avalible_shape': [200, 200],\n",
        "\n",
        "    'training_phase'    : [\n",
        "        {\n",
        "            'nr_epochs': 80,\n",
        "            'manual_parameters' : {\n",
        "                'learning_rate': (1.0e-4, [('40', 1.0e-5)]),\n",
        "                'aux_loss_dw'  : (1.0, \n",
        "                        [(str(epoch), 1.0 / epoch) for epoch in range(2, 251)]\n",
        "                    ),\n",
        "            },\n",
        "            'train_batch_size'  : 8,\n",
        "            'infer_batch_size'  : 16,\n",
        "\n",
        "            'model_flags' : {\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "\n",
        "    'optimizer'         : tf.compat.v1.train.Optimizer,\n",
        "\n",
        "    'inf_batch_size'  : 16,\n",
        "    'inf_auto_metric'   : 'valid_dice',\n",
        "    'inf_auto_comparator' : '>',}\n",
        "\n",
        "\n",
        "This works because the model_type is hardcoded to \"micronet\". The dict can be found in other.py with the tensorflow version modification of \n",
        "\n",
        "      tf.train.AdamOptimizer \n",
        "to\n",
        "\n",
        "    tf.compat.v1.train.Optimizer,\n",
        "\n",
        "\n",
        "We also had to change\n",
        "\n",
        "      model_constructor = importlib.import_module('%s' % self.model_type)\n",
        "      model_constructor = model_constructor.Graph       \n",
        "      return model_constructor # NOTE return alias, not object\n",
        "\n",
        "where we return the Graph class in the micronet.py directly in the code. \n",
        "\n",
        "and lastly\n",
        "\n",
        "      self.save_dir = './%s' % self.model_type\n",
        "\n",
        "to\n",
        "\n",
        "      self.save_dir = './%s' % 'content/drive/MyDrive'\n",
        "\n",
        "\n",
        "\n",
        "The below changes are mentioned in https://github.com/tensorpack/tensorpack/blob/master/CHANGES.md\n",
        "\n",
        "* In the Graph class i changed the name of _get_inputs() to input() because it threw a not implemented error for the interface ModelDesc\n",
        "\n",
        "the same goes for \n",
        "* InputDesc which should be replaced with tf.TensorSpec(Also switch first and second argument) \n",
        "\n",
        "* _get_optimizer() should be named optimizer()\n",
        "\n",
        "* _build_graph() should be named build_graph()\n",
        "\n",
        "\n",
        "Another change we had to do was to modify the build_graph signature from\n",
        "\n",
        "      def build_graph(self, input):\n",
        "        ...\n",
        "        images, truemap_coded = inputs\n",
        "\n",
        "to\n",
        "\n",
        "      def build_graph(self, images, truemap_coded):\n",
        "\n",
        "because it was complaining about to few arguments. The reason for this is probably the changed return value from inputs()\n",
        "                \n",
        "Since we are now using tensorflow 2.x we also had to change\n",
        "\n",
        "      tf.contrib\n",
        "to\n",
        "\n",
        "      tf.compat.v1.estimator\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cU1ifAalRPf"
      },
      "outputs": [],
      "source": [
        "class Config(object):\n",
        "    def __init__(self, ):\n",
        "\n",
        "        self.seed = 10 \n",
        "        mode = 'micronet'\n",
        "        self.model_type = 'micronet'\n",
        "\n",
        "        \n",
        "        self.type_boundray = True # whether to predict the nuclear boundray\n",
        "        self.type_nuclei = True\n",
        "        self.type_classification = True # whether to predict the nuclear type\n",
        "        # ! must use CoNSeP dataset, where nuclear type labels are available\n",
        "        # denotes number of classes for nuclear type classification, \n",
        "        # plus the background class\n",
        "        self.nr_types = 5\n",
        "        # ! some semantic segmentation network like micronet,\n",
        "        # ! nr_types will replace nr_classes if type_classification=True\n",
        "        self.nr_classes = 2 # Nuclei Pixels vs Background\n",
        "        \n",
        "        self.auxilary_tasks = False # whether to use deep supervision or auxilary tasks strategy\n",
        "        self.regression = True # whether to use np-regression branch\n",
        "        self.gcb = True # whether to use attention block on encoder\n",
        "        self.uncertainty = False # whether to use uncertainty loss weight strategy\n",
        "        self.mix_class = True # single or multiple classification branches\n",
        "        self.use_dice = False # whether to use dice loss\n",
        "\n",
        "        # define your nuclei type name here, please ensure it contains\n",
        "        # same the amount as defined in `self.nr_types` . ID 0 is preserved\n",
        "        # for background so please don't use it as ID\n",
        "        self.nuclei_type_dict = {\n",
        "            'Grade1': 1, # ! Please ensure the matching ID is unique\n",
        "            'Grade2': 2,\n",
        "            'Grade3' : 3,\n",
        "            'Endothelium': 4,\n",
        "        }\n",
        "        assert len(self.nuclei_type_dict.values()) == self.nr_types - 1\n",
        "\n",
        "        #### Dynamically setting the config file into variable\n",
        "        config_dict = {\n",
        "    'train_input_shape' : [252, 252],\n",
        "    'train_mask_shape'  : [252, 252],\n",
        "    'infer_input_shape' : [252, 252],\n",
        "    'infer_mask_shape'  : [252, 252], \n",
        "    'infer_avalible_shape': [200, 200],\n",
        "\n",
        "    'training_phase'    : [\n",
        "        {\n",
        "            'nr_epochs': 80,\n",
        "            'manual_parameters' : {\n",
        "                'learning_rate': (1.0e-4, [('40', 1.0e-5)]),\n",
        "                'aux_loss_dw'  : (1.0, \n",
        "                        [(str(epoch), 1.0 / epoch) for epoch in range(2, 251)]\n",
        "                    ),\n",
        "            },\n",
        "            'train_batch_size'  : 8,\n",
        "            'infer_batch_size'  : 16,\n",
        "\n",
        "            'model_flags' : {\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "\n",
        "    'optimizer'         : tf.compat.v1.train.Optimizer,\n",
        "\n",
        "    'inf_batch_size'  : 16,\n",
        "    'inf_auto_metric'   : 'valid_dice',\n",
        "    'inf_auto_comparator' : '>',\n",
        "    }\n",
        "\n",
        "        for variable, value in config_dict.items():\n",
        "            self.__setattr__(variable, value)\n",
        "        #### Training data\n",
        "\n",
        "        self.data_ext = '.npy' \n",
        "\n",
        "        # number of processes for parallel processing input\n",
        "        self.nr_procs_train = 8 \n",
        "        self.nr_procs_valid = 4 \n",
        "\n",
        "        self.input_norm  = True # normalize RGB to 0-1 range\n",
        "\n",
        "        ####\n",
        "        self.save_dir = '/content/drive/MyDrive'\n",
        "\n",
        "        # path to checkpoints will be used for inference, replace accordingly\n",
        "        self.inf_model_path  = self.save_dir + '/model-36000.index'\n",
        "\n",
        "\n",
        "\n",
        "        # output will have channel ordering as [Nuclei Type][Nuclei Pixels][Additional]\n",
        "        # where [Nuclei Type] will be used for getting the type of each instance\n",
        "        # while [Nuclei Pixels][Additional] will be used for extracting instances\n",
        "        # for inference during evalutaion mode i.e run by infer.py\n",
        "        self.eval_inf_input_tensor_names = ['images']\n",
        "        self.eval_inf_output_tensor_names = ['predmap-coded']\n",
        "        # for inference during training mode i.e run by trainer.py\n",
        "        self.train_inf_output_tensor_names = ['predmap-coded', 'truemap-coded']\n",
        "\n",
        "        self.inf_imgs_ext = '.png'\n",
        "\n",
        "    def get_model(self):\n",
        "        class Graph(ModelDesc, Config):\n",
        "            def __init__(self):\n",
        "                super(Graph, self).__init__()\n",
        "                assert tf.test.is_gpu_available()\n",
        "                self.data_format = 'channels_first'\n",
        "\n",
        "            def inputs(self):\n",
        "                return [tf.TensorSpec([None] + self.train_input_shape + [3], tf.float32, 'images'),\n",
        "                        tf.TensorSpec([None] + self.train_mask_shape  + [None], tf.float32,  'truemap-coded')]\n",
        "\n",
        "            # for node to receive manual info such as learning rate.\n",
        "            def add_manual_variable(self, name, init_value, summary=True):\n",
        "                var = tf.get_variable(name, initializer=init_value, trainable=False)\n",
        "                if summary:\n",
        "                    tf.summary.scalar(name + '-summary', var)\n",
        "                return\n",
        "\n",
        "            def get_optimizer(self):\n",
        "                with tf.variable_scope(\"\", reuse=True):\n",
        "                    lr = tf.get_variable('learning_rate')\n",
        "                opt = self.optimizer(learning_rate=lr)\n",
        "                return opt\n",
        "\n",
        "            def build_graph(self, images, truemap_coded):\n",
        "\n",
        "                ####\n",
        "                is_training = get_current_tower_context().is_training\n",
        "                \n",
        "               # images, truemap_coded = inputs\n",
        "\n",
        "                orig_imgs = images\n",
        "                pen_map = truemap_coded[...,-1]\n",
        "                if self.type_classification:\n",
        "                    true = truemap_coded[...,1]\n",
        "                else:\n",
        "                    true = truemap_coded[...,0]            \n",
        "                true = tf.cast(true, tf.int32)\n",
        "                true = tf.identity(true, name='truemap')\n",
        "                one  = tf.one_hot(true, self.nr_types if self.type_classification else self.nr_classes, axis=-1)\n",
        "                true = tf.expand_dims(true, axis=-1)\n",
        "\n",
        "                def down_branch(name, main_in, aux_in, ch):\n",
        "                    with tf.variable_scope(name):\n",
        "                        a = Conv2D('conv1', main_in, ch, 3, padding='valid', use_bias=False, activation=BNReLU)\n",
        "                        a = Conv2D('conv2', a, ch, 3, padding='valid', use_bias=True, activation=tf.nn.relu)\n",
        "                        a = MaxPooling('pool', a, 2, strides=2, padding= 'same') \n",
        "\n",
        "                        b = Conv2D('conv3', aux_in, ch, 3, padding='valid', use_bias=False, activation=BNReLU)\n",
        "                        b = Conv2D('conv4',      b, ch, 3, padding='valid', use_bias=True, activation=tf.nn.relu)\n",
        "\n",
        "                        c = tf.concat([a, b], axis=1)\n",
        "                    return c\n",
        "\n",
        "                def up_branch(name, main_in, aux_in, ch):\n",
        "                    with tf.variable_scope(name):\n",
        "                        a = Conv2DTranspose('up1', main_in, ch, 2, strides=(2, 2), padding='same', use_bias=True, activation=tf.identity)\n",
        "                        a = Conv2D('conv1', a, ch, 3, padding='valid', use_bias=True, activation=tf.nn.relu)\n",
        "                        a = Conv2D('conv2', a, ch, 3, padding='valid', use_bias=True, activation=tf.nn.relu)\n",
        "\n",
        "                        # stride 1 is no different from normal 5x5 conv, 'valid' to gain extrapolated border pixels\n",
        "                        b1 = Conv2DTranspose('up2',      a, ch, 5, strides=(1, 1), padding='valid', use_bias=True, activation=tf.identity)\n",
        "                        b2 = Conv2DTranspose('up3', aux_in, ch, 5, strides=(1, 1), padding='valid', use_bias=True, activation=tf.identity)\n",
        "                        b = tf.concat([b1, b2], axis=1)\n",
        "                        b = Conv2D('conv3', b, ch, 1, padding='same', use_bias=True, activation=tf.nn.relu)\n",
        "                    return b\n",
        "\n",
        "                def aux_branch(name, main_in, up_kernel, up_strides):\n",
        "                    ch = main_in.get_shape().as_list()[1] # NCHW\n",
        "                    with tf.variable_scope(name): # preserve the depth\n",
        "                        a = Conv2DTranspose('up', main_in, ch, up_kernel, strides=up_strides, padding='same', use_bias=True, activation=tf.identity)\n",
        "                        a = Conv2D('conv', a, self.nr_types if self.type_classification else self.nr_classes, 3, padding='valid', activation=tf.nn.relu)\n",
        "                        a = tf.layers.dropout(a, rate=0.5, seed=5, training=is_training)\n",
        "                    return a\n",
        "\n",
        "                #### Xavier initializer\n",
        "                with argscope(Conv2D, activation=tf.identity, \n",
        "                            kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(uniform=True),\n",
        "                            bias_initializer=tf.constant_initializer(0.1)), \\\n",
        "                    argscope(Conv2DTranspose, activation=tf.identity, \n",
        "                            kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(uniform=True),\n",
        "                            bias_initializer=tf.constant_initializer(0.1)), \\\n",
        "                        argscope([Conv2D, Conv2DTranspose, MaxPooling, BatchNorm], data_format=self.data_format):\n",
        "\n",
        "                    i = tf.transpose(images / 255.0, [0, 3, 1, 2]) # our way\n",
        "                    resize_func = lambda x, y: resize_op(x, size=y,interp='bicubic', data_format='channels_first')\n",
        "\n",
        "                    ####\n",
        "                    b1 = down_branch('b1',  i, resize_func(i, (128, 128)),  64)\n",
        "                    b2 = down_branch('b2', b1, resize_func(i, ( 64,  64)), 128)\n",
        "                    b3 = down_branch('b3', b2, resize_func(i, ( 32,  32)), 256)\n",
        "                    b4 = down_branch('b4', b3, resize_func(i, ( 16,  16)), 512)\n",
        "\n",
        "                    with tf.variable_scope('b5'):\n",
        "                        b5 = Conv2D('conv1', b4, 2048, 3, padding='valid', use_bias=True, activation=tf.nn.relu)\n",
        "                        b5 = Conv2D('conv2', b5, 2048, 3, padding='valid', use_bias=True, activation=tf.nn.relu)\n",
        "                    b6 = up_branch('b6', b5, b4, 1024)\n",
        "                    b7 = up_branch('b7', b6, b3, 512)\n",
        "                    b8 = up_branch('b8', b7, b2, 256)\n",
        "                    b9 = up_branch('b9', b8, b1, 128)\n",
        "\n",
        "                    aux_out1 = aux_branch('aux_out1', b9, 2, (2, 2))\n",
        "                    aux_out2 = aux_branch('aux_out2', b8, 4, (4, 4))\n",
        "                    aux_out3 = aux_branch('aux_out3', b7, 8, (8, 8))\n",
        "                    out = tf.concat([aux_out1, aux_out2, aux_out3], axis=1)\n",
        "                    out_list = [out, aux_out1, aux_out2, aux_out3]\n",
        "\n",
        "                    soft_list = []\n",
        "                    prob_list = []\n",
        "                    for idx, sub_out in enumerate(out_list):\n",
        "                        logi = Conv2D('conv_out%d' % idx, sub_out, \n",
        "                                        self.nr_types if self.type_classification else self.nr_classes, \n",
        "                                        3, padding='valid', use_bias=True, activation=tf.identity)\n",
        "                        logi = tf.transpose(logi, [0, 2, 3, 1])\n",
        "                        soft = tf.nn.softmax(logi, axis=-1)\n",
        "\n",
        "                        if self.type_classification:\n",
        "                            prob_np = tf.reduce_sum(soft[...,1:], axis=-1, keepdims=True)\n",
        "                            prob_np = tf.identity(prob_np, name='predmap-prob-np')\n",
        "                        else:\n",
        "                            prob_np = tf.identity(soft[...,1], name='predmap-prob')\n",
        "                            prob_np = tf.expand_dims(prob_np, axis=-1)\n",
        "                        \n",
        "                        soft_list.append(soft)\n",
        "                        prob_list.append(prob_np)\n",
        "\n",
        "                    # return the aggregated output\n",
        "                    # encoded so that inference can extract all output at once\n",
        "                    if self.type_classification:\n",
        "                        predmap_coded = tf.concat([soft_list[0], prob_list[0]], axis=-1, name='predmap-coded')\n",
        "                    else:\n",
        "                        predmap_coded = tf.identity(prob_list[0], name='predmap-coded')\n",
        "\n",
        "                ####\n",
        "                if is_training:\n",
        "                    ######## LOSS                       \n",
        "                    # get the variable to received fed weight from external scheduler\n",
        "                    with tf.variable_scope(\"\", reuse=True):\n",
        "                        aux_loss_dw = tf.get_variable('aux_loss_dw')\n",
        "\n",
        "                    loss_list = [] # index 0 is main output\n",
        "                    global_step = tf.train.get_or_create_global_step()\n",
        "                    global_step = tf.cast(global_step, tf.float32)\n",
        "                    for idx, sub_soft in enumerate(soft_list):\n",
        "                        loss_bce = categorical_crossentropy(sub_soft, one)\n",
        "                        loss_bce = tf.reduce_mean(loss_bce * pen_map)\n",
        "                        loss_bce = loss_bce if idx == 0 else loss_bce * aux_loss_dw\n",
        "                        loss_bce = tf.identity(loss_bce, name='loss-bce-%d' % idx)\n",
        "                        loss_list.append(loss_bce)\n",
        "                        add_moving_summary(loss_bce)\n",
        "\n",
        "                    wd_loss = regularize_cost('.*/W', l2_regularizer(1.0e-5), name='l2_wd_loss')\n",
        "                    add_moving_summary(wd_loss)\n",
        "\n",
        "                    cost = tf.add_n(loss_list) + wd_loss\n",
        "                    self.cost = tf.identity(cost, name='overall_cost')\n",
        "                    add_moving_summary(self.cost)\n",
        "                    ####\n",
        "\n",
        "                    add_param_summary(('.*/W', ['histogram']))   # monitor W\n",
        "\n",
        "                    #### logging visual sthg\n",
        "                    orig_imgs = tf.cast(orig_imgs  , tf.uint8)\n",
        "                    tf.summary.image('input', orig_imgs, max_outputs=1)\n",
        "\n",
        "                    colored_list = [true] + prob_list + [tf.expand_dims(pen_map, axis=-1)]\n",
        "                    colored_list = [colorize(feat[...,0], cmap='jet') for feat in colored_list]\n",
        "\n",
        "                    viz = tf.concat([orig_imgs] + colored_list, 2)\n",
        "                    tf.summary.image('output', viz, max_outputs=1)\n",
        "\n",
        "                return\n",
        "        return Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhFRSSEUj2wh"
      },
      "source": [
        "### single_image_infer.py\n",
        "Contains:\n",
        "* Inferer class\n",
        "* Other Methods:\n",
        " * process_instance_micro\n",
        " * process\n",
        "\n",
        "Depends on:\n",
        "* other.py\n",
        "* Config.py\n",
        "* postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMrfXsz4ke4y"
      },
      "outputs": [],
      "source": [
        "def process(pred, model_mode, ws=True):\n",
        "    def gen_inst_dst_map(ann):  \n",
        "        shape = ann.shape[:2] # HW\n",
        "        nuc_list = list(np.unique(ann))\n",
        "        nuc_list.remove(0) # 0 is background\n",
        "\n",
        "        canvas = np.zeros(shape, dtype=np.uint8)\n",
        "        for nuc_id in nuc_list:\n",
        "            nuc_map   = np.copy(ann == nuc_id)    \n",
        "            nuc_dst = distance_transform_edt(nuc_map)\n",
        "            nuc_dst = 255 * (nuc_dst / np.amax(nuc_dst))       \n",
        "            canvas += nuc_dst.astype('uint8')\n",
        "        return canvas\n",
        "    \n",
        "    if model_mode != 'dcan':\n",
        "        assert len(pred.shape) == 2, 'Prediction shape is not HW'\n",
        "        pred[pred  > 0.5] = 1\n",
        "        pred[pred <= 0.5] = 0\n",
        "\n",
        "        # ! refactor these\n",
        "        ws = False if model_mode == 'unet' or model_mode == 'micronet' else ws\n",
        "        if ws:\n",
        "            dist = measurements.label(pred)[0]\n",
        "            dist = gen_inst_dst_map(dist)\n",
        "            marker = np.copy(dist)\n",
        "            marker[marker <= 125] = 0\n",
        "            marker[marker  > 125] = 1\n",
        "            marker = binary_fill_holes(marker) \n",
        "            marker = binary_erosion(marker, iterations=1)\n",
        "            marker = measurements.label(marker)[0]\n",
        "\n",
        "            marker = remove_small_objects(marker, min_size=10)\n",
        "            pred = watershed(-dist, marker, mask=pred)\n",
        "            pred = remove_small_objects(pred, min_size=10)\n",
        "        else:\n",
        "            pred = binary_fill_holes(pred) \n",
        "            pred = measurements.label(pred)[0]\n",
        "            pred = remove_small_objects(pred, min_size=10)\n",
        "        \n",
        "        if model_mode == 'micronet':\n",
        "            # * dilate with same kernel size used for erosion during training\n",
        "            kernel = np.array([[0, 1, 0],\n",
        "                               [1, 1, 1],\n",
        "                               [0, 1, 0]], np.uint8)\n",
        "    \n",
        "            canvas = np.zeros([pred.shape[0], pred.shape[1]])\n",
        "            for inst_id in range(1, np.max(pred)+1):\n",
        "                inst_map = np.array(pred == inst_id, dtype=np.uint8)\n",
        "                inst_map = cv2.dilate(inst_map, kernel, iterations=1)\n",
        "                inst_map = binary_fill_holes(inst_map)\n",
        "                canvas[inst_map > 0] = inst_id\n",
        "            pred = canvas\n",
        "    else:\n",
        "        assert (pred.shape[2]) == 2, 'Prediction should have contour and blb'\n",
        "        blb = pred[...,0]\n",
        "        blb = np.squeeze(blb)\n",
        "        cnt = pred[...,1]\n",
        "        cnt = np.squeeze(cnt)\n",
        "\n",
        "        pred = blb - cnt # NOTE\n",
        "        pred[pred  > 0.3] = 1 # Kumar 0.3, UHCW 0.3\n",
        "        pred[pred <= 0.3] = 0 # CPM2017 0.1\n",
        "        pred = measurements.label(pred)[0]\n",
        "        pred = remove_small_objects(pred, min_size=20)\n",
        "        canvas = np.zeros([pred.shape[0], pred.shape[1]])\n",
        "\n",
        "        k_disk = np.array([\n",
        "            [0, 0, 0, 1, 0, 0, 0],\n",
        "            [0, 0, 1, 1, 1, 0, 0],\n",
        "            [0, 1, 1, 1, 1, 1, 0],\n",
        "            [1, 1, 1, 1, 1, 1, 1],\n",
        "            [0, 1, 1, 1, 1, 1, 0],\n",
        "            [0, 0, 1, 1, 1, 0, 0],\n",
        "            [0, 0, 0, 1, 0, 0, 0],\n",
        "        ], np.uint8)\n",
        "        for inst_id in range(1, np.max(pred)+1):\n",
        "            inst_map = np.array(pred == inst_id, dtype=np.uint8)\n",
        "            inst_map = cv2.dilate(inst_map, k_disk, iterations=1)\n",
        "            inst_map = binary_fill_holes(inst_map)\n",
        "            canvas[inst_map > 0] = inst_id\n",
        "        pred = canvas\n",
        "        \n",
        "    return pred\n",
        "\n",
        "####\n",
        "def process_instance_micro(pred_map, nr_types=0, output_dtype='uint16'):\n",
        "    pred_inst = pred_map[...,0].copy()\n",
        "    pred_inst = process(1-pred_inst, 'micronet')\n",
        "\n",
        "    if nr_types != 0:\n",
        "        pred_type = pred_map[..., 1:nr_types]\n",
        "        pred_type = np.argmax(pred_type, axis=-1)\n",
        "        pred_type = pred_type+1\n",
        "        pred_type = np.squeeze(pred_type)\n",
        "\n",
        "        pred_type_out = np.zeros([pred_type.shape[0], pred_type.shape[1]])               \n",
        "        #### * Get class of each instance id, stored at index id-1\n",
        "        pred_id_list = list(np.unique(pred_inst))[1:] # exclude background ID\n",
        "        pred_inst_type = np.full(len(pred_id_list), 0, dtype=np.int32)\n",
        "        for idx, inst_id in enumerate(pred_id_list):\n",
        "            inst_tmp = pred_inst == inst_id\n",
        "            inst_type = pred_type[pred_inst == inst_id]\n",
        "            type_list, type_pixels = np.unique(inst_type, return_counts=True)\n",
        "            type_list = list(zip(type_list, type_pixels))\n",
        "            type_list = sorted(type_list, key=lambda x: x[1], reverse=True)\n",
        "            inst_type = type_list[0][0]\n",
        "            if inst_type == 0: # ! pick the 2nd most dominant if exist\n",
        "                if len(type_list) > 1:\n",
        "                    inst_type = type_list[1][0]\n",
        "            pred_type_out += (inst_tmp * inst_type)\n",
        "    else:\n",
        "        pred_type_out = pred_inst.copy()\n",
        "        pred_type_out[pred_type_out!=0] = 1\n",
        "\n",
        "    return pred_inst.astype(output_dtype), pred_type_out.astype(output_dtype)\n",
        "\n",
        "def process_instance_hcnet(pred_map, nr_types=0, output_dtype='uint16'):\n",
        "    pos_map = pred_map[...,-1]*255\n",
        "    binary_map = pred_map[...,-2]*255\n",
        "    pred_inst = gaussianmap2binary(pos_map.astype('uint8'), binary_map.astype('uint8'), 150, 40)\n",
        "    \n",
        "    if nr_types != 0:\n",
        "        pred_type = pred_map[..., 1:nr_types]\n",
        "        pred_type = np.argmax(pred_type, axis=-1)\n",
        "        pred_type = pred_type + 1\n",
        "        pred_type = np.squeeze(pred_type)\n",
        "\n",
        "        pred_type_out = np.zeros([pred_type.shape[0], pred_type.shape[1]])               \n",
        "        #### * Get class of each instance id, stored at index id-1\n",
        "        pred_id_list = list(np.unique(pred_inst))[1:] # exclude background ID\n",
        "        pred_inst_type = np.full(len(pred_id_list), 0, dtype=np.int32)\n",
        "        for idx, inst_id in enumerate(pred_id_list):\n",
        "            inst_tmp = pred_inst == inst_id\n",
        "            inst_type = pred_type[pred_inst == inst_id]\n",
        "            type_list, type_pixels = np.unique(inst_type, return_counts=True)\n",
        "            type_list = list(zip(type_list, type_pixels))\n",
        "            type_list = sorted(type_list, key=lambda x: x[1], reverse=True)\n",
        "            inst_type = type_list[0][0]\n",
        "            if inst_type == 0: # ! pick the 2nd most dominant if exist\n",
        "                if len(type_list) > 1:\n",
        "                    inst_type = type_list[1][0]\n",
        "            pred_type_out += (inst_tmp * inst_type)\n",
        "    else:\n",
        "        pred_type_out = pred_inst.copy()\n",
        "        pred_type_out[pred_type_out!=0] = 1\n",
        "\n",
        "    return pred_inst.astype(output_dtype), pred_type_out.astype(output_dtype)\n",
        "\n",
        "####\n",
        "class Inferer(Config):\n",
        "\n",
        "    def __gen_prediction(self, x, predictor):\n",
        "        \"\"\"\n",
        "        Using 'predictor' to generate the prediction of image 'x'\n",
        "        Args:\n",
        "            x : input image to be segmented. It will be split into patches\n",
        "                to run the prediction upon before being assembled back            \n",
        "        \"\"\"    \n",
        "        step_size = self.infer_avalible_shape\n",
        "        msk_size = self.infer_avalible_shape\n",
        "        win_size = self.infer_input_shape\n",
        "        crop_size = int((self.infer_mask_shape[0] - self.infer_avalible_shape[0])/2)\n",
        "\n",
        "        def get_last_steps(length, msk_size, step_size):\n",
        "            nr_step = math.ceil((length - msk_size) / step_size)\n",
        "            last_step = (nr_step + 1) * step_size\n",
        "            return int(last_step), int(nr_step + 1)\n",
        "        \n",
        "        im_h = x.shape[0] \n",
        "        im_w = x.shape[1]\n",
        "\n",
        "        last_h, nr_step_h = get_last_steps(im_h, msk_size[0], step_size[0])\n",
        "        last_w, nr_step_w = get_last_steps(im_w, msk_size[1], step_size[1])\n",
        "\n",
        "        diff_h = win_size[0] - step_size[0]\n",
        "        padt = diff_h // 2\n",
        "        padb = last_h + win_size[0] - im_h\n",
        "\n",
        "        diff_w = win_size[1] - step_size[1]\n",
        "        padl = diff_w // 2\n",
        "        padr = last_w + win_size[1] - im_w\n",
        "\n",
        "        x = np.lib.pad(x, ((padt, padb), (padl, padr), (0, 0)), 'reflect')\n",
        "\n",
        "        #### TODO: optimize this\n",
        "        sub_patches = []\n",
        "        # generating subpatches from orginal\n",
        "        for row in range(0, last_h, step_size[0]):\n",
        "            for col in range (0, last_w, step_size[1]):\n",
        "                win = x[row:row+win_size[0], \n",
        "                        col:col+win_size[1]]\n",
        "                sub_patches.append(win)\n",
        "\n",
        "        pred_map = deque()\n",
        "        while len(sub_patches) > self.inf_batch_size:\n",
        "            mini_batch  = sub_patches[:self.inf_batch_size]\n",
        "            sub_patches = sub_patches[self.inf_batch_size:]\n",
        "            mini_output = predictor(mini_batch)[0]\n",
        "#             print(mini_output.shape)\n",
        "            mini_output = np.split(mini_output, self.inf_batch_size, axis=0)\n",
        "            pred_map.extend(mini_output)\n",
        "        if len(sub_patches) != 0:\n",
        "            mini_output = predictor(sub_patches)[0]\n",
        "#             print(mini_output.shape)\n",
        "            mini_output = np.split(mini_output, len(sub_patches), axis=0)\n",
        "            pred_map.extend(mini_output)\n",
        "        \n",
        "        #### Assemble back into full image\n",
        "        output_patch_shape = np.squeeze(pred_map[0]).shape\n",
        "        ch = 1 if len(output_patch_shape) == 2 else output_patch_shape[-1]\n",
        "\n",
        "        #### Assemble back into full image\n",
        "        pred_map = np.squeeze(np.array(pred_map))\n",
        "        \n",
        "        #### for crop_size !=0\\\n",
        "        if crop_size != 0:\n",
        "            pred_maps = []\n",
        "            for i in range(pred_map.shape[0]):\n",
        "                one_pred_map = pred_map[i][crop_size:-crop_size,crop_size:-crop_size,...]\n",
        "                pred_maps.append(one_pred_map)\n",
        "            pred_maps = np.array(pred_maps)\n",
        "            pred_map = pred_maps\n",
        "        \n",
        "        pred_map = np.reshape(pred_map, (nr_step_h, nr_step_w) + pred_map.shape[1:])\n",
        "        \n",
        "        pred_map = np.transpose(pred_map, [0, 2, 1, 3, 4]) if ch != 1 else \\\n",
        "                        np.transpose(pred_map, [0, 2, 1, 3])\n",
        "        pred_map = np.reshape(pred_map, (pred_map.shape[0] * pred_map.shape[1], \n",
        "                                         pred_map.shape[2] * pred_map.shape[3], ch))\n",
        "        pred_map = np.squeeze(pred_map[:im_h,:im_w]) # just crop back to original size\n",
        "        return pred_map\n",
        "\n",
        "    ####\n",
        "    def run(self, file_path):\n",
        "\n",
        "        model_path = self.inf_model_path\n",
        "\n",
        "        model_constructor = self.get_model()\n",
        "        pred_config = PredictConfig(\n",
        "            model        = model_constructor(),\n",
        "            session_init = get_model_loader(model_path),\n",
        "            input_names  = self.eval_inf_input_tensor_names,\n",
        "            output_names = self.eval_inf_output_tensor_names)\n",
        "        predictor = OfflinePredictor(pred_config)\n",
        "        img = cv2.imread(file_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        pred_map = self.__gen_prediction(img, predictor)\n",
        "        return pred_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VLo_Lu7fkAm"
      },
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2-js1zrvz7L"
      },
      "outputs": [],
      "source": [
        "tf.test.gpu_device_name()\n",
        "# Had to use pip install tensorflow-gpu for this to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0eKxw2cg6na"
      },
      "outputs": [],
      "source": [
        "gpus = \"0,1,2,3,4,5,6\"\n",
        "n_gpus = len(gpus.split(','))\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
        "# file path for all ROIs that need to be predicted\n",
        "# dir path for saving predicted results, .mat format files\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSKyn3eUholM"
      },
      "outputs": [],
      "source": [
        "with open(file_path) as fp:\n",
        "    lines = fp.read().splitlines() \n",
        "img_list = []\n",
        "for i in lines:\n",
        "    path = i.split()[0]\n",
        "    img_list.append(path)\n",
        "    \n",
        "inferer = Inferer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdnBOFIrhqi8"
      },
      "outputs": [],
      "source": [
        "for img_path in img_list:\n",
        "    img_name = img_path.split('/')[-1].strip('.png')\n",
        "    out_file = out_dir + img_path.split('/')[-2]\n",
        "    out_path = out_file+'/'+img_name+'.mat'\n",
        "    pred_map = inferer.run(img_path)\n",
        "    pred_inst, pred_type = process_instance_micro(pred_map, inferer.nr_types)\n",
        "    labels={'Instance':pred_inst,'Type':pred_type}\n",
        "    sio.savemat(out_path, labels)\n",
        "    print(out_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XuiAcs1osoXT"
      ],
      "name": "MicroNet_reimplementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}