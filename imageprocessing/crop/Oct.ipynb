{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> October Lab Log </h1>\n",
    "\n",
    "<h3>Conferences/Seminars attended</h3>\n",
    "\n",
    "<ul>\n",
    "    <li>NHCS Network Meeting (08/10/2019) --- Nordic High Content Screening</li>\n",
    "    <li>eSSENCE (15-16/10/2019) --- Swedish E-Science Academy 2019</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Cropping Images</h3>\n",
    "\n",
    "Most of the month was spent on cropping and going through images.\n",
    "\n",
    "The image set contained 89088 images;\n",
    "\n",
    "29696 of each channel(d0, d1, d2)\n",
    "\n",
    "Instructions from Sonja were to extract one object from each image and crop it into a 400x400 image after getting object coordinates from CellProfiler. At first an iterative approach going through and reading every image was used, but this took too much memory and exceeded the memory limit so I take a different approach. Here is a short version with just the d0 channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "#Import and process cellPro output data\n",
    "os.chdir('C:/Users/jxncx/Documents/BINP52/cProfiler/nuclei')\n",
    "imData = pd.read_csv(r'hoechst-primaryobjectsNuclei.csv')\n",
    "imData = imData.drop(imData.columns.difference(['ImageNumber', \n",
    "                                                        'ObjectNumber',\n",
    "                                                        'Metadata_FileLocation',\n",
    "                                                        'Metadata_Plate',\n",
    "                                                        'Metadata_Well',\n",
    "                                                        'Location_Center_X',\n",
    "                                                        'Location_Center_Y']),\n",
    "                           axis = 1)\n",
    "imData.to_csv(\"nucleiObjects.csv\", index = False)\n",
    "#Import and process image(s)\n",
    "imRaw = glob.glob('testTiffs/*.tiff')\n",
    "imTest = cv2.imread(imRaw[0])\n",
    "dim = imTest[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory is changed to wherever the images and data are. The primary objects csv(output of CellProfiler) is read and all columns are dropped except for the ones which are informative such as coordinates, image number, object number, etc. This data is then written to a new csv and we read just one image for now to get the dimensions(here we assume all images have the same dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "#Iterates through all images(set gets rid of duplicate names)\n",
    "imgSet = set(imData['Metadata_FileLocation'])\n",
    "for i in imgSet:\n",
    "    imName = i.split('/')[-1][:-4]\n",
    "    imCh = imName[-2:]\n",
    "    if imCh == 'd0':\n",
    "        subdir = \"ch0Res\"\n",
    "    #Make df have only those not close to the border, just take one image\n",
    "    nonBordIm = imData.loc[(imData['Metadata_FileLocation'] == i) &\n",
    "                            (imData['Location_Center_X'] > 200) &\n",
    "               (imData['Location_Center_X'] < (dim[0] - 200)) &\n",
    "               (imData['Location_Center_Y'] > 200) &\n",
    "               (imData['Location_Center_Y'] < (dim[0] - 200))].iloc[0]\n",
    "    x = int(nonBordIm['Location_Center_X'])\n",
    "    y = int(nonBordIm['Location_Center_Y'])\n",
    "    objNum = str(nonBordIm['ObjectNumber'])\n",
    "    print(\"READING IMAGE {0} named {1}\".format(counter, imName))\n",
    "    imageVar = cv2.imread('testTiffs/' + imName + '.tiff')\n",
    "    print(\"CROPPING IMAGE {0} named {1}\".format(counter, imName))\n",
    "    cropImg = imageVar[y - 200:y + 200, x - 200:x + 200].copy()\n",
    "    cv2.imwrite(\"searchCrop/{0}/{1}_{2}_{3}_{4}.png\".format(subdir,imName,\n",
    "                objNum, str(x), str(y)), cropImg)\n",
    "    print(\"IMAGE SAVED FOR --- {0} \\n PROGRESS : {1}\".format(imName,\n",
    "          ((counter / len(imgSet)) * 100)))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we initialise a counter at 1.\n",
    "\n",
    "Then, we use the set function to get rid of duplicate names in the data, since the column has a row with the image name for every object found in that image. Now, we have a list with each image name and no duplicates. Now for a for loop which goes through every image and the information found in the CellProfiler analysis.\n",
    "\n",
    "First, we check the channel, in this test case we only had d0 images and we have an if statement here that names the variable 'subdir' 'ch0Res' for channel 0 Results. Second, we want to make sure none of these objects are too close to the border of the image or else cropping will result in an image that is not 400x400 but less in at least one of the directions. After checking that it's not too close to the border, it's cropped 200 in all directions, to make 400x400. Slicing is inversed, so the y coordinate goes first, then the x coordinate when cropping an image. This is written to a .png file in the appropriate subdirectory with the image name, object number, and coordinates. \n",
    "\n",
    "The print statements are handy for showing progress and this is where the counter we initialised before comes in handy as it tells us what portion of the images are complete.\n",
    "\n",
    "This new search and crop script was better not only because of memory usage, but also because it finds corresponding images by the name so if two folders don't have the images in the exact same order, it still finds the right corresponding image. This makes it more reliable than a for loop for instance that just goes through two lists.\n",
    "\n",
    "After running this it was found that none of the channel 1 and 2 images were there. After further inspection, the CellProfiler data file didn't contain any channel 1 or 2 image information. This was because when the first CellProfiler analysis was done those channels were filtered out, so only channel 0 was processed. The CellProfiler pipeline was run again, this time for the other two channels; with LUNARC because a warning was received not to run it on the LUNARC frontend. The resulting primary object files from each channel were used as input for the cropping. \n",
    "\n",
    "Upon even further inspection, Salma found the images didn't match. This is because the script goes through the objects in each individual channel that it finds crops that, then moves to the next image. For example, if an image 1 it finds a nucleus in the top left quadrant and that was the first object it found, it would move on to the next image. Then let's say for some image 2 which is just the corresponding image but in a different channel, it couldn't anything, so the first valid object it found was something in the top right quadrant. This poses a problem because these aren't the same cell then. So after talking to Salma, we used the approach of taking the results of channel 0(because it's the easiest to find objects), and simple use the coordinates to crop an image where the channel 0 object would be. If the coordinates are the same and there's a nucleus, we know there's a cell there even if we cannot see it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
